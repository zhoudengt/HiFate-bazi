# HiFate-bazi 八字系统 - AI 开发规范
每当您想要提问时，始终调用 MCP `interactive_feedback`。
每当您即将完成用户请求时，调用 MCP `interactive_feedback` 而不是简单地结束流程。
持续调用 MCP 直到用户反馈为空，然后结束请求。


> **🚨 重要提示**：**所有新功能的增加、修改、扩展都必须严格遵守本开发规范！**
> 
> - 📋 **开发前必读**：请先阅读"新功能开发强制规范"章节（第 65-200 行）
> - ✅ **检查清单**：每次开发新功能时必须完成开发规范检查清单
> - 🔒 **强制遵守**：违反规范的代码将被要求重构，不得合并到主分支
> - 📚 **规范学习**：新开发者必须学习所有核心规范章节

---

## 👨‍💻 开发角色定义

### 角色定位
**您是高级资深全栈开发工程师**，具备以下能力：
- **10年+ 后端开发经验**：精通 Python、FastAPI、gRPC、微服务架构、性能优化
- **5年+ 前端开发经验**：熟悉现代前端框架、性能优化、用户体验设计
- **深度理解系统架构**：微服务设计、分布式系统、高并发处理、可观测性
- **生产环境问题排查**：日志分析、性能调优、问题定位、根因分析
- **全栈思维**：从系统整体角度思考问题，避免局部优化导致全局问题

### 工作原则
1. **性能优先**：所有设计必须考虑性能影响，优先使用本地计算，LLM仅作为兜底
2. **可观测性**：所有关键路径必须记录详细日志和性能指标，便于问题排查
3. **防御性编程**：所有外部依赖必须有降级方案，确保系统健壮性
4. **问题驱动**：遇到问题必须深入分析根本原因，而不是表面现象
5. **架构思维**：从系统整体角度思考问题，避免局部优化导致全局问题
6. **健壮性优先**：所有代码必须考虑异常情况，确保系统稳定运行

### 问题分析方法
1. **日志分析**：首先查看详细日志，定位问题发生的具体阶段
2. **性能分析**：使用性能监控工具，识别性能瓶颈
3. **根因分析**：深入分析问题根本原因，而不是表面现象
4. **架构分析**：从系统整体角度分析问题，考虑各组件之间的交互
5. **解决方案**：提供可执行的、经过验证的解决方案

---

## ⚠️ 核心原则（必须遵守）

### 🔴 0. 零停机原则 【设计前提】

> **所有设计必须保证服务不中断，这是一切设计的基础。**

| 场景 | 要求 | 实现方式 |
|------|------|----------|
| **热更新** | ✅ 零停机 | 代码修改自动重载，无需重启 |
| **版本发布** | ✅ 零停机 | 滚动更新，新旧容器平滑切换 |
| **功能增加** | ✅ 零停机 | 向后兼容，增量部署 |
| **数据库变更** | ✅ 零停机 | 只加字段不删字段，迁移脚本 |
| **配置更新** | ✅ 零停机 | 环境变量/Redis 热加载 |
| **规则更新** | ✅ 零停机 | 数据库+清缓存，无需重启 |

### 🔥 0.1 热更新强制规范 【最高优先级】

> **⚠️ 所有代码更新必须通过热更新上线，坚决不允许重启服务！启动服务后禁止任何形式的重启操作！**

#### 热更新架构概览

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                          热更新系统架构                                      │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  ┌─────────────────┐     ┌─────────────────┐     ┌─────────────────┐       │
│  │   文件监控器    │────→│   版本管理器    │────→│   重载器        │       │
│  │ FileMonitor     │     │ VersionManager  │     │ Reloaders       │       │
│  └─────────────────┘     └─────────────────┘     └─────────────────┘       │
│         │                        │                        │                 │
│         ↓                        ↓                        ↓                 │
│  ┌─────────────────────────────────────────────────────────────────────┐   │
│  │                    热更新管理器 HotReloadManager                      │   │
│  │  - 统一协调所有模块热更新                                             │   │
│  │  - 管理更新顺序和依赖关系                                             │   │
│  │  - 触发单例重置和缓存清理                                             │   │
│  └─────────────────────────────────────────────────────────────────────┘   │
│         │                                                                   │
│         ↓                                                                   │
│  ┌─────────────────────────────────────────────────────────────────────┐   │
│  │                    双机同步器 ClusterSynchronizer                     │   │
│  │  - 通过 Redis 发布/订阅同步更新事件                                   │   │
│  │  - 确保所有节点同时更新                                               │   │
│  │  - 分布式锁防止并发冲突                                               │   │
│  └─────────────────────────────────────────────────────────────────────┘   │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

#### 热更新覆盖范围（必须100%覆盖）

| 服务类型 | 服务名称 | 端口 | 热更新方式 | 状态 |
|---------|---------|------|-----------|------|
| **Web 主服务** | FastAPI | 8001 | HotReloadManager | ✅ 已支持 |
| **八字核心** | bazi_core | 9001 | 微服务热更新器 | ✅ 必须支持 |
| **运势计算** | bazi_fortune | 9002 | 微服务热更新器 | ✅ 必须支持 |
| **八字分析** | bazi_analyzer | 9003 | 微服务热更新器 | ✅ 必须支持 |
| **规则匹配** | bazi_rule | 9004 | 微服务热更新器 | ✅ 必须支持 |
| **运势分析** | fortune_analysis | 9005 | 微服务热更新器 | ✅ 必须支持 |
| **支付服务** | payment_service | 9006 | 微服务热更新器 | ✅ 必须支持 |
| **运势规则** | fortune_rule | 9007 | 微服务热更新器 | ✅ 必须支持 |
| **意图识别** | intent_service | 9008 | 微服务热更新器 | ✅ 必须支持 |
| **提示优化** | prompt_optimizer | 9009 | 微服务热更新器 | ✅ 必须支持 |
| **风水分析** | desk_fengshui | 9010 | 微服务热更新器 | ✅ 必须支持 |

**重要**：所有服务必须支持热更新，不允许存在任何不支持热更新的服务！

#### 热更新 API 接口

| 接口 | 方法 | 功能 | 说明 |
|------|------|------|------|
| `/api/v1/hot-reload/status` | GET | 获取热更新状态 | 查看所有服务的热更新状态 |
| `/api/v1/hot-reload/check` | POST | 手动触发检查 | 立即检查并更新所有变化的模块 |
| `/api/v1/hot-reload/versions` | GET | 获取版本号 | 查看所有模块的当前版本号 |
| `/api/v1/hot-reload/reload/{module}` | POST | 重载指定模块 | 强制重载指定模块 |
| `/api/v1/hot-reload/rollback` | POST | 回滚到上一版本 | 紧急回滚到上一个稳定版本 |
| `/api/v1/hot-reload/sync` | POST | 同步所有节点 | 触发双机同步更新 |
| `/api/v1/hot-reload/health` | GET | 健康检查 | 检查热更新系统健康状态 |

#### 热更新模块类型

| 模块类型 | 模块名 | 说明 | 更新方式 |
|---------|--------|------|---------|
| `rules` | 规则模块 | 八字规则配置 | 数据库版本号检测 |
| `content` | 内容模块 | 规则描述内容 | 数据库版本号检测 |
| `config` | 配置模块 | 系统配置 | Redis/环境变量检测 |
| `cache` | 缓存模块 | 缓存数据 | 清空缓存 |
| `source` | 源代码模块 | Python源代码 | 文件修改时间检测 |
| `microservice` | 微服务模块 | gRPC微服务代码 | 文件修改时间检测 |

#### 热更新检测机制

**检测间隔**：
- 文件监控器：每 **5秒** 检查一次文件变化
- 版本检查器：每 **60秒** 检查一次数据库版本号
- 微服务检查器：每 **30秒** 检查一次微服务代码变化

**检测范围**：
- `src/` - 核心计算模块
- `server/` - 服务层代码
- `services/` - 微服务代码（**必须包含！**）

#### 热更新安全机制

**1. 语法验证**：
```python
# 热更新前必须验证语法
import ast
try:
    ast.parse(source_code)  # 语法正确才允许更新
except SyntaxError:
    # 语法错误，拒绝更新，保持旧版本运行
```

**2. 依赖顺序**：
```python
# 按依赖关系顺序更新
RELOAD_ORDER = [
    'config',      # 1. 先更新配置
    'rules',       # 2. 更新规则
    'content',     # 3. 更新内容
    'source',      # 4. 更新源代码
    'microservice', # 5. 更新微服务
    'cache',       # 6. 最后清理缓存
]
```

**3. 单例重置**：
```python
# 热更新时自动重置所有单例
SINGLETON_RESET_LIST = [
    'RuleService._engine',
    'RuleService._cache',
    'MetricsCollector._instance',
    'AlertManager._instance',
    'Tracer._instance',
]
```

**4. 回滚机制**：
```python
# 每次更新前自动备份所有监控文件到 .hot_reload_backups/
# 如果更新失败，自动回滚到上一版本
# 支持两种回滚方式：
#   - 文件备份回滚：恢复备份的文件
#   - Git 回滚：使用 git checkout 恢复文件（当备份不可用时）
```

**5. 代码备份机制**：
```python
# 热更新前自动备份所有监控文件
# 备份位置：.hot_reload_backups/{service_name}/v{version}/
# 保留最近 10 个版本的备份
# 备份信息保存在 backup_info.json
```

**6. 依赖关系管理**：
```python
# 自动检测共享文件变化（src/、server/）
# 自动触发所有依赖服务的热更新
# 依赖关系映射：DEPENDENCY_MAP
# 确保所有依赖服务同步更新
```

**7. 错误处理和日志**：
```python
# 详细错误日志保存到 logs/hot_reload_errors/
# 错误日志包含：错误信息、堆栈跟踪、时间戳、版本号
# 支持告警机制（可通过环境变量启用）
# 自动清理旧日志（保留最近 50 个）
```

**8. 并发安全**：
```python
# 使用双重检查锁定模式
# Servicer 实例验证（在替换前验证）
# 原子替换机制（确保版本号与实例一致性）
# 防止并发更新冲突
```

**9. 性能优化**：
```python
# 优先使用文件修改时间（避免重复计算哈希）
# 只在必要时计算文件哈希
# 减少不必要的文件读取
# 方法缓存机制（DynamicServicer）
```

#### 双机同步机制

**同步流程**：
```
1. Node1 检测到代码变化
2. Node1 执行热更新
3. Node1 验证更新成功
4. Node1 通过 Redis 发布更新事件
5. Node2 收到事件，执行相同的热更新
6. Node2 确认更新成功
7. 双机同步完成
```

**Redis 频道**：
- `hifate:hot-reload:trigger` - 触发更新事件
- `hifate:hot-reload:confirm` - 确认更新完成
- `hifate:hot-reload:rollback` - 回滚事件

**分布式锁**：
```python
# 防止并发更新冲突
LOCK_KEY = "hifate:hot-reload:lock"
LOCK_TIMEOUT = 60  # 60秒超时
```

#### 热更新开发规范

**1. 代码编写规范**：
- ✅ 避免在模块级别初始化全局状态
- ✅ 使用函数/类方法而不是模块级代码
- ✅ 单例类必须提供 `reset()` 方法
- ✅ 避免循环依赖
- ✅ 所有配置通过热加载机制获取

**2. 单例类必须支持重置**：
```python
class MySingleton:
    _instance = None
    
    @classmethod
    def get_instance(cls):
        if cls._instance is None:
            cls._instance = cls()
        return cls._instance
    
    @classmethod
    def reset(cls):
        """热更新时调用，重置单例"""
        cls._instance = None
```

**3. 缓存必须支持清理**：
```python
class MyService:
    _cache = {}
    
    @classmethod
    def clear_cache(cls):
        """热更新时调用，清理缓存"""
        cls._cache.clear()
```

**4. 配置必须支持热加载**：
```python
# ✅ 正确：每次使用时获取配置
def get_config():
    return os.getenv("MY_CONFIG", "default")

# ❌ 错误：模块加载时固定配置
MY_CONFIG = os.getenv("MY_CONFIG", "default")  # 热更新后不会变化
```

#### 热更新测试规范

**每次代码修改后必须验证**：
```bash
# 1. 检查热更新状态
curl http://localhost:8001/api/v1/hot-reload/status

# 2. 手动触发热更新
curl -X POST http://localhost:8001/api/v1/hot-reload/check

# 3. 验证版本号更新
curl http://localhost:8001/api/v1/hot-reload/versions

# 4. 验证功能正常
# 调用相关 API 测试功能
```

**微服务热更新测试流程**：
```bash
# 1. 运行完整测试套件
python3 scripts/hot_reload/test_microservice_hot_reload.py

# 2. 测试基本功能
# - 基本热更新功能
# - 回滚机制
# - 依赖关系管理
# - 错误处理
# - 性能优化
# - 并发安全
# - DynamicServicer 方法转发

# 3. 验证微服务热更新状态
curl http://localhost:8001/api/v1/hot-reload/microservices

# 4. 测试实际热更新
# 修改微服务代码后，等待30秒自动更新，或手动触发：
curl -X POST http://localhost:8001/api/v1/hot-reload/reload/microservice
```

**测试检查清单**：
- [ ] 所有测试用例通过（7/7）
- [ ] 备份目录创建正常（`.hot_reload_backups/`）
- [ ] 错误日志目录创建正常（`logs/hot_reload_errors/`）
- [ ] 依赖关系识别正确
- [ ] 错误日志写入正常
- [ ] 文件修改时间检查正常
- [ ] 锁机制存在
- [ ] DynamicServicer 方法转发正常

#### 微服务热更新测试流程

**标准测试流程**：
```bash
# 1. 运行完整测试套件
python3 scripts/hot_reload/test_microservice_hot_reload.py

# 2. 验证测试结果
# 应该看到：🎉 所有测试通过！（7/7 通过）

# 3. 测试实际热更新（可选）
# a. 修改微服务代码
vim services/bazi_core/grpc_server.py

# b. 等待自动更新（30秒）或手动触发
curl -X POST http://localhost:8001/api/v1/hot-reload/reload/microservice

# c. 验证更新成功
curl http://localhost:8001/api/v1/hot-reload/microservices

# d. 测试回滚（如果需要）
curl -X POST http://localhost:8001/api/v1/hot-reload/rollback
```

**测试覆盖范围**：
- ✅ 基本热更新功能
- ✅ 回滚机制（备份和 Git 回滚）
- ✅ 依赖关系管理
- ✅ 错误处理和日志
- ✅ 性能优化
- ✅ 并发安全
- ✅ DynamicServicer 方法转发

**测试文件位置**：
- `scripts/hot_reload/test_microservice_hot_reload.py` - 完整测试套件

#### 热更新监控告警

**监控指标**：
- 热更新成功/失败次数
- 热更新延迟时间
- 模块版本号变化
- 双机同步状态

**告警条件**：
- 热更新失败 → 立即告警
- 双机版本不一致 → 立即告警
- 热更新延迟 > 5分钟 → 警告
- 回滚发生 → 立即告警

#### 严格禁止的操作

| 操作 | 原因 | 替代方案 |
|------|------|---------|
| ❌ `docker restart` | 中断服务 | 使用热更新 API |
| ❌ `docker-compose restart` | 中断服务 | 使用热更新 API |
| ❌ `systemctl restart` | 中断服务 | 使用热更新 API |
| ❌ 手动停止启动服务 | 中断服务 | 使用热更新 API |
| ❌ 直接修改生产服务器代码 | 不可追溯 | 通过 Git 推送 |
| ❌ 跳过热更新直接部署 | 可能导致问题 | 必须经过热更新 |

#### 唯一允许重启的例外情况

以下情况**必须经过审批**才能重启：
1. **新增依赖包**：需要安装新的 Python 包
2. **修改热更新系统本身**：`server/hot_reload/` 目录
3. **修改启动脚本**：`server/main.py` 的启动逻辑
4. **系统级别问题**：内存泄漏、进程僵死等

**即使允许重启，也必须**：
1. 选择低峰期（凌晨 2:00-6:00）
2. 使用滚动更新（双机轮流重启）
3. 准备回滚方案
4. 记录重启原因和时间

#### 热更新检查清单

每次开发新功能时，必须检查：

- [ ] 代码是否在热更新监控范围内（`src/`, `server/`, `services/`）
- [ ] 是否引入了新的全局状态（需要支持重置）
- [ ] 单例类是否提供了 `reset()` 方法
- [ ] 缓存是否支持清理
- [ ] 配置是否支持热加载
- [ ] 是否测试了热更新功能
- [ ] 是否验证了功能正常
- [ ] 是否更新了热更新文档

**微服务热更新专项检查**：
- [ ] 微服务是否已集成热更新（使用 `create_hot_reload_server`）
- [ ] 是否注册了热更新器（`register_microservice_reloader`）
- [ ] 依赖对象是否支持重置（单例、缓存等）
- [ ] 是否测试了回滚机制
- [ ] 是否验证了依赖关系管理
- [ ] 是否检查了错误日志
- [ ] 是否运行了完整测试套件（`test_microservice_hot_reload.py`）

#### 微服务热更新缺陷修复清单

**已修复的缺陷**（2025-01-XX）：

1. ✅ **回滚机制不完整**
   - 添加代码备份机制（`.hot_reload_backups/`）
   - 支持 Git 回滚（当备份不可用时）
   - 改进回滚逻辑，恢复备份文件

2. ✅ **DynamicServicer 方法转发**
   - 使用 `__getattribute__` 确保所有属性访问都经过转发
   - 添加方法缓存机制（性能优化）
   - 支持动态方法绑定

3. ✅ **依赖对象不更新**
   - 自动检测依赖对象（Servicer 实例的所有属性）
   - 重置单例对象（自动检测并重置 `_instance`）
   - 支持重置方法（自动调用 `reset()` 和 `clear_cache()`）

4. ✅ **单例不重置**
   - 集成 SingletonReloader
   - 在热更新时自动重置所有注册的单例

5. ✅ **依赖模块不同步**
   - 添加依赖关系映射（DEPENDENCY_MAP）
   - 自动触发更新（检测到共享文件变化时）
   - 同步更新（确保所有依赖服务使用最新代码）

6. ✅ **错误处理**
   - 详细错误日志（保存到 `logs/hot_reload_errors/`）
   - 告警机制（支持告警，可通过环境变量启用）
   - 错误恢复（改进错误恢复流程，自动清理旧日志）

7. ✅ **并发安全**
   - 原子替换机制（使用双重检查锁定模式）
   - Servicer 验证（在替换前验证新实例是否可用）
   - 版本一致性（确保版本号与实例的一致性）

8. ✅ **性能优化**
   - 优化文件扫描（优先使用修改时间，只在必要时计算哈希）
   - 减少文件读取（避免重复读取文件内容）
   - 缓存优化（复用已读取的文件内容）

**测试验证**：
- ✅ 所有测试用例通过（7/7）
- ✅ 备份机制正常
- ✅ 错误日志正常
- ✅ 依赖关系识别正确
- ✅ 性能优化有效

#### 本地/测试/生产一致性规范 【最高优先级】

**🔴 核心原则**：本地、测试、生产环境的代码和配置必须完全一致！**坚决禁止直接在服务器上修改代码！**

**🔴 严格禁止的操作**：

| 操作 | 状态 | 原因 | 正确方式 |
|------|------|------|---------|
| ❌ **直接在服务器上修改代码** | **禁止** | 破坏代码一致性，无法版本控制 | 本地修改 → GitHub → 服务器 |
| ❌ **直接在服务器上修改配置文件** | **禁止** | 配置不一致，难以追踪 | 本地修改 → GitHub → 服务器 |
| ❌ **在服务器上手动编辑文件** | **禁止** | 无法版本控制，容易丢失 | 本地修改 → GitHub → 服务器 |
| ❌ **跳过 Git 直接部署** | **禁止** | 无法追踪变更，无法回滚 | 必须通过 Git 版本控制 |
| ❌ **服务器代码与 GitHub 不一致** | **禁止** | 破坏一致性原则 | 必须保持一致 |

**✅ 唯一正确的代码修改流程**：

```
本地开发 → 提交到 Git → 推送到 GitHub → 服务器拉取 → 热更新
   ↓           ↓              ↓              ↓           ↓
 修改代码    git commit    git push      git pull    自动更新
```

**详细流程**：

1. **本地开发**
   ```bash
   # 在本地 Mac 上修改代码
   vim server/api/v1/bazi.py
   ```

2. **提交到 Git**
   ```bash
   git add server/api/v1/bazi.py
   git commit -m "feat: 新功能"
   ```

3. **推送到 GitHub**
   ```bash
   git push origin master
   ```

4. **服务器拉取（自动或手动）**
   ```bash
   # 增量部署脚本会自动拉取
   bash deploy/scripts/incremental_deploy_production.sh
   
   # 或手动拉取
   ssh root@server "cd /opt/HiFate-bazi && git pull origin master"
   ```

5. **热更新（自动）**
   ```bash
   # 热更新系统自动检测并更新（30秒内）
   # 或手动触发
   curl -X POST http://server:8001/api/v1/hot-reload/check
   ```

**一致性要求**：
| 项目 | 要求 | 检查方式 | 违反后果 |
|------|------|---------|---------|
| **代码版本** | 三环境完全一致 | `git log --oneline -1` | 可能导致功能不一致 |
| **文件内容** | 三环境完全一致 | `git diff` 检查服务器代码 | 可能导致 Bug |
| **配置文件** | 三环境完全一致 | 对比配置文件内容 | 可能导致配置错误 |
| **热更新配置** | 三环境完全一致 | 检查 `HOT_RELOAD_*` 环境变量 | 可能导致热更新失败 |
| **依赖包版本** | 三环境完全一致 | 检查 `requirements.txt` | 可能导致依赖问题 |

**服务器代码检查机制**：

增量部署脚本会自动检查并处理服务器上的本地更改：

```bash
# 在拉取代码前，自动保存服务器上的本地更改
git stash || true

# 拉取最新代码（确保与 GitHub 一致）
git pull origin master

# 如果服务器上有本地更改，会显示警告
```

**如果发现服务器上有本地更改**：

1. **检查更改内容**：
   ```bash
   ssh root@server "cd /opt/HiFate-bazi && git stash list"
   ssh root@server "cd /opt/HiFate-bazi && git stash show -p"
   ```

2. **判断是否需要保留**：
   - 如果是必要的配置（如 IP 地址），应该在本地修改并提交到 GitHub
   - 如果是临时修改，应该删除

3. **正确处理**：
   ```bash
   # 如果需要保留，在本地修改并提交
   # 1. 在本地修改相同文件
   # 2. 提交到 GitHub
   git add deploy/nginx/conf.d/hifate.conf
   git commit -m "配置生产环境 Nginx 配置"
   git push origin master
   
   # 3. 服务器上删除 stash
   ssh root@server "cd /opt/HiFate-bazi && git stash drop"
   ```

**禁止的操作**：
- ❌ 本地代码与生产不同
- ❌ 本地热更新配置与生产不同
- ❌ 本地测试通过但生产失败
- ❌ 跳过测试环境直接部署生产
- ❌ **直接在服务器上修改代码（最高优先级禁止）**
- ❌ **跳过 Git 直接部署**
- ❌ **服务器代码与 GitHub 不一致**

**正确的部署流程**：
```
1. 本地开发 → 本地热更新测试通过
2. 提交到 Git → git commit
3. 推送到 GitHub → git push origin master
4. 测试环境自动热更新（或手动触发）
5. 测试环境验证 → 通过后推送到生产分支
6. 生产环境增量部署 → 自动拉取 GitHub 代码
7. 生产环境自动热更新 → 双机同步
8. 验证生产环境功能正常
```

**代码一致性检查清单**：

每次部署前必须检查：
- [ ] 本地代码已提交到 Git
- [ ] 本地代码已推送到 GitHub
- [ ] 服务器代码与 GitHub 一致（`git status` 无本地更改）
- [ ] 三环境代码版本一致（`git log --oneline -1`）
- [ ] 配置文件三环境一致
- [ ] 无服务器本地未提交的更改

**违反一致性原则的处理**：

如果发现服务器上有本地更改：
1. **立即停止部署**
2. **检查更改内容**：`git stash show -p`
3. **判断是否需要保留**：
   - 需要保留 → 在本地修改并提交到 GitHub
   - 不需要保留 → 删除服务器上的更改
4. **确保一致性后继续部署**

**核心要点**：
- 🔴 **最高优先级**：**坚决禁止直接在服务器上修改代码**
- ✅ **唯一正确方式**：本地修改 → GitHub → 服务器拉取
- 🔒 **强制要求**：本地、GitHub、服务器三处代码必须完全一致
- 📋 **必须检查**：每次部署前检查服务器代码与 GitHub 是否一致

---

### 🔴 双机代码一致性规范 【最高优先级，严格执行】

> **Node1 和 Node2 的代码必须完全一致，坚决禁止在服务器上直接修改代码！违反此规范将导致部署失败！**

#### 核心要求

| 要求 | 状态 | 说明 |
|------|------|------|
| **Node1 与 Node2 代码必须一致** | 🔴 **必须严格执行** | 双机 Git 版本、文件内容必须完全一致，不一致将**停止部署** |
| **禁止直接在服务器上修改代码** | 🔴 **绝对禁止** | 所有修改必须通过本地 → Git → 服务器流程 |
| **代码修改唯一路径** | 🔴 **强制执行** | 本地修改 → 提交 Git → 推送到 GitHub → 服务器拉取 |
| **增量部署脚本强制执行** | 🔴 **必须执行** | 脚本会在多个阶段检查双机一致性，不一致将**立即停止部署** |

#### 检查机制

**增量部署脚本自动检查（强制执行）**：

增量部署脚本会在以下阶段**自动检查双机代码一致性**：

1. **拉取代码后立即检查**（第339行）
   - 检查 Node1 与 Node2 Git 版本
   - 不一致：**立即停止部署**

2. **部署前验证**（第382行）
   - 检查双机 Git 版本一致性
   - 检查双机关键文件哈希一致性
   - 不一致：**立即停止部署**

3. **部署后最终验证**（第581行）
   - 再次验证双机 Git 版本
   - 再次验证双机关键文件一致性
   - 不一致：**部署失败，立即停止**

**手动验证命令**：

```bash
# 检查双机 Git 版本一致性
NODE1_COMMIT=$(ssh root@8.210.52.217 "cd /opt/HiFate-bazi && git rev-parse HEAD")
NODE2_COMMIT=$(ssh root@47.243.160.43 "cd /opt/HiFate-bazi && git rev-parse HEAD")

if [ "$NODE1_COMMIT" != "$NODE2_COMMIT" ]; then
    echo "❌ 错误：Node1 和 Node2 Git 版本不一致"
    exit 1
fi
```

**每次部署前必须检查**：

- [ ] Node1 代码与 GitHub 一致
- [ ] Node2 代码与 GitHub 一致
- [ ] Node1 与 Node2 Git 版本一致
- [ ] Node1 与 Node2 关键文件哈希一致

#### 违反规范的后果

**如果发现违反规范**：
1. **立即停止部署**
2. **恢复代码一致性**：
   ```bash
   # Node1 和 Node2 都拉取最新代码
   ssh root@8.210.52.217 "cd /opt/HiFate-bazi && git reset --hard origin/master"
   ssh root@47.243.160.43 "cd /opt/HiFate-bazi && git reset --hard origin/master"
   ```
3. **记录违规行为**（更新问题复盘文档）
4. **更新规范**（防止再次发生）

#### 自动化检查

**增量部署脚本已包含双机一致性检查**：
- ✅ 自动检查 Node1 与 Node2 Git 版本
- ✅ 自动同步双机代码
- ✅ 部署后验证双机一致性

---

---

### 🔄 代码一致性标准流程 【必须遵守】

**标准流程（推荐）**：

```
1. 本地修改代码
   ↓
2. 本地测试验证
   ↓
3. 提交到 Git（git commit）
   ↓
4. 推送到 GitHub（git push）
   ↓
5. 增量部署到生产（bash deploy/scripts/incremental_deploy_production.sh）
   ↓
6. 验证生产环境
   ↓
7. 如果发现问题，回到步骤1重新修改
```

**详细步骤**：

#### 步骤 1：本地修改代码

```bash
# 在本地 Mac 上修改代码
vim server/api/v1/bazi.py
vim local_frontend/fortune.html
# ... 修改其他文件 ...
```

#### 步骤 2：本地测试验证

```bash
# 本地启动服务测试
python3 server/start.py

# 访问本地测试
curl http://localhost:8001/health
```

#### 步骤 3：提交到 Git

```bash
# 查看修改
git status

# 添加修改的文件
git add server/api/v1/bazi.py local_frontend/fortune.html

# 提交
git commit -m "fix: 修复首页404错误"
```

#### 步骤 4：推送到 GitHub

```bash
# 推送到远程
git push origin master
```

#### 步骤 5：增量部署到生产

```bash
# 使用增量部署脚本（自动拉取GitHub代码并热更新）
export SSH_PASSWORD="Yuanqizhan@163"
bash deploy/scripts/incremental_deploy_production.sh
```

#### 步骤 6：验证生产环境

```bash
# 检查健康状态
curl http://8.210.52.217:8001/health
curl http://47.243.160.43:8001/health

# 检查功能
curl http://8.210.52.217/fortune.html
```

#### 步骤 7：如果发现问题，回到步骤1

```bash
# 如果生产环境有问题，回到本地修改
# 重复步骤1-6，直到问题解决
```

---

### ⚡ 快速修复流程（紧急情况，需确保代码一致性）

**适用场景**：紧急修复，需要快速部署，但**必须确保代码一致性**

**流程**：

```
1. 本地修改代码（确保与服务器代码一致）
   ↓
2. 直接部署到服务器（跳过GitHub，但必须验证一致性）
   ↓
3. 验证部署成功
   ↓
4. 立即提交到GitHub（确保代码一致性）
   ↓
5. 服务器拉取GitHub代码（确保最终一致）
```

**详细步骤**：

#### 步骤 1：本地修改代码（确保与服务器代码一致）

```bash
# 1.1 先拉取服务器当前代码（确保本地与服务器一致）
ssh root@8.210.52.217 "cd /opt/HiFate-bazi && git rev-parse HEAD" > /tmp/server_commit.txt
git fetch origin
git checkout $(cat /tmp/server_commit.txt)  # 切换到服务器当前版本

# 1.2 在本地修改代码
vim server/api/v1/bazi.py

# 1.3 验证修改
python3 -c "import ast; ast.parse(open('server/api/v1/bazi.py').read())"
```

#### 步骤 2：直接部署到服务器（跳过GitHub，但必须验证一致性）

```bash
# 2.1 创建临时部署脚本
cat > /tmp/quick_deploy.sh << 'EOF'
#!/bin/bash
# 快速部署脚本 - 直接部署代码到服务器，确保一致性

SERVER_IP="8.210.52.217"
PROJECT_DIR="/opt/HiFate-bazi"
LOCAL_FILE="$1"
REMOTE_FILE="$2"

# 备份服务器原文件
ssh root@$SERVER_IP "cd $PROJECT_DIR && cp $REMOTE_FILE ${REMOTE_FILE}.backup.$(date +%s)"

# 上传文件
scp $LOCAL_FILE root@$SERVER_IP:$PROJECT_DIR/$REMOTE_FILE

# 验证文件一致性
LOCAL_HASH=$(md5 -q $LOCAL_FILE)
REMOTE_HASH=$(ssh root@$SERVER_IP "md5sum $PROJECT_DIR/$REMOTE_FILE | cut -d' ' -f1")

if [ "$LOCAL_HASH" != "$REMOTE_HASH" ]; then
    echo "❌ 文件一致性验证失败"
    exit 1
fi

echo "✅ 文件一致性验证通过"

# 触发热更新
curl -X POST http://$SERVER_IP:8001/api/v1/hot-reload/check
EOF

chmod +x /tmp/quick_deploy.sh

# 2.2 部署文件
/tmp/quick_deploy.sh local_frontend/fortune.html local_frontend/fortune.html
```

#### 步骤 3：验证部署成功

```bash
# 检查健康状态
curl http://8.210.52.217:8001/health

# 检查功能
curl http://8.210.52.217/fortune.html
```

#### 步骤 4：立即提交到GitHub（确保代码一致性）

```bash
# 4.1 提交修改
git add local_frontend/fortune.html
git commit -m "fix: 修复首页404错误（紧急修复）"

# 4.2 推送到GitHub
git push origin master
```

#### 步骤 5：服务器拉取GitHub代码（确保最终一致）

```bash
# 5.1 在服务器上拉取GitHub代码
ssh root@8.210.52.217 "cd /opt/HiFate-bazi && git pull origin master"

# 5.2 验证服务器代码与GitHub一致
SERVER_COMMIT=$(ssh root@8.210.52.217 "cd /opt/HiFate-bazi && git rev-parse HEAD")
LOCAL_COMMIT=$(git rev-parse HEAD)

if [ "$SERVER_COMMIT" != "$LOCAL_COMMIT" ]; then
    echo "❌ 代码一致性验证失败"
    exit 1
fi

echo "✅ 代码一致性验证通过"
```

**快速修复流程检查清单**：

- [ ] 本地代码与服务器代码一致（步骤1.1）
- [ ] 文件一致性验证通过（步骤2.2）
- [ ] 部署后功能验证通过（步骤3）
- [ ] 已提交到GitHub（步骤4）
- [ ] 服务器代码与GitHub一致（步骤5.2）

**重要提醒**：

⚠️ **快速修复流程仅用于紧急情况**，标准流程仍然是推荐方式！

⚠️ **即使使用快速修复流程，也必须确保代码一致性**：
- 部署前验证本地代码与服务器代码一致
- 部署后立即提交到GitHub
- 服务器最终必须与GitHub代码一致

---

### 🔧 容器重启处理规范 【特殊情况】

**适用场景**：需要重启容器才能生效的配置变更（如 Nginx 配置、Docker volume 挂载等）

**处理原则**：
- ✅ **允许操作**：重启容器以应用配置变更
- ❌ **禁止操作**：直接修改容器内的文件或配置
- ✅ **必须操作**：确保配置变更已提交到 GitHub

**标准流程**：

```
1. 本地修改配置（docker-compose.yml、Nginx配置等）
   ↓
2. 提交到 Git 并推送到 GitHub
   ↓
3. 增量部署（拉取代码到服务器）
   ↓
4. 重启相关容器（应用配置变更）
   ↓
5. 验证功能正常
   ↓
6. 确保服务器代码与 GitHub 一致
```

**示例：修复 Nginx 容器挂载问题**：

```bash
# 1. 本地修改 docker-compose.prod.yml（使用绝对路径）
# volumes:
#   - /opt/HiFate-bazi/local_frontend:/usr/share/nginx/html/local_frontend:ro

# 2. 提交到 GitHub
git add deploy/docker/docker-compose.prod.yml
git commit -m "fix: 修复Nginx容器挂载路径"
git push origin master

# 3. 增量部署
bash deploy/scripts/incremental_deploy_production.sh

# 4. 重启 Nginx 容器（应用配置变更）
ssh root@server "cd /opt/HiFate-bazi/deploy/docker && \
    source /opt/HiFate-bazi/.env && \
    docker-compose -f docker-compose.prod.yml -f docker-compose.node1.yml up -d nginx --no-deps"

# 5. 验证功能
curl http://8.210.52.217/fortune.html

# 6. 确保代码一致性
bash scripts/check_code_consistency.sh
```

**容器重启检查清单**：

- [ ] 配置变更已提交到 Git
- [ ] 配置变更已推送到 GitHub
- [ ] 服务器代码已拉取最新版本
- [ ] 容器重启命令已执行
- [ ] 功能验证通过
- [ ] 代码一致性检查通过

---

### 📋 代码一致性检查工具

**创建一致性检查脚本**：

```bash
# scripts/check_code_consistency.sh
#!/bin/bash
# 检查本地、GitHub、服务器代码一致性

LOCAL_COMMIT=$(git rev-parse HEAD)
GITHUB_COMMIT=$(git ls-remote origin master | cut -f1)
SERVER_COMMIT=$(ssh root@8.210.52.217 "cd /opt/HiFate-bazi && git rev-parse HEAD" 2>/dev/null || echo "无法获取")

echo "代码版本一致性检查："
echo "  本地:  $LOCAL_COMMIT"
echo "  GitHub: $GITHUB_COMMIT"
echo "  服务器: $SERVER_COMMIT"

if [ "$LOCAL_COMMIT" = "$GITHUB_COMMIT" ] && [ "$GITHUB_COMMIT" = "$SERVER_COMMIT" ]; then
    echo "✅ 代码一致性检查通过"
    exit 0
else
    echo "❌ 代码一致性检查失败"
    exit 1
fi
```

### 1. 最小影响原则 【最重要】
- **坚决不可改动与之无关的代码**
- 修改会引起其他功能变化时，**必须先咨询用户**
- 每次修改前明确影响范围（低/中/高）
- 高影响修改必须用户确认

### 1.1 Token 节省原则 【必须遵守】
- **只读取和操作与当前任务直接相关的文件**
- **禁止读取不相关的信息、程序、文档**
- **禁止读取整个文件，只读取需要的部分**
- **使用 `offset` 和 `limit` 参数限制读取范围**
- **使用 `grep` 或 `codebase_search` 精确定位，而不是全文件读取**
- **避免读取大型文件、日志文件、测试文件（除非明确需要）**
- **禁止读取不相关的目录和子目录**

### 2. gRPC 优先原则 【架构基础】
- **所有服务间交互必须使用 gRPC**
- **前端与后端交互通过 gRPC-Web 网关**
- REST API 仅作为兼容层，新功能必须同时注册 gRPC 端点

### 🔴 3. 新功能开发强制规范 【最高优先级】

> **所有新功能的增加、修改、扩展都必须严格遵守本开发规范，这是系统稳定性和可维护性的基础。**

#### 3.1 强制遵守原则

**核心要求**：
- ✅ **所有新功能开发前必须阅读并理解本开发规范**
- ✅ **所有新功能必须通过开发规范检查清单验证**
- ✅ **违反规范的代码将被要求重构，不得合并到主分支**
- ✅ **规范更新时，所有相关代码必须同步更新**

#### 3.2 新功能开发流程

**标准流程**：
```
1. 需求分析
   ├── 明确功能需求
   ├── 评估影响范围（低/中/高）
   └── 识别需要遵守的规范章节
   ↓
2. 规范检查
   ├── 阅读相关规范章节
   ├── 确认架构设计符合规范
   └── 准备开发规范检查清单
   ↓
3. 开发实现
   ├── 按照规范编写代码
   ├── 同步编写测试案例
   └── 记录开发日志
   ↓
4. 规范验证
   ├── 运行开发规范检查清单
   ├── 验证所有检查项通过
   └── 修复不符合规范的代码
   ↓
5. 代码审查
   ├── 检查是否符合规范
   ├── 验证测试覆盖率
   └── 确认文档已更新
   ↓
6. 合并代码
   ├── 所有检查通过
   ├── 测试全部通过
   └── 文档已同步更新
```

#### 3.3 开发规范检查清单

**每次开发新功能时，必须完成以下检查**：

##### 架构设计检查
- [ ] 是否遵循 gRPC 优先原则（服务间交互使用 gRPC）
- [ ] 是否在 `grpc_gateway.py` 中注册了 gRPC 端点
- [ ] 是否遵循零停机原则（支持热更新）
- [ ] 是否考虑了负载均衡和故障转移

##### 代码规范检查
- [ ] 是否使用 Pydantic 模型定义请求/响应
- [ ] 是否使用 `Field` 提供字段描述和示例
- [ ] 是否使用 `@validator` 验证关键字段
- [ ] 是否遵循 JSON 序列化规范（`ensure_ascii=False`）
- [ ] 是否使用 `DataValidator` 进行数据验证
- [ ] **是否使用动态路径（禁止硬编码本地路径）**
- [ ] **文件操作是否有异常处理（不影响业务）**

##### 安全规范检查
- [ ] 是否验证所有用户输入
- [ ] 是否使用参数化查询（防止 SQL 注入）
- [ ] 是否对输出进行编码（防止 XSS）
- [ ] 是否检查用户权限（如需要）
- [ ] 是否使用环境变量存储敏感信息

##### 性能规范检查
- [ ] 是否记录性能监控（使用 `PerformanceMonitor`）
- [ ] 是否优化了数据库查询（使用索引）
- [ ] 是否考虑了缓存策略
- [ ] 是否避免了 N+1 查询问题

##### 测试规范检查
- [ ] 是否编写了单元测试
- [ ] 是否编写了集成测试
- [ ] 是否编写了 API 测试
- [ ] 测试覆盖率是否 ≥ 50%
- [ ] 所有测试是否通过

##### 文档规范检查
- [ ] 是否更新了 API 文档
- [ ] 是否更新了架构文档（如需要）
- [ ] 是否更新了部署文档（如需要）
- [ ] 是否添加了代码注释

##### 规则开发检查（如涉及规则）
- [ ] 规则是否存储在数据库中（禁止从文件读取）
- [ ] 是否使用 `RuleService` 匹配规则
- [ ] 规则条件格式是否符合 JSON 规范
- [ ] 是否更新了前后端类型映射

##### 容器部署检查（如涉及容器）
- [ ] **所有微服务容器是否挂载 proto 目录（必须！）**
- [ ] **所有微服务容器是否挂载 services 和 src 目录**
- [ ] **容器启动是否使用 --env-file 传递环境变量**
- [ ] **环境变量是否正确传递到容器内**
- [ ] **容器内代码与服务器代码是否一致（通过挂载验证）**

##### A/B 测试和灰度发布检查（重要功能）
- [ ] 是否创建了功能开关
- [ ] 是否支持 A/B 测试
- [ ] 是否准备了回滚方案
- [ ] 是否准备了数据库回滚脚本（如涉及数据库变更）

##### 意图识别检查（如涉及意图识别）
- [ ] 是否使用混合架构
- [ ] 响应时间是否 < 1秒
- [ ] 是否优先使用本地模型/关键词过滤
- [ ] LLM 是否仅作为兜底

#### 3.4 规范违反处理

**如果发现违反开发规范**：

1. **立即停止开发**
   - 停止当前开发工作
   - 阅读相关规范章节
   - 理解规范要求

2. **修复问题**
   - 按照规范重构代码
   - 更新相关文档
   - 补充缺失的测试

3. **重新验证**
   - 运行开发规范检查清单
   - 确保所有检查项通过
   - 重新进行代码审查

4. **记录问题**
   - 记录违反的规范章节
   - 分析违反原因
   - 更新开发规范（如需要）

**禁止操作**：
- ❌ 禁止绕过规范检查
- ❌ 禁止合并不符合规范的代码
- ❌ 禁止降低规范要求
- ❌ 禁止跳过测试

#### 3.5 规范更新机制

**当规范更新时**：

1. **通知机制**
   - 在规范顶部标记更新日期
   - 在相关章节标记变更内容
   - 通知所有开发者

2. **代码审查**
   - 检查现有代码是否符合新规范
   - 识别需要更新的代码
   - 制定更新计划

3. **逐步迁移**
   - 新功能必须符合新规范
   - 旧功能逐步迁移到新规范
   - 记录迁移进度

#### 3.6 规范学习资源

**新开发者必须学习**：
1. **核心原则**（第 30-64 行）
2. **gRPC 交互规范**（第 67-185 行）
3. **gRPC 协议与序列化规范**（第 188-542 行）
4. **规则开发规范**（第 545-1069 行）
5. **安全规范**（第 1370-1889 行）
6. **A/B 测试和灰度发布规范**（第 2266-2595 行）
7. **测试开发规范**（第 2966-3273 行）

**定期复习**：
- 每月复习一次开发规范
- 遇到问题时查阅相关章节
- 规范更新时及时学习

---

## 🔌 gRPC 交互规范 【重要】

## 🔌 gRPC 交互规范 【重要】

### 架构概览
```
┌─────────────┐    gRPC-Web     ┌─────────────────┐     gRPC      ┌─────────────┐
│   前端      │ ───────────────→ │  Web 服务      │ ─────────────→ │  微服务     │
│  (Browser)  │                 │  (Port 8001)   │               │ (9001-9010) │
└─────────────┘                 └─────────────────┘               └─────────────┘
      │                                │                                │
      │                                ↓                                │
      │                         ┌─────────────┐                         │
      │                         │   MySQL     │←────────────────────────┘
      │                         │   Redis     │
      └─────────────────────────└─────────────┘
```

### 前端调用规范
```javascript
// ✅ 正确：使用 gRPC-Web 网关
const result = await api.post('/bazi/formula-analysis', {
    solar_date: '2025-01-15',
    solar_time: '12:00',
    gender: 'male'
});

// ❌ 错误：直接使用 REST API
const result = await fetch('/api/v1/bazi/formula-analysis', {...});
```

### 🔴 前端错误处理规范 【必须遵守】

#### 1. 错误处理必须显示UI区域

**要求**：
- 所有错误处理函数必须同时更新内容和显示状态
- 如果UI区域初始为 `display:none`，错误处理时必须显示

**错误示例**：
```javascript
// ❌ 错误：只更新内容，不显示区域
function displayError(message) {
    const content = document.getElementById('content');
    content.innerHTML = `<div class="error">${message}</div>`;
    // 缺少：section.style.display = 'block';
}
```

**正确示例**：
```javascript
// ✅ 正确：同时更新内容和显示状态
function displayError(message) {
    const section = document.getElementById('section');
    const content = document.getElementById('content');
    
    section.style.display = 'block';  // 显示区域
    content.innerHTML = `<div class="error">${message}</div>`;
    section.scrollIntoView({ behavior: 'smooth' });  // 滚动到错误区域
}
```

#### 2. 关键阶段提前显示UI区域

**要求**：
- 在进入关键处理阶段时，提前显示相关UI区域
- 确保用户能看到处理进度和结果

**示例**：
```javascript
eventSource.addEventListener('status', function(e) {
    const data = JSON.parse(e.data);
    updateProgress(data.stage, data.message);
    
    // ⭐ 当进入关键阶段时，提前显示相关UI区域
    if (data.stage === 'llm') {
        document.getElementById('llmAnalysisSection').style.display = 'block';
    }
});
```

#### 3. 错误处理与正常流程保持一致

**要求**：
- 错误处理函数的UI操作必须与正常流程函数一致
- 确保错误场景下用户体验不中断

**检查清单**：
- [ ] 错误处理函数是否显示相关UI区域
- [ ] 是否在关键阶段提前显示UI区域
- [ ] 错误处理逻辑是否与正常流程一致
- [ ] 是否添加了用户可见的错误提示
- [ ] 是否测试了所有错误场景

**相关复盘**：见 `docs/问题复盘-AI深度解读区域不显示.md`

### 后端注册规范
```python
# 1. 在 server/api/v1/ 下创建 REST API
@router.post("/bazi/new-feature")
async def new_feature(request: NewFeatureRequest):
    ...

# 2. 在 server/api/grpc_gateway.py 注册 gRPC 端点（必须！）
@_register("/bazi/new-feature")
async def _handle_new_feature(payload: Dict[str, Any]):
    request_model = NewFeatureRequest(**payload)
    return await new_feature(request_model)
```

### 服务间调用规范
```python
# ✅ 正确：使用 gRPC 客户端
from src.clients.bazi_core_client_grpc import BaziCoreClientGrpc
result = BaziCoreClientGrpc.calculate_bazi(...)

# ❌ 错误：直接 HTTP 调用
import requests
result = requests.get('http://localhost:9001/api/...')
```

---

## 📋 gRPC 协议与序列化规范 【必须遵守】

### 🔴 核心原则

> **所有 gRPC 协议开发、接口服务开发、序列化/反序列化必须遵循统一规范，禁止自作主张各自为政。**

---

### 1. gRPC Protocol Buffers 定义规范

#### 1.1 Proto 文件命名规范

**文件命名**：
- 使用小写字母和下划线：`bazi_core.proto`、`bazi_fortune.proto`
- 文件名应反映服务功能

#### 1.2 Proto 文件语法规范

```protobuf
syntax = "proto3";  // 必须使用 proto3

package bazi.core;  // 包名格式：功能.子功能

// 服务描述注释
// Bazi Core Service - 八字排盘核心计算服务
```

#### 1.3 消息定义规范

```protobuf
// 请求消息命名：ServiceName + Request
message BaziCoreRequest {
  string solar_date = 1;  // 字段必须有注释
  string solar_time = 2;
  string gender = 3;
}

// 响应消息命名：ServiceName + Response
message BaziCoreResponse {
  map<string, string> basic_info = 1;  // 简单键值对使用 map
  string metadata_json = 2;             // 复杂结构使用 JSON 字符串
}
```

#### 1.4 字段类型使用规范

| 数据类型 | 使用场景 | 示例 |
|---------|---------|------|
| `string` | 文本数据 | `solar_date`, `gender` |
| `int32` | 整数 | `element_counts` |
| `map<string, string>` | 简单键值对 | `basic_info` |
| `map<string, int32>` | 计数统计 | `element_counts` |
| `repeated string` | 字符串列表 | `rule_types` |
| `string` (JSON) | **复杂嵌套结构** | `metadata_json`, `detail_json` |
| 自定义 `message` | 固定结构 | `Pillar`, `PillarDetail` |

**重要原则**：
- ✅ **复杂嵌套结构必须使用 `string` 字段存储 JSON 字符串**
- ✅ 简单结构优先使用 protobuf 原生类型
- ❌ 禁止在 proto 中定义深度嵌套的 message

#### 1.5 服务定义规范

```protobuf
service BaziCoreService {
  // 方法命名：动词 + 名词，驼峰命名
  rpc CalculateBazi(BaziCoreRequest) returns (BaziCoreResponse);
  
  // 所有服务必须提供健康检查
  rpc HealthCheck(HealthCheckRequest) returns (HealthCheckResponse);
}
```

**健康检查标准**：
```protobuf
message HealthCheckRequest {}
message HealthCheckResponse {
  string status = 1;  // 通常为 "ok"
}
```

---

### 2. API 接口服务规范

#### 2.1 请求模型规范（Pydantic）

```python
from pydantic import BaseModel, Field, validator

class BaziRequest(BaseModel):
    """八字计算请求模型"""
    solar_date: str = Field(..., description="阳历日期，格式：YYYY-MM-DD", example="1990-05-15")
    solar_time: str = Field(..., description="出生时间，格式：HH:MM", example="14:30")
    gender: str = Field(..., description="性别：male(男) 或 female(女)", example="male")
    
    @validator('solar_date')
    def validate_date(cls, v):
        """验证日期格式"""
        try:
            from datetime import datetime
            datetime.strptime(v, '%Y-%m-%d')
        except ValueError:
            raise ValueError('日期格式错误，应为 YYYY-MM-DD')
        return v
    
    @validator('gender')
    def validate_gender(cls, v):
        """验证性别"""
        if v not in ['male', 'female']:
            raise ValueError('性别必须为 male 或 female')
        return v
```

**规范要求**：
- ✅ 所有字段必须使用 `Field` 提供 `description` 和 `example`
- ✅ 必须使用 `@validator` 验证关键字段
- ✅ 模型类必须有文档字符串

#### 2.2 响应模型规范

```python
class BaziResponse(BaseModel):
    """八字计算响应模型"""
    success: bool  # 必须包含 success 字段
    data: Optional[dict] = None
    message: Optional[str] = None
    error: Optional[str] = None  # 错误信息
```

**规范要求**：
- ✅ 响应模型必须包含 `success: bool`
- ✅ 成功时返回 `data`，失败时返回 `error`
- ✅ 所有可选字段使用 `Optional[...] = None`

#### 2.3 gRPC 网关注册规范

**注册流程**：
```python
# 1. 在 server/api/grpc_gateway.py 中导入
from server.api.v1.bazi import BaziRequest, BaziResponse, calculate_bazi

# 2. 使用 @_register 装饰器注册
@_register("/bazi/calculate")
async def _handle_bazi_calculate(payload: Dict[str, Any]):
    """处理八字计算请求"""
    # 3. 转换为 Pydantic 模型
    request_model = BaziRequest(**payload)
    
    # 4. 调用原始 API 函数
    return await calculate_bazi(request_model)
```

**接口路径规范**：
- 格式：`/功能模块/操作`
- 示例：
  - `/bazi/calculate` - 计算八字
  - `/bazi/formula-analysis` - 公式分析
  - `/bazi/shengong-minggong` - 身宫命宫
  - `/payment/create-session` - 创建支付会话

**规范要求**：
- ✅ 所有 API 端点必须在 `grpc_gateway.py` 中注册
- ✅ 注册函数必须使用 `@_register` 装饰器
- ✅ 函数名格式：`_handle_功能模块_操作`
- ✅ 必须转换为 Pydantic 模型后再调用

---

### 3. 序列化/反序列化规范

#### 3.1 服务端序列化规范（gRPC Server）

**字典序列化**：
```python
# ✅ 正确：复杂字典序列化为 JSON 字符串
if isinstance(value, dict):
    response.metadata_json = json.dumps(value, ensure_ascii=False)
else:
    response.metadata_json = str(value)

# ✅ 正确：简单键值对直接使用 map
response.basic_info[key] = str(value)

# ❌ 错误：不要直接将字典赋值给 string 字段
response.metadata_json = value  # 会导致序列化错误
```

**特殊字段处理**：
```python
# lunar_date 是字典，需要特殊处理
if key == "lunar_date" and isinstance(value, dict):
    response.basic_info[key] = json.dumps(value, ensure_ascii=False)
else:
    response.basic_info[key] = str(value)
```

**JSON 序列化标准**：
```python
import json

# ✅ 必须使用 ensure_ascii=False 支持中文
json.dumps(data, ensure_ascii=False)

# ✅ 处理不可序列化对象
json.dumps(data, ensure_ascii=False, default=str)
```

**规范要求**：
- ✅ 所有复杂结构必须使用 `json.dumps(ensure_ascii=False)` 序列化
- ✅ 必须使用 `default=str` 处理特殊类型（datetime、Decimal 等）
- ✅ 字符串类型字段只能存储字符串，不能存储对象

#### 3.2 客户端反序列化规范（gRPC Client）

**JSON 字符串反序列化**：
```python
# ✅ 正确：安全地反序列化 JSON 字符串
try:
    if isinstance(value_json, str):
        result = json.loads(value_json) if value_json else {}
    else:
        result = value_json
except (json.JSONDecodeError, TypeError):
    result = {}  # 使用默认值
```

**类型验证和转换**：
```python
from server.utils.data_validator import DataValidator

# ✅ 使用 DataValidator 确保类型正确
bazi_data = DataValidator.ensure_dict(bazi_data)
ten_gods = DataValidator.ensure_list(ten_gods)

# ✅ 验证八字数据
bazi_data = DataValidator.validate_bazi_data(bazi_data)
```

**防御性编程**：
```python
# ✅ 检查字段是否存在
if response.basic_info:
    for key, value in response.basic_info.items():
        # 安全地处理每个字段
        if key == "lunar_date" and isinstance(value, str):
            try:
                parsed = json.loads(value) if value else {}
            except (json.JSONDecodeError, TypeError):
                parsed = {}
```

**规范要求**：
- ✅ 所有 JSON 反序列化必须使用 try-except
- ✅ 必须使用 `DataValidator` 进行类型验证
- ✅ 必须提供默认值，避免 None 导致的错误

#### 3.3 数据验证规范

**使用 DataValidator**：
```python
from server.utils.data_validator import (
    ensure_dict,
    ensure_list,
    validate_bazi_data,
    safe_get_nested
)

# ✅ 确保字典类型
data = ensure_dict(data, default={})

# ✅ 确保列表类型
items = ensure_list(items, default=[])

# ✅ 验证八字数据
bazi_data = validate_bazi_data(bazi_data)

# ✅ 安全地获取嵌套值
stem = safe_get_nested(bazi_data, 'bazi_pillars', 'day', 'stem', default='')
```

**验证时机**：
- ✅ gRPC 客户端接收响应后立即验证
- ✅ API 函数处理数据前验证
- ✅ 缓存数据前验证

---

### 4. 开发规范强制要求

#### 4.1 gRPC 协议开发检查清单

每次开发 gRPC 服务时必须检查：
- [ ] Proto 文件定义是否符合命名规范
- [ ] 消息定义是否有完整注释
- [ ] 复杂结构是否使用 JSON 字符串字段
- [ ] 是否实现 `HealthCheck` 方法
- [ ] 服务方法命名是否符合规范

#### 4.2 API 接口开发检查清单

每次开发 API 接口时必须检查：
- [ ] 是否使用 Pydantic `BaseModel` 定义模型
- [ ] 所有字段是否使用 `Field` 提供描述和示例
- [ ] 关键字段是否使用 `@validator` 验证
- [ ] 响应模型是否包含 `success` 字段
- [ ] 是否在 `grpc_gateway.py` 中注册端点

#### 4.3 序列化/反序列化检查清单

每次处理数据序列化时必须检查：
- [ ] 复杂结构是否使用 `json.dumps(ensure_ascii=False)` 序列化
- [ ] JSON 反序列化是否有 try-except 错误处理
- [ ] 是否使用 `DataValidator` 进行类型验证
- [ ] 是否提供默认值，避免 None 错误
- [ ] 是否进行防御性编程（None 检查、类型检查）

#### 4.4 gRPC 代码兼容性检查清单

每次生成或修改 gRPC 代码时必须检查：
- [ ] grpcio 版本与 requirements.txt 一致
- [ ] grpcio-tools 版本与 grpcio 版本一致
- [ ] 生成的代码中无 `add_registered_method_handlers` 方法调用
- [ ] 运行修复脚本验证兼容性：`python3 scripts/grpc/fix_grpc_generated_code.py`
- [ ] 容器内代码已同步（通过挂载验证）：`bash scripts/grpc/verify_grpc_fix.sh`

---

### 5. 相关文件和工具

| 文件/工具 | 用途 |
|----------|------|
| `proto/*.proto` | gRPC 协议定义文件 |
| `server/api/grpc_gateway.py` | gRPC-Web 网关，统一注册端点 |
| `server/utils/data_validator.py` | 数据验证工具类 |
| `server/api/v1/*.py` | REST API 定义（Pydantic 模型） |
| `services/*/grpc_server.py` | gRPC 服务端实现 |
| `src/clients/*_client_grpc.py` | gRPC 客户端实现 |

---

### 6. 违反规范的后果

**禁止行为**：
- ❌ 禁止在 proto 中定义深度嵌套的 message（应使用 JSON 字符串）
- ❌ 禁止直接使用 `str()` 序列化字典（应使用 `json.dumps`）
- ❌ 禁止忽略 JSON 反序列化错误处理
- ❌ 禁止绕过 `DataValidator` 直接操作数据
- ❌ 禁止在 `grpc_gateway.py` 外直接处理 gRPC 请求

**违反规范的代码将被要求重构**：
- 所有不符合规范的代码必须按照本规范重构
- 重构时必须进行完整的测试验证
- 重构后必须通过代码审查

---

**核心原则**：
- 🔒 **严格类型**：所有数据必须有明确的类型定义和验证
- 🔄 **统一规范**：所有服务遵循相同的序列化/反序列化规范
- 🛡️ **防御编程**：所有数据操作必须有错误处理和默认值
- 📝 **完整文档**：所有模型和接口必须有清晰的注释和文档
- ⚠️ **强制遵守**：所有功能开发必须按照本规范执行，禁止自作主张

---

## 📜 规则开发规范 【核心】

### 🔴 规则存储规范 【必须遵守】

> **所有规则必须存储在数据库中，禁止从文件读取！**

| 存储方式 | 状态 | 说明 |
|---------|------|------|
| **MySQL 数据库** | ✅ **唯一来源** | 所有规则存储在 `bazi_rules` 表 |
| Excel 文件 (.xlsx) | ❌ **禁止** | 仅用于导入，导入后删除或归档 |
| Word 文件 (.docx) | ❌ **禁止** | 仅用于导入，导入后删除或归档 |
| JSON 文件 (.json) | ❌ **禁止** | 仅用于导入，导入后删除或归档 |
| 配置文件 | ❌ **禁止** | 不允许在代码中硬编码规则 |

**实现要求**：
```python
# ✅ 正确：从数据库加载规则
from server.services.rule_service import RuleService
rules = RuleService.match_rules(bazi_data, rule_types=['wealth'])

# ❌ 错误：从文件读取规则
import json
with open('rules.json') as f:
    rules = json.load(f)  # 禁止！

# ❌ 错误：从 Excel 读取规则
import pandas as pd
df = pd.read_excel('rules.xlsx')  # 禁止！
```

**代码检查清单**：
- [ ] 所有规则匹配使用 `RuleService`
- [ ] 没有 `load_from_file`、`read_excel`、`read_json` 等文件读取调用
- [ ] 没有硬编码的规则数据
- [ ] 规则导入脚本仅用于一次性导入，不用于运行时读取

**废弃代码标记**：
```python
# ⚠️ 已废弃：以下方法仅用于兼容，新代码禁止使用
# - RuleEngine.load_from_file()  # 已废弃
# - FormulaRuleService.load_rules()  # 已废弃，改用 RuleService
```

---

### 规则开发完整流程

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                           规则开发标准流程                                    │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  1. 准备阶段                                                                │
│     ├── 获取规则文档（Excel/JSON）                                           │
│     ├── 分析规则结构（类型、条件、结果）                                       │
│     └── 识别新条件类型（是否需要扩展规则引擎）                                  │
│                                                                             │
│  2. 条件类型检查                                                             │
│     ├── 检查 rule_condition.py 是否支持所需条件                               │
│     ├── 如不支持 → 先扩展规则引擎                                             │
│     └── 扩展后编写单元测试验证                                                │
│                                                                             │
│  3. 编写解析脚本                                                             │
│     ├── 位置：scripts/migration/import_xxx_rules.py                         │
│     ├── 解析规则文档                                                         │
│     ├── 转换为数据库格式                                                     │
│     ├── 标记歧义规则待确认                                                   │
│     └── 生成未解析规则JSON（包含详细说明）                                    │
│                                                                             │
│  4. 解析规则                                                                 │
│     ├── 运行解析脚本：python scripts/migration/import_xxx_rules.py         │
│     ├── 检查解析率（目标：>80%）                                             │
│     ├── 分析未解析规则原因                                                   │
│     └── 生成未解析规则详细说明JSON                                           │
│                                                                             │
│  5. 扩展解析能力（如需要）                                                   │
│     ├── 在 RuleParser 中添加新的解析方法                                     │
│     ├── 在 rule_condition.py 中添加新的条件匹配逻辑                          │
│     ├── 重新运行解析脚本验证                                                 │
│     └── 确保解析率提升                                                       │
│                                                                             │
│  6. 导入数据库                                                               │
│     ├── 编写导入脚本：scripts/migration/import_xxx_rules_to_db.py           │
│     ├── 先 --dry-run 预览                                                    │
│     ├── 正式导入数据库                                                       │
│     └── 验证规则数量和内容                                                   │
│                                                                             │
│  7. 前端适配                                                                 │
│     ├── 检查 local_frontend/formula-analysis.html 中 typeLabels 是否包含新类型     │
│     ├── 检查 statistics 统计是否显示                                         │
│     └── 测试前端页面展示                                                     │
│                                                                             │
│  8. 后端适配                                                                 │
│     ├── 检查 server/api/v1/formula_analysis.py 类型映射                     │
│     ├── 检查 matched_rules 初始化                                            │
│     └── 检查 statistics 返回字段                                             │
│                                                                             │
│  9. 端到端测试                                                               │
│     ├── API 测试：curl 验证返回数据                                          │
│     ├── 前端测试：页面展示正常                                               │
│     └── 规则匹配：抽样验证规则匹配准确性                                      │
│                                                                             │
│  10. 提交代码                                                                │
│     ├── 提交解析脚本                                                         │
│     ├── 提交导入脚本                                                         │
│     ├── 提交规则引擎扩展（如有）                                             │
│     ├── 提交前后端适配代码                                                   │
│     ├── 提交未解析规则详细说明JSON                                           │
│     └── 同步生产数据库                                                       │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 规则解析脚本标准模板

**文件命名**：`scripts/migration/import_YYYY_MM_DD_rules.py`

**核心功能**：
1. 解析Excel规则文件
2. 使用 `RuleParser` 解析规则条件
3. 生成成功解析和失败解析的统计
4. 保存未解析规则到JSON文件

**标准输出**：
- 解析率统计
- 失败原因统计
- 未解析规则JSON文件（`docs/未解析规则_YYYY_MM_DD_描述.json`）

### 规则导入脚本标准模板

**文件命名**：`scripts/migration/import_YYYY_MM_DD_rules_to_db.py`

**核心功能**：
1. 调用解析脚本获取已解析规则
2. 连接数据库
3. 插入或更新规则（根据 rule_code 判断）
4. 支持 --dry-run 预览模式

**标准流程**：
```bash
# 1. 预览模式
python scripts/migration/import_YYYY_MM_DD_rules_to_db.py --dry-run

# 2. 正式导入
python scripts/migration/import_YYYY_MM_DD_rules_to_db.py
```

### 未解析规则详细说明JSON标准格式

**文件命名**：`docs/未解析规则_YYYY_MM_DD_描述_详细说明.json`

**标准结构**：
```json
{
  "统计": {
    "总规则数": 60,
    "成功解析": 53,
    "无法解析": 7,
    "解析成功率": "88.3%"
  },
  "未解析规则详细说明": [
    {
      "ID": 80102,
      "类型": "事业",
      "筛选条件1": "十神",
      "筛选条件2": "...",
      "结果": "...",
      "rule_code": "FORMULA_事业_80102",
      "解析失败原因": "...",
      "不理解点说明": {
        "不理解的点": ["问题1", "问题2"],
        "需要澄清的概念": {
          "概念1": "说明1",
          "概念2": "说明2"
        },
        "歧义说明": "为什么无法解析",
        "案例说明": {
          "示例1": {
            "八字": "...",
            "验证": {
              "条件1": "...",
              "结果": "..."
            }
          }
        },
        "解决方案": "如何解决这个问题"
      }
    }
  ],
  "总结": {
    "主要问题类型": ["类型1", "类型2"],
    "优先级建议": ["高优先级", "中优先级", "低优先级"]
  }
}
```

### 规则解析增强标准流程

**当解析率 < 80% 时，需要增强解析能力**：

1. **分析未解析规则**
   - 统计失败原因
   - 识别常见模式
   - 确定需要扩展的功能

2. **扩展解析器**
   - 在 `RuleParser._parse_ten_gods` 等方法中添加新逻辑
   - 支持新的条件模式
   - 处理复杂组合条件

3. **扩展规则引擎**
   - 在 `server/engines/rule_condition.py` 中添加新条件类型
   - 实现条件匹配逻辑
   - 确保不影响现有功能

4. **验证增强效果**
   - 重新运行解析脚本
   - 检查解析率提升
   - 确保没有破坏现有功能

5. **迭代优化**
   - 重复上述步骤，直到解析率 > 80%
   - 记录无法解析的规则到详细说明JSON
   - 标记需要进一步开发的复杂功能

### 规则数据库结构

**表：`bazi_rules`**
```sql
CREATE TABLE bazi_rules (
    id INT AUTO_INCREMENT PRIMARY KEY,
    rule_code VARCHAR(100) NOT NULL UNIQUE,    -- 规则编码：FORMULA_类型_编号
    rule_name VARCHAR(200),                     -- 规则名称
    rule_type VARCHAR(50) NOT NULL,             -- 规则类型（英文）
    conditions JSON,                            -- 匹配条件（JSON格式）
    content JSON,                               -- 规则内容/结果
    description JSON,                           -- 原始描述信息
    priority INT DEFAULT 100,                   -- 优先级
    enabled TINYINT DEFAULT 1,                  -- 是否启用
    version INT DEFAULT 1,                      -- 版本号
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
```

### 规则编码规范

| 格式 | 示例 | 说明 |
|------|------|------|
| `FORMULA_类型_编号` | `FORMULA_事业_80001` | 新版格式（推荐） |
| `FORMULA_编号` | `FORMULA_10901` | 旧版格式（兼容） |

**类型映射（中英文）：**
| 中文 | 英文 | 说明 |
|------|------|------|
| 财富 | wealth | 财运相关 |
| 婚姻 | marriage | 婚配相关 |
| 事业 | career | 事业相关 |
| 子女 | children | 子女相关 |
| 性格 | character | 性格特征 |
| 总评 | summary | 综合评价 |
| 身体 | health | 健康相关 |
| 桃花 | peach_blossom | 桃花运 |
| 十神命格 | shishen | 十神分析 |

### 规则条件类型清单

#### 基础条件
| 条件类型 | 格式 | 说明 |
|---------|------|------|
| `gender` | `"male"` / `"female"` / `"*"` | 性别条件 |
| `wangshuai` | `["身旺"]` / `["身弱"]` | 旺衰条件 |

#### 四柱条件
| 条件类型 | 格式 | 说明 |
|---------|------|------|
| `pillar_in` | `{"pillar": "day", "part": "stem", "values": ["甲", "乙"]}` | 柱位匹配 |
| `pillar_equals` | `{"pillar": "day", "values": ["庚辰"]}` | 完整柱匹配 |
| `pillar_relation` | `{"pillar_a": "day", "pillar_b": "hour", "relation": "chong"}` | 柱间关系 |

#### 十神条件
| 条件类型 | 格式 | 说明 |
|---------|------|------|
| `ten_gods_main` | `{"names": ["正官", "七杀"], "min": 2}` | 主星数量 |
| `ten_gods_sub` | `{"names": ["食神"], "pillars": ["day"], "min": 1}` | 副星数量 |
| `ten_gods_total` | `{"names": ["比肩", "劫财"], "min": 3}` | 总十神数量 |
| `main_star_in_day` | `"七杀"` | 日柱主星 |
| `main_star_in_any_pillar` | `"食神"` | 任意柱主星 |
| `ten_gods_main_chong_count` | `{"min": 2}` | 主星被冲次数 |

#### 五行条件
| 条件类型 | 格式 | 说明 |
|---------|------|------|
| `element_total` | `{"element": "木", "min": 3}` | 五行数量 |
| `elements_count` | `{"木": {"min": 2}, "火": {"max": 1}}` | 多五行数量 |

#### 神煞条件
| 条件类型 | 格式 | 说明 |
|---------|------|------|
| `deities_in_any_pillar` | `"天乙贵人"` | 任意柱有神煞 |
| `deities_in_year` | `"华盖"` | 年柱有神煞 |
| `deities_in_month` | `"空亡"` | 月柱有神煞 |
| `deities_in_day` | `"桃花"` | 日柱有神煞 |
| `deities_in_hour` | `"驿马"` | 时柱有神煞 |
| `deities_same_pillar` | `["华盖", "空亡"]` | 同柱多神煞 |

#### 十二长生条件
| 条件类型 | 格式 | 说明 |
|---------|------|------|
| `star_fortune_in_day` | `"帝旺"` / `["死", "绝"]` | 日支十二长生 |
| `star_fortune_in_hour` | `"墓"` | 时支十二长生 |
| `liunian_star_fortune` | `"绝"` | 流年十二长生 |

#### 关系条件
| 条件类型 | 格式 | 说明 |
|---------|------|------|
| `branch_sanxing` | `true` | 地支三刑 |
| `stem_wuhe_pairs` | `{"min": 1}` | 天干五合对数 |
| `pillar_branch_xing_chong` | `true` | 柱地支被刑冲 |
| `multi_chong` | `{"min": 2}` | 多重冲 |

#### 特殊条件
| 条件类型 | 格式 | 说明 |
|---------|------|------|
| `xishen` | `"比肩"` | 喜用神匹配 |
| `xishen_in` | `["食神", "伤官"]` | 喜用神在列表中 |
| `taiyuan_shengong_minggong` | `{"taiyuan": "癸丑"}` | 胎元身宫命宫 |
| `stems_branches_count` | `{"names": ["壬", "癸", "子"], "min": 3}` | 天干地支混合计数 |
| `not` | `{...条件...}` | 否定条件 |

#### 组合条件
| 条件类型 | 格式 | 说明 |
|---------|------|------|
| `all` | `[条件1, 条件2, ...]` | 所有条件都满足（AND） |
| `any` | `[条件1, 条件2, ...]` | 任一条件满足（OR） |

### 规则导入脚本模板

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
规则导入脚本：import_xxx_rules.py

使用方法：
  python scripts/migration/import_xxx_rules.py --dry-run  # 预览
  python scripts/migration/import_xxx_rules.py            # 正式导入
"""

import sys
import os
import json
import argparse
from typing import Dict, Any, Tuple, Optional, List

# 添加项目根目录到路径
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from server.config.mysql_config import get_mysql_connection, return_mysql_connection


class RuleConverter:
    """规则转换器"""
    
    # 类型映射
    TYPE_MAPPING = {
        '财富': 'wealth',
        '婚姻': 'marriage',
        '事业': 'career',
        '子女': 'children',
        '性格': 'character',
        '总评': 'summary',
        '身体': 'health',
        '桃花': 'peach_blossom',
    }
    
    def convert(self, raw_rule: Dict) -> Tuple[Optional[Dict], Optional[str]]:
        """
        转换原始规则为数据库格式
        
        Returns:
            (rule_dict, ambiguity_reason) - 如果有歧义返回原因
        """
        # 1. 提取字段
        rule_id = raw_rule.get('ID')
        rule_type_cn = raw_rule.get('类型', '')
        condition1 = raw_rule.get('筛选条件1', '')
        condition2 = raw_rule.get('筛选条件2', '')
        result = raw_rule.get('结果', '')
        gender = raw_rule.get('性别', '')
        
        # 2. 转换类型
        rule_type = self.TYPE_MAPPING.get(rule_type_cn, rule_type_cn.lower())
        
        # 3. 解析条件
        conditions, ambiguity = self._parse_conditions(condition1, condition2, gender)
        if ambiguity:
            return None, f"ID {rule_id}: {ambiguity}"
        
        # 4. 构建规则
        rule = {
            'rule_code': f'FORMULA_{rule_type_cn}_{rule_id}',
            'rule_name': f'{rule_type_cn}规则-{rule_id}',
            'rule_type': rule_type,
            'conditions': conditions,
            'content': {'text': result},
            'description': {
                '筛选条件1': condition1,
                '筛选条件2': condition2,
                '性别': gender
            }
        }
        
        return rule, None
    
    def _parse_conditions(self, cond1: str, cond2: str, gender: str) -> Tuple[Dict, Optional[str]]:
        """解析条件文本为JSON格式"""
        conditions = {}
        
        # 解析性别
        if gender == '男':
            conditions['gender'] = 'male'
        elif gender == '女':
            conditions['gender'] = 'female'
        
        # 解析具体条件（根据实际规则格式实现）
        # ...
        
        return conditions, None


def import_rules(rules: List[Dict], dry_run: bool = False) -> Tuple[int, int, List[str]]:
    """
    导入规则到数据库
    
    Returns:
        (inserted, updated, ambiguous_rules)
    """
    inserted = 0
    updated = 0
    ambiguous = []
    
    if dry_run:
        print("=== DRY RUN 模式，不会修改数据库 ===\n")
    
    conn = get_mysql_connection()
    try:
        with conn.cursor() as cursor:
            for rule in rules:
                if dry_run:
                    print(f"将导入: {rule['rule_code']}")
                    continue
                
                # 检查是否存在
                cursor.execute(
                    "SELECT id FROM bazi_rules WHERE rule_code = %s",
                    (rule['rule_code'],)
                )
                existing = cursor.fetchone()
                
                if existing:
                    # 更新
                    cursor.execute("""
                        UPDATE bazi_rules SET
                            rule_name = %s,
                            rule_type = %s,
                            conditions = %s,
                            content = %s,
                            description = %s,
                            version = version + 1
                        WHERE rule_code = %s
                    """, (
                        rule['rule_name'],
                        rule['rule_type'],
                        json.dumps(rule['conditions'], ensure_ascii=False),
                        json.dumps(rule['content'], ensure_ascii=False),
                        json.dumps(rule['description'], ensure_ascii=False),
                        rule['rule_code']
                    ))
                    updated += 1
                else:
                    # 插入
                    cursor.execute("""
                        INSERT INTO bazi_rules 
                        (rule_code, rule_name, rule_type, conditions, content, description)
                        VALUES (%s, %s, %s, %s, %s, %s)
                    """, (
                        rule['rule_code'],
                        rule['rule_name'],
                        rule['rule_type'],
                        json.dumps(rule['conditions'], ensure_ascii=False),
                        json.dumps(rule['content'], ensure_ascii=False),
                        json.dumps(rule['description'], ensure_ascii=False)
                    ))
                    inserted += 1
            
            if not dry_run:
                conn.commit()
    finally:
        return_mysql_connection(conn)
    
    return inserted, updated, ambiguous


def main():
    parser = argparse.ArgumentParser(description='规则导入脚本')
    parser.add_argument('--dry-run', action='store_true', help='预览模式，不修改数据库')
    args = parser.parse_args()
    
    # 加载规则数据
    # ...
    
    # 导入规则
    inserted, updated, ambiguous = import_rules(rules, args.dry_run)
    
    print(f"\n=== 导入结果 ===")
    print(f"新增: {inserted} 条")
    print(f"更新: {updated} 条")
    print(f"歧义: {len(ambiguous)} 条")


if __name__ == '__main__':
    main()
```

---

## 🔄 问题复盘机制 【重要】

### 复盘流程

每次遇到问题后，必须完成以下步骤：

1. **问题记录**
   - 记录问题现象、错误信息、复现步骤
   - 记录问题发生时间、影响范围

2. **根因分析**
   - 分析问题根本原因（不是表面现象）
   - 检查是否违反开发规范
   - 检查是否有类似问题历史

3. **解决方案**
   - 实施修复方案
   - 验证修复效果
   - 确保不会再次出现

4. **规范更新**
   - 将问题复盘记录到开发规范
   - 更新相关检查清单
   - 添加预防措施

5. **代码审查**
   - 检查是否有类似代码需要修复
   - 确保所有相关代码都符合规范

### 复盘记录格式

```markdown
## 问题复盘：[问题标题] - YYYY-MM-DD

### 问题描述
- **现象**：具体问题表现
- **影响**：影响范围和严重程度
- **复现**：复现步骤

### 根因分析
- **直接原因**：表面原因
- **根本原因**：深层原因
- **规范违反**：违反了哪些开发规范

### 解决方案
- **修复内容**：具体修改
- **验证结果**：测试验证情况

### 预防措施
- **规范更新**：更新的规范内容
- **检查清单**：新增的检查项
- **代码审查**：需要检查的代码范围
```

---

## 🚨 常见问题与解决方案

### 问题复盘：生产环境服务崩溃和页面报错 - 2025-12-14

#### 问题描述
- **现象**：所有微服务容器持续重启，生产页面报错 500
- **影响**：全部服务中断，前端功能完全不可用
- **复现**：生产环境访问页面返回 500 错误

#### 根因分析
1. **直接原因**：
   - gRPC 代码兼容性问题：`add_registered_method_handlers` 方法不存在
   - 硬编码本地路径：`/Users/zhoudt/.../debug.log` 导致 FileNotFoundError
   - MySQL 密码配置问题：容器内环境变量为空
   - 容器代码未同步：proto 目录未挂载，使用镜像内旧代码

2. **根本原因**：
   - 代码生成工具版本与运行时版本不一致
   - 开发时使用了硬编码路径
   - 容器配置不完整，缺少代码目录挂载
   - 环境变量未正确传递到容器

3. **规范违反**：
   - ❌ 违反了路径配置规范（硬编码本地路径）
   - ❌ 违反了容器代码挂载规范（proto 目录未挂载）
   - ❌ 违反了 gRPC 兼容性规范（版本不一致）

#### 解决方案
1. **修复 gRPC 代码兼容性**：
   - 删除所有 `add_registered_method_handlers` 方法调用
   - 为所有微服务添加 proto 目录挂载

2. **修复硬编码路径**：
   - 移除所有硬编码本地路径的调试日志代码
   - 如需日志，使用动态路径并添加异常处理

3. **修复 MySQL 配置**：
   - 确保容器启动使用 `--env-file`
   - 验证环境变量正确加载

4. **确保代码一致性**：
   - 所有微服务容器挂载 proto、services、src 目录
   - 通过 Git 和容器挂载确保代码同步

#### 预防措施
1. **规范更新**：
   - ✅ 添加路径配置规范（禁止硬编码路径）
   - ✅ 添加容器代码挂载规范（必须挂载 proto 目录）
   - ✅ 添加 gRPC 兼容性规范（版本一致性）

2. **检查清单**：
   - [ ] 代码中无硬编码路径
   - [ ] 所有微服务容器挂载 proto 目录
   - [ ] gRPC 代码兼容性已验证
   - [ ] 环境变量正确传递到容器

3. **自动化工具**：
   - `scripts/grpc/fix_grpc_generated_code.py` - 自动修复 gRPC 代码
   - `scripts/grpc/verify_grpc_fix.sh` - 验证修复结果

---

### 问题复盘：十神命格规则匹配失败 - 2025-11-28

#### 问题描述
- **现象**：生日 1987-01-07 09:00 无法匹配十神命格规则
- **影响**：所有十神命格规则都无法匹配，影响规则分析功能
- **复现**：调用 `/bazi/formula-analysis` API，`shishen_count` 始终为 0

#### 根因分析
1. **直接原因**：
   - `formula_analysis.py` 中十神命格使用 `FormulaRuleService` 匹配
   - `FormulaRuleService` 期望旧格式（文本条件），但数据库规则已迁移为 JSON 格式
   - 规则条件格式问题：`hidden_stars_in_year` 包含文本描述（如"日柱副星有正财"）

2. **根本原因**：
   - 规则迁移后未统一匹配服务
   - 规则引擎未支持混合条件格式（文本描述+十神名称）
   - 缺少规则匹配的统一测试

3. **规范违反**：
   - ❌ 未使用统一的 `RuleService` 匹配规则
   - ❌ 规则条件格式不统一
   - ❌ 缺少规则匹配的验证测试

#### 解决方案
1. **修改 `formula_analysis.py`**：
   - 移除 `FormulaRuleService` 特殊处理
   - 统一使用 `RuleService` 匹配所有规则（包括十神命格）

2. **增强 `rule_condition.py`**：
   - 增强 `hidden_stars_in_*` 条件处理
   - 支持解析文本描述（如"日柱副星有正财"）并检查对应柱

#### 预防措施
1. **规范更新**：
   - ✅ 所有规则必须使用 `RuleService` 匹配
   - ✅ 规则条件格式必须统一为 JSON
   - ✅ 新增规则类型必须同步更新前后端

2. **检查清单**：
   - [ ] 新规则类型是否使用 `RuleService` 匹配
   - [ ] 规则条件格式是否符合 JSON 规范
   - [ ] 前后端是否同步支持新规则类型
   - [ ] 是否编写了规则匹配测试

3. **代码审查**：
   - 检查所有使用 `FormulaRuleService` 的代码
   - 检查规则条件格式是否统一
   - 检查规则匹配逻辑是否完整

---

### 问题1：数据库名配置错误

**症状**：`Unknown database 'bazi_system'`

**原因**：`server/config/mysql_config.py` 中默认数据库名不正确

**解决**：见下方"数据库配置默认值"规范

**预防**：检查 `env.template` 中的 `MYSQL_DATABASE` 值，确保默认值与实际数据库一致

---

### 问题2：规则ID包含中文导致解析失败

**症状**：
```
invalid literal for int() with base 10: '财富_20106'
```

**原因**：规则ID格式不统一（`FORMULA_80001` vs `FORMULA_财富_20106`）

**解决**：
```python
# 兼容两种格式
try:
    numeric_id = int(original_id)
except ValueError:
    parts = original_id.rsplit('_', 1)
    if len(parts) == 2 and parts[1].isdigit():
        numeric_id = int(parts[1])
    else:
        numeric_id = hash(original_id) % 1000000
```

**预防**：
- 导入时统一使用 `FORMULA_类型_编号` 格式
- 在数据库中保持 `rule_type` 字段为英文

---

### 问题3：规则类型不一致

**症状**：前端显示不出新增的规则类型（如事业、子女）

**原因**：数据库 `rule_type` 字段值不统一（`formula_career` vs `career`）

**解决**：见下方"规则类型命名"规范

**预防**：导入脚本中使用统一的英文类型名，不要使用 `formula_` 前缀

---

### 问题4：前端类型标签缺失

**症状**：前端页面没有显示新类型的标签页

**原因**：`local_frontend/formula-analysis.html` 中 `typeLabels` 未定义新类型

**解决**：在 `typeLabels` 中添加新类型映射（参考上方"类型映射"表格）

**预防**：新增规则类型时同步更新前端 `typeLabels` 和 `displayStatistics` 函数

---

### 问题5：新条件类型不支持

**症状**：规则无法匹配，日志显示条件未处理

**原因**：`rule_condition.py` 中未实现对应条件类型

**解决**：在 `EnhancedRuleCondition.match` 中添加条件处理逻辑

**预防**：
- 导入前检查所有条件类型是否已支持
- 不支持的条件先扩展规则引擎再导入

---

### 问题6：gRPC 端点未注册

**症状**：前端调用 API 返回错误或无响应

**原因**：`grpc_gateway.py` 中未注册对应端点

**解决**：
```python
# 在 grpc_gateway.py 中注册
@_register("/bazi/new-feature")
async def _handle_new_feature(payload: Dict[str, Any]):
    request_model = NewFeatureRequest(**payload)
    return await new_feature(request_model)
```

**预防**：
- 新增 API 时必须同时注册 gRPC 端点
- 测试时验证 gRPC-Web 调用是否正常

---

## 🔄 Redis缓存开发规范 【必须遵守】

### 🔴 核心原则

> **所有使用Redis缓存的模块必须遵循统一的缓存开发规范，确保数据一致性、性能和可维护性。**

### 📋 缓存架构

**多级缓存架构**：
```
用户请求
    ↓
【L1: 本地内存缓存】（最快，5分钟TTL）
    ├─ 缓存命中 → 直接返回（0个数据库连接）
    └─ 缓存未命中 → 继续
    ↓
【L2: Redis分布式缓存】（较快，24小时TTL）
    ├─ 缓存命中 → 回填L1 → 返回（0个数据库连接）
    └─ 缓存未命中 → 继续
    ↓
【L3: 数据库查询】（最慢，1个连接）
    ├─ 查询数据库
    └─ 写入L1和L2缓存
    ↓
返回结果
```

### 📝 缓存键设计规范

**命名格式**：
- 格式：`{模块名}:{功能名}:{参数1}:{参数2}:...`
- 示例：
  - `daily_fortune:calendar:2025-01-15:1990-05-15:12:00:male`
  - `daily_fortune:service:2025-01-15:1990-05-15:12:00:male:rule`

**设计原则**：
- ✅ 使用完整字符串，不使用MD5哈希（便于调试和清理）
- ✅ 参数按重要性排序（日期 > 用户信息 > 其他）
- ✅ 使用冒号分隔，保持层次清晰
- ✅ 空参数使用空字符串，不使用`None`

**实现示例**：
```python
@staticmethod
def _generate_cache_key(
    date_str: Optional[str],
    user_solar_date: Optional[str],
    user_solar_time: Optional[str],
    user_gender: Optional[str]
) -> str:
    """生成缓存键"""
    # 标准化参数
    date_key = date_str or date.today().strftime('%Y-%m-%d')
    user_solar_date = user_solar_date or ''
    user_solar_time = user_solar_time or ''
    user_gender = user_gender or ''
    
    # 生成键（使用完整字符串）
    key_parts = [
        'daily_fortune',
        'calendar',
        date_key,
        user_solar_date,
        user_solar_time,
        user_gender
    ]
    return ':'.join(key_parts)
```

### ⏰ TTL设置规范

**TTL选择原则**：
- **短期数据**（实时性要求高）：5-15分钟
- **中期数据**（每天变化）：24小时（86400秒）
- **长期数据**（很少变化）：7-30天

**每日运势缓存TTL**：
```python
# 每日运势每天变化，使用24小时TTL
CACHE_TTL = 86400  # 24小时
```

**实现示例**：
```python
# 使用自定义TTL
cache.l2.ttl = DailyFortuneCalendarService.CACHE_TTL
cache.set(cache_key, result)
# 恢复默认TTL
cache.l2.ttl = 3600
```

### 🔄 缓存失效机制

**失效方式**：
1. **自动失效**：TTL过期自动删除
2. **手动清理**：数据导入/更新时主动清理
3. **双机同步**：使用Redis发布/订阅同步失效事件

**实现示例**：
```python
@staticmethod
def invalidate_cache_for_date(target_date: Optional[str] = None):
    """使指定日期的缓存失效（支持双机同步）"""
    try:
        from server.utils.cache_multi_level import get_multi_cache
        from server.config.redis_config import get_redis_client
        
        # 1. 清理本地L1缓存
        cache = get_multi_cache()
        cache.l1.clear()
        
        # 2. 清理Redis缓存（支持pattern匹配）
        redis_client = get_redis_client()
        if redis_client:
            pattern = f"daily_fortune:calendar:{target_date or '*'}:*"
            # 使用SCAN迭代删除（避免阻塞）
            cursor = 0
            while True:
                cursor, keys = redis_client.scan(cursor, match=pattern, count=100)
                if keys:
                    redis_client.delete(*keys)
                if cursor == 0:
                    break
            
            # 3. 发布缓存失效事件（双机同步）
            redis_client.publish('cache:invalidate:daily_fortune', target_date or 'all')
    except Exception as e:
        print(f"⚠️  缓存失效操作失败（不影响业务）: {e}")
```

### 🔄 双机缓存同步机制

**同步流程**：
```
Node1 清理缓存
    ↓
发布Redis事件（cache:invalidate:daily_fortune）
    ↓
Node2 订阅器接收事件
    ↓
Node2 清理本地L1缓存
    ↓
同步完成
```

**实现方式**：
1. **发布端**：在 `invalidate_cache_for_date()` 中发布事件
2. **订阅端**：在服务启动时启动订阅器（`server/main.py`）

**订阅器实现**：
```python
# server/utils/cache_sync_subscriber.py
def _cache_sync_subscriber():
    """缓存同步订阅器（后台线程）"""
    redis_client = get_redis_client()
    pubsub = redis_client.pubsub()
    pubsub.subscribe('cache:invalidate:daily_fortune')
    
    for message in pubsub.listen():
        if message['type'] == 'message':
            target_date = message['data'].decode('utf-8')
            # 清理本地L1缓存
            cache.l1.clear()
```

**服务启动时初始化**：
```python
# server/main.py - lifespan函数
from server.utils.cache_sync_subscriber import start_cache_sync_subscriber
start_cache_sync_subscriber()
```

### 🛡️ 降级机制

**Redis不可用时的处理**：
- ✅ 自动降级到数据库查询
- ✅ 不影响业务功能
- ✅ 记录警告日志

**实现示例**：
```python
try:
    from server.utils.cache_multi_level import get_multi_cache
    cache = get_multi_cache()
    cached_result = cache.get(cache_key)
    if cached_result:
        return cached_result
except Exception as e:
    # Redis不可用，降级到数据库查询
    print(f"⚠️  Redis缓存不可用，降级到数据库查询: {e}")

# 继续执行数据库查询
result = _query_from_database(...)
```

### 📊 缓存使用检查清单

每次开发使用Redis缓存的功能时，必须检查：

- [ ] 缓存键格式是否符合规范（`模块名:功能名:参数`）
- [ ] TTL设置是否合理（根据数据变化频率）
- [ ] 是否实现了缓存失效机制（数据更新时清理）
- [ ] 是否支持双机同步（发布/订阅事件）
- [ ] 是否实现了降级机制（Redis不可用时）
- [ ] 是否在数据导入脚本中添加了缓存清理
- [ ] 是否测试了缓存命中/未命中场景
- [ ] 是否测试了缓存失效功能

### 🚨 常见问题

#### 问题1：缓存键冲突

**症状**：不同用户的缓存互相覆盖

**原因**：缓存键未包含用户标识

**解决**：在缓存键中包含所有影响结果的参数

#### 问题2：数据不一致

**症状**：数据更新后缓存未清理，用户看到旧数据

**原因**：数据导入/更新时未清理缓存

**解决**：在数据导入脚本中添加缓存清理逻辑

#### 问题3：Redis连接数不足

**症状**：`max_connections` 错误

**原因**：未使用连接池或连接池配置过小

**解决**：
```python
# server/config/redis_config.py
REDIS_CONFIG = {
    'max_connections': 100,  # 增加到100以支持更高并发
}
```

#### 问题4：双机缓存不同步

**症状**：Node1清理缓存后，Node2仍使用旧缓存

**原因**：未实现双机同步机制

**解决**：使用Redis发布/订阅机制同步缓存失效事件

### 📚 相关文件

| 文件 | 用途 |
|------|------|
| `server/utils/cache_multi_level.py` | 多级缓存管理器（L1内存 + L2 Redis） |
| `server/utils/cache_sync_subscriber.py` | 缓存同步订阅器（双机同步） |
| `server/config/redis_config.py` | Redis连接配置 |
| `server/services/daily_fortune_calendar_service.py` | 每日运势日历服务（缓存示例） |
| `server/services/daily_fortune_service.py` | 每日运势服务（缓存示例） |

### ✅ 最佳实践

1. **缓存键设计**：
   - 使用完整字符串，便于调试
   - 包含所有影响结果的参数
   - 保持层次清晰

2. **TTL设置**：
   - 根据数据变化频率选择
   - 每日变化的数据使用24小时TTL
   - 实时性要求高的数据使用短TTL

3. **缓存失效**：
   - 数据更新时立即清理相关缓存
   - 使用pattern匹配批量清理
   - 支持双机同步

4. **降级机制**：
   - Redis不可用时自动降级
   - 不影响业务功能
   - 记录警告日志

5. **性能优化**：
   - 优先使用L1内存缓存
   - L2 Redis缓存回填L1
   - 减少数据库查询次数

---

## 📁 项目架构

### 前端架构 `local_frontend/`
```
local_frontend/
├── js/
│   ├── api.js                  # gRPC-Web 客户端（核心）
│   ├── config.js               # API 配置
│   ├── fortune.js              # 运势数据逻辑
│   ├── fortune-timeline.js     # 运势 UI 渲染
│   └── ...
├── css/                        # 样式文件
└── *.html                      # 页面文件
```

**⚠️ 重要说明**：
- **`local_frontend/`** 是本地前端目录，用于本地开发、测试环境、双机部署
- **生产前端**由前端团队独立部署，不在此仓库中
- 所有配置文件和脚本必须使用 `local_frontend` 路径

### 后端架构 `server/`
```
server/
├── api/
│   ├── grpc_gateway.py         # gRPC-Web 网关（核心）
│   └── v1/                     # REST API
│       ├── formula_analysis.py # 算法公式分析
│       └── ...
├── services/                   # 业务逻辑
│   ├── rule_service.py         # 规则匹配服务
│   └── ...
├── engines/                    # 规则引擎
│   ├── rule_engine.py          # 核心引擎
│   └── rule_condition.py       # 条件匹配（扩展点）
├── config/
│   └── mysql_config.py         # MySQL 配置（注意默认值）
└── db/                         # 数据库连接
```

### 微服务架构 `services/`
```
services/
├── bazi_core/                  # 八字核心服务 (gRPC 9001)
├── bazi_fortune/               # 运势服务 (gRPC 9002)
├── bazi_analyzer/              # 八字分析 (gRPC 9003)
├── bazi_rule/                  # 规则匹配 (gRPC 9004)
├── fortune_analysis/           # 运势分析 (gRPC 9005)
├── payment_service/            # 支付服务 (gRPC 9006)
├── fortune_rule/               # 运势规则 (gRPC 9007)
├── intent_service/             # 意图识别 (gRPC 9008)
├── prompt_optimizer/           # 提示优化 (gRPC 9009)
└── desk_fengshui/              # 风水分析 (gRPC 9010)
```

**服务端口清单**：
| 服务 | 端口 | 用途 |
|------|------|------|
| Web 服务 | 8001 | HTTP + gRPC-Web 网关 |
| bazi-core | 9001 | 八字核心计算 |
| bazi-fortune | 9002 | 运势计算 |
| bazi-analyzer | 9003 | 八字分析 |
| bazi-rule | 9004 | 规则匹配 |
| fortune-analysis | 9005 | 运势分析 |
| payment | 9006 | 支付服务 |
| fortune-rule | 9007 | 运势规则 |
| intent | 9008 | 意图识别 |
| optimizer | 9009 | 提示优化 |
| desk-fengshui | 9010 | 风水分析 |

### 脚本目录 `scripts/`
```
scripts/
├── migration/                  # 数据迁移脚本
│   ├── import_2025_1128_rules.py   # 规则导入示例
│   └── import_confirmed_rules.py   # 确认规则导入
├── db/                         # 数据库脚本
│   └── sync_db.sh              # 数据库同步
└── ...
```

---

## 🔒 核心文件（修改前必须咨询）

| 文件 | 作用 | 风险 |
|------|------|------|
| `server/api/grpc_gateway.py` | gRPC-Web 网关 | 极高 |
| `server/engines/rule_condition.py` | 规则条件匹配 | 高 |
| `server/config/mysql_config.py` | MySQL 配置 | 高 |
| `src/bazi_calculator.py` | 核心八字计算 | 极高 |
| `local_frontend/js/api.js` | 前端 gRPC 客户端 | 高 |
| `proto/*.proto` | gRPC 协议定义 | 高 |

---

## 📁 路径配置规范 【必须遵守】

### 🔴 核心原则

> **禁止硬编码本地路径，所有路径必须基于项目根目录动态获取，确保跨平台兼容性。**

### 📋 禁止的操作

| 操作 | 状态 | 原因 | 正确方式 |
|------|------|------|---------|
| ❌ **硬编码本地路径** | **禁止** | 破坏跨平台兼容性，生产环境无法使用 | 使用动态路径 |
| ❌ **硬编码 Mac 路径** | **禁止** | 如 `/Users/zhoudt/...` | 基于项目根目录 |
| ❌ **硬编码 Windows 路径** | **禁止** | 如 `C:\Users\...` | 基于项目根目录 |
| ❌ **日志写入无异常处理** | **禁止** | 日志失败导致业务失败 | 添加异常处理 |

### ✅ 正确的路径配置方式

#### 1. 获取项目根目录

```python
import os

# ✅ 正确：基于当前文件路径获取项目根目录
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# ✅ 正确：使用 os.path.join 构建路径（跨平台兼容）
LOG_PATH = os.path.join(PROJECT_ROOT, 'logs', 'debug.log')
CONFIG_PATH = os.path.join(PROJECT_ROOT, 'config', 'app.ini')
```

#### 2. 文件操作必须有异常处理

```python
# ✅ 正确：添加异常处理，不影响业务
try:
    os.makedirs(os.path.dirname(LOG_PATH), exist_ok=True)
    with open(LOG_PATH, 'a') as f:
        f.write(log_message)
except Exception as e:
    logger.warning(f"日志写入失败（不影响业务）: {e}")
    # 或直接忽略：pass

# ❌ 错误：无异常处理，日志失败导致请求失败
with open('/Users/zhoudt/Downloads/project/HiFate-bazi/.cursor/debug.log', 'a') as f:
    f.write(log_message)  # 如果路径不存在，整个请求失败
```

#### 3. 调试日志不应影响业务

```python
# ✅ 正确：调试日志失败不影响业务
def debug_log(message: str):
    """调试日志（不影响业务）"""
    try:
        log_path = os.path.join(PROJECT_ROOT, 'logs', 'debug.log')
        os.makedirs(os.path.dirname(log_path), exist_ok=True)
        with open(log_path, 'a') as f:
            f.write(f"{datetime.now()} - {message}\n")
    except Exception:
        pass  # 忽略日志写入错误

# ✅ 推荐：使用标准日志库
import logging
logger = logging.getLogger(__name__)
logger.debug("调试信息")  # 自动处理路径和异常
```

### ✅ 路径配置检查清单

每次编写文件操作代码时，必须检查：

- [ ] 是否使用了硬编码路径（如 `/Users/...`、`C:\...`）
- [ ] 路径是否基于项目根目录动态获取
- [ ] 是否使用 `os.path.join` 构建路径（跨平台兼容）
- [ ] 文件操作是否有异常处理
- [ ] 日志写入失败是否会影响业务

### 🚨 常见错误示例

```python
# ❌ 错误示例 1：硬编码 Mac 路径
with open('/Users/zhoudt/Downloads/project/HiFate-bazi/.cursor/debug.log', 'a') as f:
    f.write(log_message)

# ❌ 错误示例 2：硬编码 Windows 路径
config_file = 'C:\\Users\\zhoudt\\project\\config.ini'

# ❌ 错误示例 3：无异常处理
with open(LOG_PATH, 'a') as f:  # 如果路径不存在，程序崩溃
    f.write(log_message)

# ✅ 正确示例
import os
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
LOG_PATH = os.path.join(PROJECT_ROOT, 'logs', 'debug.log')

try:
    os.makedirs(os.path.dirname(LOG_PATH), exist_ok=True)
    with open(LOG_PATH, 'a') as f:
        f.write(log_message)
except Exception:
    pass  # 忽略日志写入错误
```

---

## 🐳 容器代码挂载规范 【必须遵守】

### 🔴 核心原则

> **所有需要热更新的代码目录必须在容器中挂载，确保本地、容器、生产环境代码完全一致。**

### 📋 容器挂载要求

#### 必须挂载的目录

| 目录 | 容器内路径 | 挂载模式 | 说明 |
|------|-----------|---------|------|
| **proto** | `/app/proto` | `:ro` | gRPC 生成代码（必须！） |
| **services** | `/app/services` | `:ro` | 微服务代码 |
| **src** | `/app/src` | `:ro` | 核心计算代码 |
| **server** | `/app/server` | `:ro` | Web 服务代码 |

#### Docker Compose 标准配置

```yaml
volumes:
  - /opt/HiFate-bazi/proto:/app/proto:ro  # 必须挂载（gRPC 代码）
  - /opt/HiFate-bazi/services:/app/services:ro  # 微服务代码
  - /opt/HiFate-bazi/src:/app/src:ro  # 核心代码
  - /opt/HiFate-bazi/server:/app/server:ro  # Web 服务代码
```

**重要**：
- ✅ 所有微服务容器都必须挂载上述目录
- ✅ `proto` 目录挂载是**必须的**（gRPC 代码兼容性修复依赖于此）
- ✅ 使用 `:ro` 只读模式，防止容器内修改

### ✅ 容器挂载检查清单

每次部署前必须检查：

- [ ] Web 服务容器是否挂载了所有代码目录
- [ ] 所有微服务容器是否挂载了 `proto` 目录（**必须！**）
- [ ] 所有微服务容器是否挂载了 `services` 目录
- [ ] 所有微服务容器是否挂载了 `src` 目录
- [ ] 挂载路径是否正确（服务器路径 -> 容器路径）
- [ ] 挂载模式是否为 `:ro`（只读）

### 🔍 验证容器挂载

```bash
# 检查容器挂载
docker inspect hifate-bazi-core --format="{{range .Mounts}}{{.Source}} -> {{.Destination}}{{println}}{{end}}" | grep proto

# 验证容器内代码与服务器代码一致
docker exec hifate-bazi-core grep -c "add_registered_method_handlers" /app/proto/generated/bazi_core_pb2_grpc.py
# 应该返回 0（无问题代码）
```

---

## 🔧 微服务监听地址配置规范 【必须遵守】

### 🔴 核心原则

> **Docker 容器环境中的微服务必须监听所有接口（0.0.0.0 或 [::]），禁止使用 localhost，确保容器间可以通信。**

### 📋 监听地址配置要求

#### 1. Docker 容器环境（生产/测试）

**必须使用**：
- ✅ `[::]:{port}` - 支持 IPv4 和 IPv6（推荐）
- ✅ `0.0.0.0:{port}` - 仅 IPv4（也可用）

**禁止使用**：
- ❌ `localhost:{port}` - 只监听容器内部，其他容器无法连接
- ❌ `127.0.0.1:{port}` - 只监听容器内部，其他容器无法连接

**原因**：
- Docker 容器使用独立的网络命名空间
- `localhost` 只监听容器内部接口
- 其他容器需要通过容器网络接口连接
- 必须监听 `0.0.0.0` 或 `[::]` 才能被其他容器访问

#### 2. 本地开发环境

**可以使用**：
- ✅ `localhost:{port}` - 本地开发可用
- ✅ `0.0.0.0:{port}` - 推荐，保持一致性
- ✅ `[::]:{port}` - 推荐，支持 IPv4 和 IPv6

**建议**：
- 统一使用 `[::]:{port}` 保持环境一致性

#### 3. 配置方式

**使用环境变量**：
```python
import os

# 从环境变量读取监听地址
SERVICE_HOST = os.getenv("SERVICE_HOST", "[::]")  # 默认 [::]
listen_addr = f"{SERVICE_HOST}:{port}"
```

**直接配置**：
```python
# ✅ 正确：Docker 容器环境
listen_addr = f"[::]:{port}"  # 支持 IPv4 和 IPv6

# ❌ 错误：Docker 容器环境
listen_addr = f"localhost:{port}"  # 其他容器无法连接
```

### ✅ 微服务监听地址检查清单

每次开发新微服务时，必须检查：

- [ ] 监听地址是否使用 `[::]` 或 `0.0.0.0`（Docker 环境）
- [ ] 是否支持通过环境变量配置监听地址
- [ ] 是否在 Docker Compose 中正确配置服务地址
- [ ] 是否测试了容器间连接
- [ ] 是否验证了服务可以被其他容器访问

### 🚨 常见错误

#### 错误 1：使用 localhost 监听

**症状**：
- 服务启动成功，但其他容器无法连接
- gRPC 客户端返回 `StatusCode.UNAVAILABLE`
- 错误信息：`认证服务错误: StatusCode.UNAVAILABLE`

**原因**：
```python
# ❌ 错误：使用 localhost
listen_addr = f"localhost:{port}"
```

**解决**：
```python
# ✅ 正确：使用 [::]
listen_addr = f"[::]:{port}"
```

#### 错误 2：未配置环境变量

**症状**：
- 本地开发正常，但 Docker 容器中失败
- 服务无法被其他容器访问

**原因**：
- 硬编码监听地址，未考虑不同环境

**解决**：
```python
# ✅ 正确：使用环境变量
SERVICE_HOST = os.getenv("SERVICE_HOST", "[::]")
listen_addr = f"{SERVICE_HOST}:{port}"
```

### 📝 标准配置模板

**微服务 gRPC 服务器标准配置**：

```python
def serve(port: int = 9001):
    """启动 gRPC 服务器（支持热更新）"""
    import os
    
    # 从环境变量读取监听地址（默认 [::]）
    SERVICE_HOST = os.getenv("SERVICE_HOST", "[::]")
    listen_addr = f"{SERVICE_HOST}:{port}"
    
    # 创建服务器
    server, reloader = create_hot_reload_server(
        service_name="my_service",
        module_path="services.my_service.grpc_server",
        servicer_class_name="MyServiceServicer",
        add_servicer_to_server_func=my_service_pb2_grpc.add_MyServiceServicer_to_server,
        port=port,
        listen_addr=listen_addr,  # 使用配置的地址
        server_options=server_options
    )
    
    # 启动服务器
    server.start()
    print(f"🚀 my-service 启动成功: {listen_addr}", flush=True)
    server.wait_for_termination()
```

### 🔍 验证监听地址

**检查服务监听地址**：
```bash
# 检查容器内服务监听地址
docker exec hifate-auth-service netstat -tlnp | grep 9011

# 应该显示：
# tcp6       0      0 :::9011                 :::*                    LISTEN
# 或
# tcp        0      0 0.0.0.0:9011            0.0.0.0:*               LISTEN
```

**测试容器间连接**：
```bash
# 从 Web 服务容器测试连接认证服务
docker exec hifate-web python -c "
import grpc
import sys
sys.path.insert(0, '/app/proto/generated')
import auth_pb2, auth_pb2_grpc
channel = grpc.insecure_channel('auth-service:9011')
stub = auth_pb2_grpc.AuthServiceStub(channel)
response = stub.HealthCheck(auth_pb2.HealthCheckRequest(), timeout=5.0)
print('✅ 连接成功:', response.status)
"
```

### 📚 相关文档

- **问题复盘**：`docs/问题复盘-认证服务UNAVAILABLE错误.md`
- **Docker 网络文档**：https://docs.docker.com/network/

---

**核心要点**：
- 🔴 **Docker 容器环境必须使用 `[::]` 或 `0.0.0.0` 监听**
- ✅ **禁止使用 `localhost` 在容器环境中监听**
- 📋 **所有新微服务必须遵守监听地址配置规范**
- 🔍 **部署前必须验证容器间连接**

---

## 🔧 gRPC 代码兼容性规范 【必须遵守】

### 🔴 核心原则

> **gRPC 代码生成工具版本必须与运行时版本一致，生成的代码必须在目标版本中验证可用。**

### 📋 兼容性要求

#### 1. 版本一致性

| 组件 | 要求 | 说明 |
|------|------|------|
| **grpcio** | 与 requirements.txt 一致 | 运行时库版本 |
| **grpcio-tools** | 与 grpcio 版本一致 | 代码生成工具版本 |
| **生成代码** | 在目标版本中可用 | 验证兼容性 |

#### 2. 不兼容方法处理

**已知不兼容方法**：
- `add_registered_method_handlers()` - 在 grpcio 1.60.0-1.70.0 中不存在

**修复方法**：
```bash
# 自动修复脚本
python3 scripts/grpc/fix_grpc_generated_code.py

# 手动修复（删除不兼容方法调用）
find proto/generated -name "*_pb2_grpc.py" -exec sed -i "/server.add_registered_method_handlers/d" {} \;
```

#### 3. 代码生成流程

```bash
# 1. 生成 gRPC 代码
python -m grpc_tools.protoc --python_out=. --grpc_python_out=. proto/*.proto

# 2. 修复兼容性问题
python3 scripts/grpc/fix_grpc_generated_code.py

# 3. 验证修复
bash scripts/grpc/verify_grpc_fix.sh
```

### ✅ gRPC 兼容性检查清单

每次生成或更新 gRPC 代码时，必须检查：

- [ ] grpcio 版本与 requirements.txt 一致
- [ ] grpcio-tools 版本与 grpcio 版本一致
- [ ] 生成的代码中无 `add_registered_method_handlers` 方法调用
- [ ] 运行修复脚本验证兼容性
- [ ] 容器内代码已同步（通过挂载验证）

### 🚨 常见问题

#### 问题 1：版本不匹配

**症状**：`AttributeError: '_Server' object has no attribute 'add_registered_method_handlers'`

**原因**：生成代码使用了新版本方法，但运行时库版本不支持

**解决**：
1. 删除不兼容的方法调用
2. 运行修复脚本
3. 验证修复结果

---

## 🔧 环境变量配置规范 【必须遵守】

### 🔴 核心原则

> **容器启动必须使用 --env-file 传递环境变量，确保关键配置（如密码）正确加载。**

### 📋 环境变量传递要求

#### 1. Docker Compose 标准配置

```bash
# ✅ 正确：使用 --env-file 传递环境变量
docker-compose -f docker-compose.prod.yml -f docker-compose.node1.yml \
  --env-file /opt/HiFate-bazi/.env up -d web

# ❌ 错误：不使用 --env-file
docker-compose up -d web  # 环境变量未加载
```

#### 2. 环境变量验证

**启动后必须验证**：
```bash
# 检查关键环境变量是否正确加载
docker exec hifate-web env | grep -E "MYSQL_PASSWORD|MYSQL_USER|MYSQL_HOST"

# 应该显示：
# MYSQL_PASSWORD=Yuanqizhan@163
# MYSQL_USER=root
# MYSQL_HOST=mysql
```

#### 3. 重启容器注意事项

**重要**：修改环境变量后必须重新创建容器：
```bash
# ✅ 正确：重新创建容器以应用新环境变量
docker-compose -f docker-compose.prod.yml -f docker-compose.node1.yml \
  --env-file /opt/HiFate-bazi/.env up -d --force-recreate web

# ❌ 错误：仅重启容器，环境变量不会更新
docker-compose restart web  # 环境变量不更新
```

### ✅ 环境变量配置检查清单

每次部署前必须检查：

- [ ] 容器启动是否使用 `--env-file` 参数
- [ ] 环境变量文件路径是否正确（`.env` 文件存在）
- [ ] 关键环境变量是否正确加载（如 MYSQL_PASSWORD）
- [ ] 修改环境变量后是否重新创建了容器

### 🚨 常见问题

#### 问题：MySQL 连接失败 - Access denied

**症状**：`Access denied for user 'root'@'xxx' (using password: NO)`

**原因**：容器内 `MYSQL_PASSWORD` 环境变量为空

**解决**：
1. 检查 `.env` 文件是否存在且包含 `MYSQL_PASSWORD`
2. 确保容器启动使用 `--env-file`
3. 重新创建容器：`docker-compose up -d --force-recreate web`
4. 验证环境变量：`docker exec hifate-web env | grep MYSQL_PASSWORD`

---

## 🔐 安全规范 【必须遵守】

### 🔴 安全开发原则

> **安全是最高优先级，所有代码必须遵循安全最佳实践。**

| 原则 | 要求 | 说明 |
|------|------|------|
| **最小权限** | ✅ 必须 | 只授予必要的权限，禁止过度授权 |
| **输入验证** | ✅ 必须 | 所有用户输入必须验证和过滤 |
| **输出编码** | ✅ 必须 | 所有输出必须正确编码，防止 XSS |
| **敏感数据保护** | ✅ 必须 | 密码、密钥、Token 等必须加密存储 |
| **错误处理** | ✅ 必须 | 不暴露系统内部信息给用户 |
| **依赖安全** | ✅ 必须 | 定期更新依赖，修复已知漏洞 |

---

### 🛡️ 常见安全漏洞防护

#### 1. SQL 注入防护 【高危】

**禁止**：
```python
# ❌ 错误：直接拼接 SQL
query = f"SELECT * FROM users WHERE id = {user_id}"
cursor.execute(query)

# ❌ 错误：使用 % 格式化
cursor.execute("SELECT * FROM users WHERE name = '%s'" % user_name)
```

**正确做法**：
```python
# ✅ 正确：使用参数化查询
cursor.execute("SELECT * FROM users WHERE id = %s", (user_id,))
cursor.execute("SELECT * FROM users WHERE name = %s AND age = %s", (user_name, age))

# ✅ 正确：使用 ORM（SQLAlchemy）
from server.config.mysql_config import get_mysql_connection
with get_mysql_connection() as conn:
    result = conn.execute(
        text("SELECT * FROM users WHERE id = :id"),
        {"id": user_id}
    )
```

**检查清单**：
- [ ] 所有 SQL 查询使用参数化
- [ ] 禁止字符串拼接构建 SQL
- [ ] 使用 ORM 或参数化查询接口

---

#### 2. XSS（跨站脚本攻击）防护 【高危】

**禁止**：
```python
# ❌ 错误：直接输出用户输入
return f"<div>{user_input}</div>"

# ❌ 错误：在 JavaScript 中直接嵌入
return f"<script>var data = '{user_data}';</script>"
```

**正确做法**：
```python
# ✅ 正确：使用模板引擎自动转义（FastAPI + Jinja2）
from fastapi.templating import Jinja2Templates
templates = Jinja2Templates(directory="templates")
return templates.TemplateResponse("page.html", {
    "request": request,
    "user_input": user_input  # 自动转义
})

# ✅ 正确：手动转义（如需要）
import html
safe_output = html.escape(user_input)

# ✅ 正确：JSON 输出（自动转义）
from fastapi.responses import JSONResponse
return JSONResponse({"data": user_input})  # 自动转义
```

**前端防护**：
```javascript
// ✅ 正确：使用 textContent 而不是 innerHTML
element.textContent = userInput;

// ✅ 正确：使用 DOMPurify 清理 HTML
import DOMPurify from 'dompurify';
element.innerHTML = DOMPurify.sanitize(userInput);
```

**检查清单**：
- [ ] 所有用户输入在输出前转义
- [ ] 使用模板引擎自动转义
- [ ] 前端使用安全的 DOM 操作方式

---

#### 3. CSRF（跨站请求伪造）防护 【高危】

**后端防护**：
```python
# ✅ 正确：使用 CSRF Token（FastAPI）
from fastapi_csrf_protect import CsrfProtect
from fastapi_csrf_protect.exceptions import CsrfProtectError

@router.post("/api/v1/sensitive-action")
async def sensitive_action(
    request: Request,
    csrf_protect: CsrfProtect = Depends()
):
    await csrf_protect.validate_csrf(request)
    # 处理请求
    ...

# ✅ 正确：检查 Referer 头
referer = request.headers.get("referer")
if not referer or not referer.startswith("https://yourdomain.com"):
    raise HTTPException(status_code=403, detail="Invalid referer")
```

**前端防护**：
```javascript
// ✅ 正确：从后端获取 CSRF Token
const csrfToken = await fetch('/api/csrf-token').then(r => r.json());

// ✅ 正确：在请求头中携带 Token
fetch('/api/v1/sensitive-action', {
    method: 'POST',
    headers: {
        'X-CSRF-Token': csrfToken,
        'Content-Type': 'application/json'
    },
    body: JSON.stringify(data)
});
```

**检查清单**：
- [ ] 所有修改操作需要 CSRF Token
- [ ] 验证 Referer 头（可选，作为额外保护）
- [ ] 使用 SameSite Cookie 属性

---

#### 4. 敏感信息泄露防护 【高危】

**禁止**：
```python
# ❌ 错误：在错误信息中暴露系统信息
except Exception as e:
    return {"error": f"Database error: {str(e)}"}  # 暴露数据库结构

# ❌ 错误：在日志中记录敏感信息
logger.info(f"User login: {username}, password: {password}")

# ❌ 错误：在响应中返回敏感字段
return {"user": {"id": 1, "password": "hashed_password", "api_key": "xxx"}}
```

**正确做法**：
```python
# ✅ 正确：通用错误信息
except Exception as e:
    logger.error(f"Database error: {e}", exc_info=True)  # 记录详细日志
    return {"error": "操作失败，请稍后重试"}  # 用户友好的错误信息

# ✅ 正确：不记录敏感信息
logger.info(f"User login: {username}")  # 不记录密码

# ✅ 正确：过滤敏感字段
def sanitize_user_data(user):
    return {
        "id": user.id,
        "username": user.username,
        # 不返回 password, api_key 等敏感字段
    }
```

**环境变量保护**：
```python
# ✅ 正确：使用环境变量，不提交到代码库
import os
from dotenv import load_dotenv

load_dotenv()
SECRET_KEY = os.getenv("SECRET_KEY")  # 从 .env 读取
DATABASE_PASSWORD = os.getenv("MYSQL_PASSWORD")

# ❌ 错误：硬编码密钥
SECRET_KEY = "my-secret-key-12345"  # 禁止！
```

**检查清单**：
- [ ] 错误信息不暴露系统内部信息
- [ ] 日志不记录密码、Token 等敏感信息
- [ ] API 响应不返回敏感字段
- [ ] 所有密钥使用环境变量，不提交到代码库

---

#### 5. 身份认证与授权防护 【高危】

**密码安全**：
```python
# ✅ 正确：使用 bcrypt 加密密码
import bcrypt

def hash_password(password: str) -> str:
    salt = bcrypt.gensalt()
    hashed = bcrypt.hashpw(password.encode('utf-8'), salt)
    return hashed.decode('utf-8')

def verify_password(password: str, hashed: str) -> bool:
    return bcrypt.checkpw(password.encode('utf-8'), hashed.encode('utf-8'))

# ❌ 错误：明文存储密码
user.password = password  # 禁止！
```

**Token 安全**：
```python
# ✅ 正确：使用 JWT，设置过期时间
import jwt
from datetime import datetime, timedelta

def generate_token(user_id: int) -> str:
    payload = {
        "user_id": user_id,
        "exp": datetime.utcnow() + timedelta(hours=24),  # 24小时过期
        "iat": datetime.utcnow()
    }
    return jwt.encode(payload, SECRET_KEY, algorithm="HS256")

# ✅ 正确：验证 Token
def verify_token(token: str) -> dict:
    try:
        payload = jwt.decode(token, SECRET_KEY, algorithms=["HS256"])
        return payload
    except jwt.ExpiredSignatureError:
        raise HTTPException(status_code=401, detail="Token 已过期")
    except jwt.InvalidTokenError:
        raise HTTPException(status_code=401, detail="无效的 Token")
```

**权限检查**：
```python
# ✅ 正确：每个操作都检查权限
@router.post("/api/v1/admin/delete-user")
async def delete_user(user_id: int, current_user: User = Depends(get_current_user)):
    # 检查是否为管理员
    if not current_user.is_admin:
        raise HTTPException(status_code=403, detail="权限不足")
    
    # 执行删除操作
    ...
```

**检查清单**：
- [ ] 密码必须加密存储（bcrypt/argon2）
- [ ] Token 设置合理的过期时间
- [ ] 所有敏感操作验证用户身份
- [ ] 所有操作检查用户权限

---

#### 6. 文件上传安全防护 【高危】

**禁止**：
```python
# ❌ 错误：不验证文件类型
@router.post("/upload")
async def upload(file: UploadFile):
    content = await file.read()
    with open(f"uploads/{file.filename}", "wb") as f:
        f.write(content)  # 危险！可能上传恶意文件
```

**正确做法**：
```python
# ✅ 正确：验证文件类型和大小
from fastapi import UploadFile, File
import magic  # 或使用 python-magic

ALLOWED_MIME_TYPES = ["image/jpeg", "image/png", "image/webp"]
MAX_FILE_SIZE = 10 * 1024 * 1024  # 10MB

@router.post("/upload")
async def upload(file: UploadFile = File(...)):
    # 1. 检查文件大小
    content = await file.read()
    if len(content) > MAX_FILE_SIZE:
        raise HTTPException(status_code=400, detail="文件过大")
    
    # 2. 验证文件类型（使用 MIME 类型，不依赖扩展名）
    mime_type = magic.from_buffer(content, mime=True)
    if mime_type not in ALLOWED_MIME_TYPES:
        raise HTTPException(status_code=400, detail="不支持的文件类型")
    
    # 3. 生成安全的文件名（防止路径遍历）
    import uuid
    import os
    safe_filename = f"{uuid.uuid4()}.{mime_type.split('/')[1]}"
    safe_path = os.path.join("uploads", safe_filename)
    
    # 4. 保存文件
    with open(safe_path, "wb") as f:
        f.write(content)
    
    return {"filename": safe_filename}
```

**检查清单**：
- [ ] 验证文件 MIME 类型（不依赖扩展名）
- [ ] 限制文件大小
- [ ] 生成安全的文件名（防止路径遍历）
- [ ] 文件存储在隔离目录，不在 Web 根目录

---

#### 7. API 限流防护 【中危】

**防止暴力破解和 DDoS**：
```python
# ✅ 正确：使用 slowapi 限流
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address
from slowapi.errors import RateLimitExceeded

limiter = Limiter(key_func=get_remote_address)

@router.post("/api/v1/login")
@limiter.limit("5/minute")  # 每分钟最多 5 次
async def login(request: Request):
    # 登录逻辑
    ...

@router.post("/api/v1/bazi/calculate")
@limiter.limit("100/hour")  # 每小时最多 100 次
async def calculate_bazi(request: Request):
    # 计算逻辑
    ...
```

**检查清单**：
- [ ] 登录接口设置严格限流（如 5次/分钟）
- [ ] 计算接口设置合理限流（如 100次/小时）
- [ ] 使用 IP 地址作为限流键

---

#### 8. 依赖安全更新 【中危】

**定期检查依赖漏洞**：
```bash
# ✅ 使用安全扫描工具
pip install safety
safety check

# ✅ 使用 pip-audit（Python 官方推荐）
pip install pip-audit
pip-audit

# ✅ 定期更新依赖
pip list --outdated
pip install --upgrade package_name
```

**检查清单**：
- [ ] 每月检查一次依赖漏洞
- [ ] 及时更新有安全漏洞的依赖
- [ ] 使用 `requirements.txt` 固定版本号
- [ ] 记录依赖更新日志

---

#### 9. 日志安全 【中危】

**禁止记录敏感信息**：
```python
# ❌ 错误：记录敏感信息
logger.info(f"User {username} login with password {password}")
logger.debug(f"API Key: {api_key}")

# ✅ 正确：不记录敏感信息
logger.info(f"User {username} login successful")
logger.debug(f"API Key: {api_key[:10]}...")  # 只记录部分
```

**日志访问控制**：
```python
# ✅ 正确：日志文件权限控制
# 日志文件只允许应用用户访问
chmod 600 logs/app.log
chown app:app logs/app.log
```

**检查清单**：
- [ ] 日志不包含密码、Token、API Key
- [ ] 日志文件权限设置为 600
- [ ] 定期清理旧日志
- [ ] 生产环境日志级别设置为 WARNING 或 ERROR

---

#### 10. 配置安全 【中危】

**环境变量管理**：
```python
# ✅ 正确：使用 .env 文件（不提交到代码库）
# .env 文件添加到 .gitignore
# .env.example 作为模板提交

# .env.example
SECRET_KEY=your-secret-key-here
MYSQL_PASSWORD=your-password-here
REDIS_PASSWORD=your-redis-password

# .env（不提交）
SECRET_KEY=actual-secret-key-12345
MYSQL_PASSWORD=actual-password-12345
```

**配置文件安全**：
```python
# ✅ 正确：敏感配置从环境变量读取
import os
from dotenv import load_dotenv

load_dotenv()
SECRET_KEY = os.getenv("SECRET_KEY")
if not SECRET_KEY:
    raise ValueError("SECRET_KEY 环境变量未设置")

# ❌ 错误：硬编码配置
SECRET_KEY = "hardcoded-secret-key"  # 禁止！
```

**检查清单**：
- [ ] `.env` 文件添加到 `.gitignore`
- [ ] 提供 `.env.example` 作为模板
- [ ] 所有敏感配置从环境变量读取
- [ ] 生产环境使用强密码和密钥

---

### 🔍 安全代码审查清单

每次提交代码前，必须检查：

#### 输入验证
- [ ] 所有用户输入都经过验证
- [ ] 验证数据类型、长度、格式
- [ ] 禁止直接使用用户输入构建 SQL/命令

#### 输出编码
- [ ] 所有输出都正确编码
- [ ] 防止 XSS 攻击
- [ ] JSON 输出使用 `ensure_ascii=False` 时确保安全

#### 身份认证
- [ ] 密码加密存储
- [ ] Token 设置过期时间
- [ ] 敏感操作验证用户身份

#### 权限控制
- [ ] 每个操作检查用户权限
- [ ] 防止越权访问
- [ ] 使用最小权限原则

#### 错误处理
- [ ] 不暴露系统内部信息
- [ ] 记录详细错误日志（服务器端）
- [ ] 返回用户友好的错误信息

#### 依赖安全
- [ ] 定期检查依赖漏洞
- [ ] 及时更新有安全问题的依赖
- [ ] 使用固定版本号

---

### 🚨 安全事件响应

#### 发现安全漏洞时

1. **立即处理**
   - 评估漏洞严重程度（高危/中危/低危）
   - 立即修复或临时禁用相关功能
   - 通知相关人员

2. **修复流程**
   - 创建修复分支：`git checkout -b security/fix-xxx-vulnerability`
   - 修复漏洞并编写测试
   - 代码审查（重点关注安全性）
   - 合并到主分支并部署

3. **记录与复盘**
   - 记录漏洞详情和修复方案
   - 更新安全规范，防止类似问题
   - 检查是否有其他类似问题

---

### 📚 安全资源

- **OWASP Top 10**：https://owasp.org/www-project-top-ten/
- **Python 安全最佳实践**：https://python.readthedocs.io/en/latest/library/security.html
- **FastAPI 安全文档**：https://fastapi.tiangolo.com/tutorial/security/

---

**安全开发核心原则**：
- 🔒 **默认拒绝**：默认情况下拒绝所有访问，只允许明确授权的操作
- 🔍 **深度防御**：多层安全防护，不依赖单一安全措施
- 🛡️ **最小权限**：只授予必要的权限，禁止过度授权
- 📝 **安全审计**：定期审查代码和配置，及时发现安全问题
- 🚨 **快速响应**：发现安全问题立即处理，不拖延

## 🏠 办公桌风水模块（核心模块，禁止随意修改）

### ⚠️ 重要说明

**办公桌风水模块（`services/desk_fengshui/`）是稳定运行的核心功能模块，除非用户明确要求，否则禁止修改此模块的任何代码、规则或配置。**

### 模块配置

**技术栈**：
- **YOLO版本**：YOLOv8（不是YOLOv5）
- **库**：`ultralytics>=8.0.0`
- **模型文件**：`yolov8n.pt`（YOLOv8 nano版本）
- **置信度阈值**：0.15
- **备用方案**：OpenCV（当YOLO未安装时）

**核心文件**：
- `services/desk_fengshui/item_detector.py` - 物品检测器（YOLOv8）
- `services/desk_fengshui/rule_engine.py` - 风水规则引擎
- `services/desk_fengshui/position_calculator.py` - 方位计算器
- `services/desk_fengshui/analyzer.py` - 主分析器
- `services/desk_fengshui/bazi_client.py` - 八字客户端
- `services/desk_fengshui/requirements.txt` - 依赖配置

**规则系统**：
- 规则存储在MySQL数据库（`desk_fengshui_rules`表）
- 包含青龙位、白虎位、朱雀位、玄武位等传统风水规则
- 结合八字喜用神、忌神进行个性化分析

**修改原则**：
1. ❌ **禁止修改**：除非用户明确要求
2. ✅ **允许操作**：查看、测试、调试
3. ⚠️ **修改前必须**：先咨询用户，说明影响范围
4. 🔒 **保护范围**：所有 `services/desk_fengshui/` 目录下的文件

---

## 📝 代码规范

### 数据库配置默认值
```python
# ✅ 正确：使用实际的数据库名
'database': os.getenv('MYSQL_DATABASE', 'hifate_bazi'),

# ❌ 错误：使用过时的数据库名
'database': os.getenv('MYSQL_DATABASE', 'bazi_system'),
```
**相关错误**：见"问题1：数据库名配置错误"

### JSON 序列化
```python
# ✅ 正确：支持中文
json.dumps(data, ensure_ascii=False)

# ❌ 错误：中文被转义
json.dumps(data)  # 输出 \u4e2d\u6587
```

### 规则类型命名
```python
# ✅ 正确：使用英文小写（参考上方"类型映射"表格）
rule_type = 'career'
rule_type = 'children'

# ❌ 错误：使用中文或带前缀
rule_type = '事业'
rule_type = 'formula_career'  # 不要使用 formula_ 前缀
```
**相关错误**：见"问题3：规则类型不一致"、"问题4：前端类型标签缺失"

---

## 🚀 CI/CD 标准流程 【必须遵守】

### 🔴 核心原则

> **所有部署必须遵循标准 CI/CD 流程，禁止在服务器上直接构建镜像。**

### 📋 标准流程

```
本地开发 → 推送到 GitHub → GitHub Actions 构建镜像 → 推送到 GHCR → 服务器拉取镜像部署
```

| 步骤 | 操作 | 说明 |
|------|------|------|
| **1. 本地开发** | 在本地 Mac 开发 | 修改代码、测试 |
| **2. 推送到 GitHub** | `git push origin master` | 触发 CI/CD |
| **3. 自动构建镜像** | GitHub Actions 执行 | `.github/workflows/build-and-push.yml` |
| **4. 推送到 GHCR** | 自动推送到 GitHub Container Registry | 镜像标签：`ghcr.io/owner/repo/hifate-bazi:master` |
| **5. 服务器拉取部署** | 服务器从 GHCR 拉取镜像 | `.github/workflows/deploy-test.yml` 自动部署 |

### 🔧 工作流文件

| 文件 | 功能 | 触发条件 |
|------|------|---------|
| `.github/workflows/build-and-push.yml` | 构建镜像并推送到 GHCR | 推送到 `master` 或 `develop` 分支 |
| `.github/workflows/deploy-test.yml` | 部署到测试环境 | 推送到 `master` 分支 |
| `.github/workflows/deploy-production.yml` | 部署到生产环境 | 推送到 `master` 分支（手动触发） |

### ✅ 标准流程检查清单

每次部署前必须检查：

- [ ] 代码已推送到 GitHub
- [ ] GitHub Actions 构建成功
- [ ] 镜像已推送到 GHCR
- [ ] 服务器成功拉取镜像
- [ ] 健康检查通过

### 🚫 禁止的操作

| 操作 | 原因 | 正确方式 |
|------|------|---------|
| ❌ 在服务器上构建镜像 | 占用服务器资源、构建慢 | 使用 GitHub Actions 构建 |
| ❌ 手动上传镜像文件 | 不标准、容易出错 | 使用 GHCR 自动推送 |
| ❌ 直接修改服务器代码 | 无法版本控制 | 推送到 GitHub，自动部署 |

### 📝 部署命令

**测试环境部署**（自动）：
```bash
# 1. 本地开发完成后
git add .
git commit -m "feat: 新功能"
git push origin master

# 2. GitHub Actions 自动执行：
#    - build-and-push.yml: 构建镜像并推送到 GHCR
#    - deploy-test.yml: 部署到测试服务器 (123.57.216.15)
```

**生产环境部署**（手动触发）：
```bash
# 1. 在 GitHub Actions 页面手动触发 deploy-production.yml
# 2. 或推送到 master 分支后，在 Actions 页面手动触发
```

### 🔍 故障排查

**如果部署失败**：
1. 查看 GitHub Actions 日志
2. 检查镜像是否成功推送到 GHCR
3. 检查服务器 SSH 连接
4. 检查服务器磁盘空间
5. 查看服务器日志：`docker compose logs --tail=100`

---

## 🚀 增量部署规范 【必须遵守】

### 🔴 核心原则

> **增量部署通过热更新实现零停机快速部署，适用于日常代码更新，必须经过完整的安全检查。**

### 📋 增量部署 vs 完整部署对比

| 对比项 | 完整部署（CI/CD） | 增量部署（热更新） |
|--------|------------------|-------------------|
| **构建镜像** | ✅ 需要（GitHub Actions 构建） | ❌ 不需要（直接使用代码） |
| **容器重启** | ✅ 需要（`docker-compose up -d`） | ❌ 不需要（热更新） |
| **服务中断** | ⚠️ 可能有短暂中断（滚动更新） | ✅ 零中断 |
| **部署速度** | 慢（8-15分钟） | 快（30秒-2分钟） |
| **适用场景** | 首次部署、依赖变更、Dockerfile 变更 | 日常代码更新、规则更新 |
| **资源消耗** | 高（构建镜像、网络传输） | 低（仅代码更新） |
| **回滚速度** | 慢（拉取旧镜像+重启） | 快（热更新回滚，秒级） |

### 🎯 适用场景判断

#### ✅ 使用增量部署的场景

1. **Python 代码更新**
   - 业务逻辑修改
   - Bug 修复
   - 性能优化

2. **规则更新**
   - 数据库规则变更
   - 配置更新
   - 环境变量更新

3. **微服务代码修改**
   - 微服务逻辑更新
   - 服务间调用优化

4. **日常迭代**
   - 快速发布
   - 频繁更新

#### ❌ 必须使用完整部署的场景

1. **依赖变更**
   - 修改 `requirements.txt`
   - 新增 Python 包
   - 需要重建镜像

2. **Dockerfile 变更**
   - 修改构建流程
   - 修改基础镜像
   - 需要重新构建

3. **首次部署**
   - 需要构建完整镜像
   - 需要安装所有依赖

4. **重大架构变更**
   - 需要完整验证
   - 需要回滚保障

### 📋 增量部署标准流程

```
1. 本地开发 → 提交代码
   ↓
2. 推送到 GitHub
   ↓
3. 运行增量部署脚本
   ├─ 部署前检查（语法、导入、分支等）
   ├─ 拉取代码到服务器
   ├─ 服务器端验证
   ├─ 触发热更新
   └─ 部署后验证（健康检查、功能验证）
   ↓
4. 完成部署（零停机）
```

### 🔒 增量部署安全检查

#### 第一层：部署前检查（本地）

**必须检查项**：
- [ ] 当前分支为 `master`（或确认分支）
- [ ] 无未提交的更改
- [ ] 无未推送的提交（或先推送）
- [ ] Python 语法验证通过
- [ ] 关键模块导入验证通过

**检查命令**：
```bash
# 检查分支
git rev-parse --abbrev-ref HEAD

# 检查未提交更改
git status --porcelain

# 语法验证
python3 -c "import ast; import glob; [ast.parse(open(f).read()) for f in glob.glob('server/**/*.py', recursive=True)]"

# 模块导入验证
python3 -c "from server.main import app; from server.services.rule_service import RuleService"
```

#### 第二层：服务器端验证

**必须检查项**：
- [ ] 服务器 SSH 连接正常
- [ ] 代码拉取成功
- [ ] 服务器端语法验证通过
- [ ] 热更新服务可用

**验证命令**：
```bash
# 检查服务可用性
curl -f http://8.210.52.217:8001/health

# 检查热更新状态
curl http://8.210.52.217:8001/api/v1/hot-reload/status
```

#### 第三层：部署后验证

**必须检查项**：
- [ ] 健康检查通过（Node1 和 Node2）
- [ ] 热更新状态正常
- [ ] 关键功能验证通过（可选）

**验证命令**：
```bash
# 健康检查
curl -f http://8.210.52.217:8001/health
curl -f http://47.243.160.43:8001/health

# 功能验证
curl -X POST http://8.210.52.217:8001/api/v1/bazi/calculate \
  -H "Content-Type: application/json" \
  -d '{"solar_date":"1990-01-15","solar_time":"12:00","gender":"male"}'
```

### 🚀 增量部署执行步骤

#### 方式 1：使用增量部署脚本（推荐）

```bash
# 1. 确保代码已提交并推送
git add .
git commit -m "feat: 新功能"
git push origin master

# 2. 运行增量部署脚本
bash deploy/scripts/incremental_deploy_production.sh
```

**脚本功能**：
- ✅ 自动执行所有安全检查
- ✅ 自动拉取代码到双机
- ✅ 自动触发热更新
- ✅ 自动验证部署结果
- ✅ 自动回滚（如果失败）

#### 方式 2：手动增量部署

```bash
# 1. 在 Node1 上拉取代码
ssh root@8.210.52.217 "cd /opt/HiFate-bazi && git pull origin master"

# 2. 在 Node2 上拉取代码
ssh root@47.243.160.43 "cd /opt/HiFate-bazi && git pull origin master"

# 3. 在 Node1 上触发热更新（自动同步到 Node2）
curl -X POST http://8.210.52.217:8001/api/v1/hot-reload/sync

# 4. 验证部署结果
curl http://8.210.52.217:8001/health
curl http://47.243.160.43:8001/health
```

### 🔄 增量部署回滚机制

**自动回滚触发条件**：
- 健康检查失败（5次重试后）
- 语法验证失败
- 模块导入失败

**手动回滚**：
```bash
# 在 Node1 上回滚
curl -X POST http://8.210.52.217:8001/api/v1/hot-reload/rollback

# 在 Node2 上回滚
curl -X POST http://47.243.160.43:8001/api/v1/hot-reload/rollback
```

**回滚机制**：
1. 优先使用代码备份（`.hot_reload_backups/`）
2. 如果备份不可用，使用 Git 回滚
3. 自动重新加载模块
4. 验证回滚结果

### ✅ 增量部署检查清单

每次增量部署前必须检查：

#### 代码路径规范检查（最高优先级）
- [ ] ✅ 所有代码修改都在本地完成（未在服务器上修改）
- [ ] ✅ 代码已提交到 Git（git commit）
- [ ] ✅ 代码已推送到 GitHub（git push origin master）
- [ ] ✅ 未在服务器上直接修改任何代码（sed、vim、nano 等）
- [ ] ✅ 准备使用增量部署脚本（自动同步双机）

#### 代码质量检查
- [ ] 代码已提交到 Git
- [ ] 代码已推送到远程
- [ ] 当前分支为 `master`（或确认分支）
- [ ] 无未提交的更改

#### 语法和导入检查
- [ ] Python 语法验证通过（本地）
- [ ] Python 语法验证通过（服务器）
- [ ] 关键模块可以导入
- [ ] 无循环依赖

#### 服务器连接检查
- [ ] Node1 SSH 连接正常
- [ ] Node2 SSH 连接正常
- [ ] Node1 服务可用（健康检查通过）
- [ ] Node2 服务可用（健康检查通过）

#### 部署后验证
- [ ] Node1 健康检查通过
- [ ] Node2 健康检查通过
- [ ] Node1 与 Node2 Git 版本一致（脚本自动验证）
- [ ] Node1 与 Node2 关键文件哈希一致（脚本自动验证）
- [ ] 热更新状态正常
- [ ] 关键功能验证通过（可选）

### 🚨 增量部署注意事项

1. **代码必须已推送**
   - 增量部署脚本会拉取远程代码
   - 未推送的代码不会被部署

2. **不适用依赖变更**
   - 修改 `requirements.txt` 必须使用完整部署
   - 新增系统依赖必须使用完整部署

3. **双机同步**
   - 在 Node1 上触发热更新会自动同步到 Node2
   - 确保 Redis 连接正常（用于双机同步）

4. **监控和告警**
   - 部署后持续监控服务状态
   - 发现问题立即回滚

5. **测试优先**
   - 重要变更先在测试环境验证
   - 生产环境部署后立即验证

### 📊 增量部署性能指标

| 指标 | 目标值 | 说明 |
|------|--------|------|
| **部署时间** | < 2分钟 | 从拉取代码到完成验证 |
| **服务中断** | 0秒 | 零停机部署 |
| **回滚时间** | < 10秒 | 热更新回滚速度 |
| **成功率** | > 99% | 部署成功率 |

### 🔍 故障排查

**如果增量部署失败**：

1. **检查代码语法**
   ```bash
   python3 -c "import ast; import glob; [ast.parse(open(f).read()) for f in glob.glob('server/**/*.py', recursive=True)]"
   ```

2. **检查热更新状态**
   ```bash
   curl http://8.210.52.217:8001/api/v1/hot-reload/status
   ```

3. **检查服务日志**
   ```bash
   ssh root@8.210.52.217 "docker logs hifate-web --tail 100"
   ```

4. **手动回滚**
   ```bash
   curl -X POST http://8.210.52.217:8001/api/v1/hot-reload/rollback
   ```

5. **查看热更新错误日志**
   ```bash
   ssh root@8.210.52.217 "cat /opt/HiFate-bazi/logs/hot_reload_errors/*.log | tail -50"
   ```

### 📚 相关文档

- **增量部署脚本**：`deploy/scripts/incremental_deploy_production.sh`
- **热更新系统**：见"🔥 热更新强制规范"章节
- **完整部署流程**：见"🚀 CI/CD 标准流程"章节

---

## 🚀 生产双节点部署流程规范 【必须遵守】

### 🔴 核心原则

> **生产环境双节点部署必须经过完整的测试验证，确保所有接口功能正常，不单单是登录界面能进去就好。**

### 📋 部署方式选择

| 部署方式 | 适用场景 | 部署时间 | 服务中断 | 使用命令 |
|---------|---------|---------|---------|---------|
| **增量部署脚本** | 日常代码更新（90%情况） | 30秒-2分钟 | 0秒 | `bash deploy/scripts/incremental_deploy_production.sh` |
| **GitHub Actions CI/CD** | 依赖变更、首次部署 | 8-15分钟 | 可能有短暂中断 | GitHub Actions 自动触发 |

### 🎯 部署方式选择指南

#### 部署方式选择决策树

```
代码变更
    ↓
是否需要构建镜像？
    ├─ 是（依赖变更、Dockerfile 变更）
    │   ↓
    │   使用完整部署（GitHub Actions CI/CD）
    │
    └─ 否（仅代码更新）
        ↓
        使用增量部署（热更新）
```

#### ✅ 使用增量部署脚本（推荐，日常使用）

**适用场景**：
- Python 代码更新
- 业务逻辑修改
- Bug 修复
- 规则更新（数据库规则）
- 配置更新
- 微服务代码修改

**不适用场景**（必须使用 GitHub Actions）：
- 依赖变更（`requirements.txt`）
- Dockerfile 变更
- 首次部署
- 重大架构变更

**优势**：
- ⚡ 快速部署（30秒-2分钟）
- 🔄 零停机（服务不中断）
- 🚀 快速回滚（秒级回滚）
- 💰 低资源消耗（无需构建镜像）

#### ✅ 使用 GitHub Actions CI/CD（完整部署）

**适用场景**：
- 依赖变更（`requirements.txt`）
- Dockerfile 变更
- 首次部署
- 重大架构变更

**触发方式**：
- 自动触发：推送到 `master` 分支
- 手动触发：GitHub Actions 页面手动触发 `🚀 Deploy to Aliyun (Dual Nodes)`

**优势**：
- 🔒 完整验证（构建、测试、部署）
- 🐳 镜像管理（版本化、可回滚）
- 🤖 自动化（无需手动操作）
- 📊 可追溯（GitHub Actions 日志）

---

### 📋 标准部署流程

#### 方式 1：增量部署脚本（日常使用）

**标准流程**：

```bash
# 1. 本地开发并提交
git add .
git commit -m "feat: 新功能"
git push origin master

# 2. 运行增量部署脚本（自动执行所有检查）
bash deploy/scripts/incremental_deploy_production.sh

# 3. 运行端到端测试（必须！）
python3 tests/e2e_production_test.py

# 4. 验证部署结果
curl http://8.210.52.217:8001/health
curl http://47.243.160.43:8001/health
```

**脚本执行流程**：

```
第一步：部署前检查
  ├─ 检查当前分支（必须是 master）
  ├─ 检查未提交的更改（禁止）
  ├─ 检查未推送的提交（提示推送）
  ├─ 本地语法验证（Python 文件）
  └─ 关键模块导入验证（可选）

第二步：服务器连接检查
  ├─ 检查 Node1 SSH 连接
  └─ 检查 Node2 SSH 连接

第三步：拉取代码
  ├─ Node1 拉取最新代码（确保与 GitHub 一致）
  ├─ Node2 拉取最新代码（确保与 GitHub 一致）
  ├─ 验证双机代码一致性（Git 版本）
  └─ 修复 Nginx 配置（IP 占位符）

第四步：服务器端验证
  ├─ Node1 语法验证
  ├─ Node2 语法验证
  └─ 热更新服务可用性检查

第五步：触发热更新
  ├─ Node1 触发热更新
  └─ 自动同步到 Node2（通过 Redis）

第六步：部署后验证
  ├─ 健康检查（Node1 和 Node2）
  ├─ 热更新状态检查
  └─ 双机代码一致性验证

第七步：运行端到端测试（必须！）
  ├─ 执行端到端测试脚本
  ├─ 验证所有9个关键接口
  └─ 确保所有测试通过（Node1 和 Node2）
```

**完整部署流程图**：

```mermaid
flowchart TD
    Start[开始部署] --> CheckCode{代码已提交并推送?}
    CheckCode -->|否| CommitCode[提交并推送代码]
    CommitCode --> CheckCode
    CheckCode -->|是| RunScript[运行增量部署脚本]
    
    RunScript --> PreCheck[部署前检查]
    PreCheck --> CheckBranch{分支是master?}
    CheckBranch -->|否| Error1[错误: 必须在master分支]
    CheckBranch -->|是| CheckUncommitted{有未提交更改?}
    CheckUncommitted -->|是| Error2[错误: 存在未提交更改]
    CheckUncommitted -->|否| CheckSyntax[语法验证]
    
    CheckSyntax --> SyntaxOK{语法验证通过?}
    SyntaxOK -->|否| Error3[错误: 语法验证失败]
    SyntaxOK -->|是| CheckSSH[检查SSH连接]
    
    CheckSSH --> SSHOK{SSH连接正常?}
    SSHOK -->|否| Error4[错误: SSH连接失败]
    SSHOK -->|是| PullCode[拉取代码到双机]
    
    PullCode --> VerifyCode[验证代码一致性]
    VerifyCode --> CodeOK{代码一致?}
    CodeOK -->|否| Error5[错误: 代码不一致]
    CodeOK -->|是| HotReload[触发热更新]
    
    HotReload --> HealthCheck[健康检查]
    HealthCheck --> HealthOK{健康检查通过?}
    HealthOK -->|否| Rollback[自动回滚]
    HealthOK -->|是| RunE2E[运行端到端测试]
    
    RunE2E --> E2EOK{所有测试通过?}
    E2EOK -->|否| Error6[错误: 测试失败]
    E2EOK -->|是| Success[部署成功]
    
    Error1 --> End[结束]
    Error2 --> End
    Error3 --> End
    Error4 --> End
    Error5 --> End
    Error6 --> End
    Rollback --> End
    Success --> End
```

#### 方式 2：GitHub Actions CI/CD（完整部署）

**标准流程**：

```bash
# 1. 修改依赖或 Dockerfile
vim requirements.txt

# 2. 提交并推送
git add .
git commit -m "chore: 更新依赖"
git push origin master

# 3. GitHub Actions 自动触发
#    - build-and-push.yml: 构建镜像并推送到 ACR
#    - deploy-aliyun-dual.yml: 部署到双节点

# 4. 运行端到端测试（必须！）
python3 tests/e2e_production_test.py

# 5. 验证部署结果
curl http://8.210.52.217:8001/health
curl http://47.243.160.43:8001/health
```

---

### 🧪 端到端测试规范 【必须遵守】

> **⚠️ 所有部署后必须运行完整的端到端测试，覆盖所有关键接口，不单单是登录界面能进去就好！**

#### 测试脚本

**端到端测试脚本**：`tests/e2e_production_test.py`

**使用方法**：

```bash
# 使用默认配置（Node1: 8.210.52.217, Node2: 47.243.160.43）
python3 tests/e2e_production_test.py

# 自定义 Node URL
python3 tests/e2e_production_test.py \
  --node1-url http://8.210.52.217:8001 \
  --node2-url http://47.243.160.43:8001

# 自定义超时时间
python3 tests/e2e_production_test.py --timeout 60
```

#### 测试覆盖范围

**必须测试的接口**：

1. **健康检查接口**
   - `/health` - 基本健康检查
   - `/api/v1/health` - API 健康检查

2. **八字计算接口**
   - `/api/v1/bazi/calculate` - 八字计算（男性）
   - `/api/v1/bazi/calculate` - 八字计算（女性）

3. **公式分析接口**
   - `/api/v1/bazi/formula-analysis` - 公式分析

4. **运势接口**
   - `/api/v1/bazi/monthly-fortune` - 月运势
   - `/api/v1/bazi/daily-fortune` - 日运势

5. **身宫命宫接口**
   - `/api/v1/bazi/shengong-minggong` - 身宫命宫

6. **智能分析接口**
   - `/api/v1/smart-analyze` - 智能分析（财富意图）

7. **热更新状态接口**
   - `/api/v1/hot-reload/status` - 热更新状态

8. **API 文档接口**
   - `/docs` - API 文档

**测试要求**：
- ✅ 所有接口必须测试（Node1 和 Node2）
- ✅ 必须验证响应状态码
- ✅ 必须验证响应数据结构
- ✅ 必须测试成功和失败场景
- ✅ 必须测试不同性别、不同日期

#### 测试检查清单

**部署后必须检查**：

- [ ] 运行端到端测试脚本：`python3 tests/e2e_production_test.py`
- [ ] 所有测试用例通过（Node1 和 Node2）
- [ ] 健康检查通过（基本和 API）
- [ ] 八字计算接口正常（男性和女性）
- [ ] 公式分析接口正常
- [ ] 运势接口正常（月运势和日运势）
- [ ] 身宫命宫接口正常
- [ ] 智能分析接口正常
- [ ] 热更新状态正常
- [ ] API 文档可访问

---

### 🔒 部署前安全检查清单

#### 代码一致性检查（最高优先级）

```bash
# 1. 确保代码已提交并推送
git status  # 应该显示 "working tree clean"
git log --oneline -1  # 记录最新提交
git push origin master  # 确保已推送

# 2. 验证本地代码与 GitHub 一致
LOCAL_COMMIT=$(git rev-parse HEAD)
REMOTE_COMMIT=$(git ls-remote origin master | cut -f1)
if [ "$LOCAL_COMMIT" != "$REMOTE_COMMIT" ]; then
    echo "❌ 本地代码与 GitHub 不一致，请先推送"
    exit 1
fi
```

#### 服务器代码一致性检查

```bash
# 检查双机代码版本
NODE1_COMMIT=$(ssh root@8.210.52.217 "cd /opt/HiFate-bazi && git rev-parse HEAD")
NODE2_COMMIT=$(ssh root@47.243.160.43 "cd /opt/HiFate-bazi && git rev-parse HEAD")
LOCAL_COMMIT=$(git rev-parse HEAD)

# 必须完全一致
if [ "$NODE1_COMMIT" != "$LOCAL_COMMIT" ] || [ "$NODE2_COMMIT" != "$LOCAL_COMMIT" ]; then
    echo "❌ 服务器代码与 GitHub 不一致，请先同步"
    exit 1
fi
```

#### 语法和导入验证

```bash
# 本地验证
python3 -c "import ast; import glob; [ast.parse(open(f).read()) for f in glob.glob('server/**/*.py', recursive=True)]"

# 服务器端验证（增量部署脚本会自动执行）
```

#### 服务健康检查

```bash
# 部署前检查服务是否正常
curl -f http://8.210.52.217:8001/health
curl -f http://47.243.160.43:8001/health
```

---

### 🔍 部署后验证清单

#### 健康检查

```bash
# 基本健康检查
curl -f http://8.210.52.217:8001/health
curl -f http://47.243.160.43:8001/health

# API 健康检查（更详细）
curl -f http://8.210.52.217:8001/api/v1/health
curl -f http://47.243.160.43:8001/api/v1/health
```

#### 热更新状态检查

```bash
# 检查热更新状态
curl http://8.210.52.217:8001/api/v1/hot-reload/status
curl http://47.243.160.43:8001/api/v1/hot-reload/status

# 检查版本号
curl http://8.210.52.217:8001/api/v1/hot-reload/versions
curl http://47.243.160.43:8001/api/v1/hot-reload/versions
```

#### 双机一致性验证

```bash
# 验证双机 Git 版本一致
NODE1_COMMIT=$(ssh root@8.210.52.217 "cd /opt/HiFate-bazi && git rev-parse HEAD")
NODE2_COMMIT=$(ssh root@47.243.160.43 "cd /opt/HiFate-bazi && git rev-parse HEAD")

if [ "$NODE1_COMMIT" != "$NODE2_COMMIT" ]; then
    echo "❌ 双机代码版本不一致"
    exit 1
fi
```

#### 端到端测试（必须！）

```bash
# 运行完整的端到端测试
python3 tests/e2e_production_test.py

# 必须所有测试通过才能认为部署成功
```

---

### 🚨 故障处理

#### 如果部署失败

**增量部署失败**：

```bash
# 1. 查看错误信息（脚本会显示详细错误）
# 2. 手动回滚
curl -X POST http://8.210.52.217:8001/api/v1/hot-reload/rollback
curl -X POST http://47.243.160.43:8001/api/v1/hot-reload/rollback

# 3. 检查服务状态
ssh root@8.210.52.217 "docker logs hifate-web --tail 100"
```

**GitHub Actions 部署失败**：

```bash
# 1. 查看 GitHub Actions 日志
#    Actions → 查看失败的 workflow → 查看日志

# 2. 手动回滚（使用上一个版本的镜像）
ssh root@8.210.52.217 "cd /opt/HiFate-bazi && \
  docker pull registry.cn-hangzhou.aliyuncs.com/hifate/hifate-bazi:previous_tag && \
  docker-compose -f docker-compose.yml -f docker-compose.aliyun.yml up -d --no-deps web"
```

#### 如果测试失败

```bash
# 1. 查看测试错误详情
python3 tests/e2e_production_test.py --node1-url http://8.210.52.217:8001 --node2-url http://47.243.160.43:8001

# 2. 检查服务日志
ssh root@8.210.52.217 "docker logs hifate-web --tail 100"
ssh root@47.243.160.43 "docker logs hifate-web --tail 100"

# 3. 检查热更新状态
curl http://8.210.52.217:8001/api/v1/hot-reload/status
curl http://47.243.160.43:8001/api/v1/hot-reload/status

# 4. 如果问题严重，立即回滚
curl -X POST http://8.210.52.217:8001/api/v1/hot-reload/rollback
curl -X POST http://47.243.160.43:8001/api/v1/hot-reload/rollback
```

---

### 📊 部署成功标准

**部署成功的标准**（必须全部满足）：

1. ✅ **健康检查通过**：Node1 和 Node2 的健康检查都通过
2. ✅ **热更新状态正常**：热更新系统运行正常
3. ✅ **双机代码一致**：Node1 和 Node2 的代码版本完全一致
4. ✅ **端到端测试通过**：所有测试用例通过（Node1 和 Node2）
5. ✅ **所有接口正常**：所有关键接口都能正常响应
6. ✅ **功能验证通过**：关键功能（八字计算、公式分析、运势等）都能正常工作

**禁止操作**：
- ❌ 禁止只检查登录界面就认为部署成功
- ❌ 禁止跳过端到端测试
- ❌ 禁止只测试一个节点
- ❌ 禁止只测试健康检查接口

---

### 📚 相关文档

- **增量部署使用指南**：`docs/增量部署使用指南.md`
- **热更新系统**：`.cursorrules` - "🔥 热更新强制规范"章节
- **CI/CD 标准流程**：`.cursorrules` - "🚀 CI/CD 标准流程"章节
- **端到端测试脚本**：`tests/e2e_production_test.py`

---

**核心要点**：
- **🔴 最高优先级**：**所有部署后必须运行完整的端到端测试**
- **📋 测试覆盖**：**必须覆盖所有关键接口，不单单是登录界面**
- **✅ 双机验证**：**必须验证 Node1 和 Node2 都正常**
- **🚫 禁止跳过**：**禁止跳过测试或只做表面检查**

---

### 🎯 部署方式选择指南

**如何选择部署方式**：

```
代码变更
    ↓
是否需要构建镜像？
    ├─ 是（依赖变更、Dockerfile 变更）
    │   ↓
    │   使用完整部署（CI/CD）
    │
    └─ 否（仅代码更新）
        ↓
        使用增量部署（热更新）
```

**决策树**：
- 修改 `requirements.txt` → 完整部署
- 修改 `Dockerfile` → 完整部署
- 首次部署 → 完整部署
- 仅修改 Python 代码 → 增量部署
- 仅修改规则/配置 → 增量部署

### 🐳 ACR/GHCR 镜像推送规范 【必须遵守】

> **问题复盘 2025-12-06**：ACR 推送失败导致部署使用旧镜像，引发 uvicorn 缺失等问题。

#### 1. docker/build-push-action 必须配置 provenance: false

**原因**：阿里云 ACR 不支持 Docker BuildKit 的 provenance 特性，会导致 `error from registry: unsupported` 错误。

**正确配置**：
```yaml
- name: 🐳 Build and push Docker image
  uses: docker/build-push-action@v5
  with:
    context: .
    push: true
    tags: ${{ steps.meta.outputs.tags }}
    platforms: linux/amd64
    provenance: false  # ⚠️ ACR 必需！不要删除！
    build-args: |
      ...
```

**检查清单**：
- [ ] `deploy-test.yml` 中 build-push-action 包含 `provenance: false`
- [ ] `deploy-production.yml` 中 build-push-action 包含 `provenance: false`
- [ ] `build-and-push.yml` 中使用 `--provenance=false` 参数

#### 2. 服务器部署前必须清理磁盘空间

**原因**：服务器磁盘空间不足会导致 `no space left on device` 错误，无法拉取新镜像。

**正确配置**：在部署脚本开头添加：
```bash
echo "🔄 开始部署到测试环境..."

# 清理磁盘空间（必须！防止 no space left on device）
docker system prune -af 2>/dev/null || true
docker image prune -af 2>/dev/null || true

# 进入项目目录
cd /opt/HiFate-bazi
```

**检查清单**：
- [ ] `deploy-test.yml` 部署脚本包含磁盘清理
- [ ] `deploy-production.yml` 部署脚本包含磁盘清理

#### 3. 常见错误及解决方案

| 错误 | 原因 | 解决方案 |
|-----|------|---------|
| `error from registry: unsupported` | ACR 不支持 provenance | 添加 `provenance: false` |
| `no space left on device` | 服务器磁盘满 | 部署前执行 `docker system prune -af` |
| `unauthorized: authentication required` | ACR 认证失败 | 检查 secrets 配置 |
| `ModuleNotFoundError: No module named 'uvicorn'` | 使用了旧镜像 | 确保新镜像成功推送并拉取 |

### 📚 相关文档

- `.github/workflows/build-and-push.yml` - 构建和推送流程
- `.github/workflows/deploy-test.yml` - 测试环境部署流程
- `docs/GitHub-Container-Registry部署方案.md` - 详细部署文档

---

## 🚀 服务管理

### 启动服务
```bash
# 启动主服务
python3 server/start.py

# 或使用脚本
./start.sh
```

### 测试 API
```bash
# 测试 gRPC-Web 网关
curl -s -X POST 'http://127.0.0.1:8001/api/v1/bazi/formula-analysis' \
  -H 'Content-Type: application/json' \
  -d '{"solar_date": "1990-01-15", "solar_time": "12:00", "gender": "male"}'
```

### 查看日志
```bash
tail -f logs/server_8001.log
```

---

## 📦 Git 提交规范

### Commit Message 格式
```
[类型] 简短描述

- 修改文件：列出文件
- 功能说明：详细说明
- 测试情况：测试结果
```

### 类型标签
- `[新增]` - 新功能/新规则
- `[修复]` - Bug修复
- `[优化]` - 性能优化
- `[重构]` - 代码重构
- `[规则]` - 规则相关变更
- `[配置]` - 配置修改

---

## 📖 Gitee 仓库

| 项目 | 值 |
|------|-----|
| **仓库地址** | https://gitee.com/zhoudengtang/hifate-prod.git |
| **本地 remote** | gitee |
| **默认分支** | master |

### 提交流程
```bash
git add .
git commit -m "[类型] 描述"
git push gitee master
```

### 部署到生产
```bash
./deploy.sh  # 选择 1) 完整部署
```

**📖 详细部署文档**：`docs/Docker生产部署完整指南.md`

---

## 🐳 Docker 基础镜像优化

### 📋 原理

使用预构建的基础镜像（包含所有 Python 依赖包和框架），大幅加速部署：

```
传统方式：每次部署都安装依赖（5-10分钟）
优化方式：基础镜像已含所有包和框架，只需复制代码（10-20秒）
```

**核心优化**：
- ✅ 所有 Python 包和框架预装在基础镜像中
- ✅ 部署时只需复制代码，无需安装依赖
- ✅ 基础镜像包含：FastAPI、gRPC、数据库驱动、图像处理库等

### 🚀 使用流程

**1. 首次构建基础镜像**（仅需一次，约 5-10 分钟）

```bash
./scripts/docker/build_base.sh
```

**2. 检查基础镜像状态**

```bash
./scripts/docker/check_base.sh
```

**3. 正常部署**（快速，10-20秒）

```bash
docker compose up -d --build web
```

### ⚠️ 何时需要重建基础镜像

| 场景 | 是否需要重建 | 说明 |
|------|------------|------|
| 修改代码 | ❌ 不需要 | 直接部署即可 |
| 修改 requirements.txt | ✅ **必须重建** | 依赖变更 |
| 修改 Dockerfile.base | ✅ 需要重建 | 基础镜像配置变更 |

### 🔒 安全机制

1. **跨平台兼容**：使用 `--platform linux/amd64` 确保 Mac M1/Intel 都能构建
2. **保险层**：应用 Dockerfile 会再次执行 `pip install`，确保依赖完整
3. **自动检查**：`check_base.sh` 会检测 requirements.txt 是否变更
4. **依赖验证**：基础镜像构建时验证核心框架（FastAPI、gRPC、数据库驱动等）
5. **健康检查**：基础镜像包含健康检查，确保可用性

### 📊 性能对比

| 场景 | 传统方式 | 基础镜像 | 提升 |
|------|---------|---------|------|
| 首次部署 | 10-15分钟 | 5-10分钟（构建基础镜像） | 1次性 |
| 代码更新 | 1-2分钟 | **10-20秒** | **6-12倍** |
| 依赖更新 | 10-15分钟 | 5-10分钟（重建基础镜像） | 1次性 |

### 🛠️ 维护命令

```bash
# 构建基础镜像
./scripts/docker/build_base.sh

# 检查是否需要更新
./scripts/docker/check_base.sh

# 查看基础镜像信息
docker images hifate-base

# 删除旧版本（可选）
docker rmi hifate-base:20241128
```

---

## 💡 开发原则

> **⚠️ 重要提示**：所有新功能的增加、修改、扩展都必须严格遵守本开发规范。开发前必须阅读"新功能开发强制规范"章节（第 65-200 行），并完成开发规范检查清单。

1. **📋 规范优先**：**所有新功能必须遵守开发规范**，这是最高优先级（见"新功能开发强制规范"）
2. **🔐 安全优先**：安全是最高优先级，所有代码必须遵循安全最佳实践（见"安全规范"）
3. **🔴 零停机优先**：所有设计必须支持不停机更新（见"零停机原则"）
4. **🔌 gRPC 优先**：服务间交互必须使用 gRPC（见"gRPC 交互规范"）
5. **📜 规则数据库化**：规则存数据库，支持热更新，**禁止从文件读取**（见"规则存储规范"）
6. **🔄 向后兼容**：只加不删，保持兼容
7. **✅ 先测试后提交**：修改后立即测试，测试覆盖率 ≥ 50%（见"测试开发规范"）
8. **📝 规范命名**：类型用英文，ID 统一格式（见"规则编码规范"和"规则类型命名"）
9. **🔄 问题复盘**：每次问题必须复盘并更新规范（见"问题复盘机制"）
10. **💾 Token 节省**：只读取相关文件，使用 `offset`/`limit` 限制范围（见"Token 节省原则"）
11. **🧪 A/B 测试优先**：新功能必须支持 A/B 测试（见"A/B 测试和灰度发布规范"）
12. **🚀 灰度发布优先**：重要变更必须通过灰度发布（见"A/B 测试和灰度发布规范"）
13. **🔄 回滚准备**：所有数据库变更必须准备回滚脚本（见"A/B 测试和灰度发布规范"）
14. **📊 性能监控**：所有关键流程必须记录性能监控（见"智能运势分析性能监控规范"）
15. **🎯 意图识别混合架构**：意图识别必须使用混合架构，响应时间 < 1秒（见"意图识别混合架构规范"）

---

## 🧪 A/B 测试和灰度发布规范 【必须遵守】

### 🔴 核心原则

> **所有新功能、重要变更、数据库变更都必须支持 A/B 测试、灰度发布和回滚机制。**

| 场景 | 要求 | 实现方式 |
|------|------|----------|
| **新功能开发** | ✅ 必须 | 使用功能开关（Feature Flag）控制 |
| **算法优化** | ✅ 必须 | 使用 A/B 测试对比效果 |
| **重要变更** | ✅ 必须 | 通过灰度发布逐步上线 |
| **数据库变更** | ✅ 必须 | 准备回滚脚本，支持快速回滚 |
| **性能优化** | ✅ 推荐 | 使用 A/B 测试验证效果 |

---

### 📋 A/B 测试开发规范

#### 1. 新功能必须支持 A/B 测试

**要求**：
- 所有新功能、算法优化、UI 变更必须支持 A/B 测试
- 使用 `server/utils/ab_test.py` 框架
- 创建实验，分配变体，记录事件

**开发流程**：

```python
# 1. 导入 A/B 测试框架
from server.utils.ab_test import get_ab_test_manager, Experiment, ExperimentStatus

# 2. 创建实验（在服务启动时或通过 API）
manager = get_ab_test_manager()
experiment = Experiment(
    name="新算法测试",
    description="测试新的八字计算算法",
    status=ExperimentStatus.RUNNING,
    traffic_percent=50.0,  # 50% 流量
    variants={"A": 50, "B": 50}  # A/B 各 50%
)
manager.create_experiment(experiment)

# 3. 在代码中使用
variant = manager.assign_variant("新算法测试", user_id=user_id)
if variant == "A":
    result = old_algorithm.calculate()
elif variant == "B":
    result = new_algorithm.calculate()

# 4. 记录用户行为事件
manager.record_event("新算法测试", user_id, "click", {"button": "submit"})
```

**检查清单**：
- [ ] 新功能是否创建了 A/B 测试实验
- [ ] 是否在代码中正确分配变体
- [ ] 是否记录了关键事件（点击、转化等）
- [ ] 是否可以通过 API 查看实验统计

---

### 🚩 功能开关开发规范

#### 1. 新功能必须使用功能开关

**要求**：
- 所有新功能必须通过功能开关控制
- 支持快速开启/关闭，无需重新部署
- 支持百分比灰度、白名单、黑名单

**开发流程**：

```python
# 1. 导入功能开关框架
from server.utils.feature_flag import get_feature_flag_manager, FeatureFlag, FlagType

# 2. 创建功能开关（在服务启动时或通过 API）
manager = get_feature_flag_manager()
flag = FeatureFlag(
    name="新功能",
    description="新功能开关",
    enabled=True,
    flag_type=FlagType.PERCENTAGE,  # 百分比开关
    value=10.0  # 10% 流量
)
manager.create_flag(flag)

# 3. 在代码中检查开关
if manager.is_enabled("新功能", user_id=user_id):
    # 使用新功能
    result = new_feature.process()
else:
    # 使用旧功能或跳过
    result = old_feature.process()
```

**功能开关类型**：
- `FlagType.BOOLEAN` - 布尔开关（全部开启/关闭）
- `FlagType.PERCENTAGE` - 百分比开关（灰度发布）
- `FlagType.WHITELIST` - 白名单（指定用户）
- `FlagType.BLACKLIST` - 黑名单（排除用户）

**检查清单**：
- [ ] 新功能是否创建了功能开关
- [ ] 是否在代码中正确检查开关状态
- [ ] 是否支持快速关闭（紧急情况）
- [ ] 是否可以通过 API 切换开关状态

---

### 🚀 灰度发布规范

#### 1. 重要变更必须通过灰度发布

**要求**：
- 所有重要功能变更、性能优化、架构调整必须通过灰度发布
- 从 10% 流量开始，逐步增加到 100%
- 监控关键指标，随时准备回滚

**灰度发布流程**：

```bash
# 1. 开发新功能
git checkout -b feature/new-feature
# ... 开发代码 ...

# 2. 创建功能开关（10% 流量）
# 使用 API 或代码创建功能开关

# 3. 执行灰度发布
./deploy.sh
# 选择 8) 灰度发布

# 4. 监控灰度版本
docker logs -f hifate-bazi-web-gray

# 5. 逐步增加流量（如果正常）
# 调整负载均衡器配置：10% → 20% → 50% → 100%

# 6. 如果异常，立即回滚
./deploy.sh
# 选择 10) 灰度发布回滚
```

**灰度发布检查清单**：
- [ ] 是否创建了功能开关（百分比开关）
- [ ] 是否执行了灰度发布脚本
- [ ] 是否配置了负载均衡器流量分配
- [ ] 是否监控了关键指标（错误率、响应时间、业务指标）
- [ ] 是否准备了回滚方案

**监控指标**：
- 错误率（应 < 1%）
- 响应时间（不应明显增加）
- 业务指标（转化率、用户满意度等）
- 系统资源（CPU、内存、数据库连接等）

---

### 🔄 数据库回滚规范

#### 1. 所有数据库变更必须准备回滚脚本

**要求**：
- 所有数据库迁移必须同时准备回滚脚本
- 回滚脚本必须经过测试验证
- 回滚脚本命名规范：`rollback_YYYYMMDD_HHMMSS_description.sql`

**开发流程**：

```bash
# 1. 创建数据库迁移脚本
# scripts/migration/add_user_table.sql
CREATE TABLE `new_user_table` (...);

# 2. 同时创建回滚脚本
./scripts/migration/create_rollback.sh
# 输入描述：回滚添加用户表

# 3. 编辑回滚脚本
# scripts/migration/rollback/rollback_20250115_143000_add_user_table.sql
START TRANSACTION;
DROP TABLE IF EXISTS `new_user_table`;
COMMIT;

# 4. 在测试环境验证回滚脚本
mysql -h test_host -u root -p test_db < scripts/migration/rollback/rollback_*.sql

# 5. 执行迁移（生产环境）
# 如果失败，立即执行回滚
./deploy.sh
# 选择 9) 数据库回滚
```

**回滚脚本规范**：
- 必须使用事务（`START TRANSACTION` / `COMMIT`）
- 必须使用 `IF EXISTS` 避免错误
- 必须包含验证 SQL（可选）
- 必须记录回滚日志

**检查清单**：
- [ ] 是否创建了回滚脚本
- [ ] 回滚脚本是否经过测试验证
- [ ] 回滚脚本是否使用事务
- [ ] 是否可以在生产环境快速执行回滚

---

### 📝 开发检查清单

每次开发新功能或重要变更时，必须检查：

#### A/B 测试检查
- [ ] 是否创建了 A/B 测试实验
- [ ] 是否在代码中正确分配变体
- [ ] 是否记录了关键事件
- [ ] 是否可以通过 API 查看统计

#### 功能开关检查
- [ ] 是否创建了功能开关
- [ ] 是否在代码中正确检查开关
- [ ] 是否支持快速关闭
- [ ] 是否可以通过 API 切换

#### 灰度发布检查
- [ ] 是否执行了灰度发布
- [ ] 是否配置了流量分配
- [ ] 是否监控了关键指标
- [ ] 是否准备了回滚方案

#### 数据库回滚检查
- [ ] 是否创建了回滚脚本
- [ ] 回滚脚本是否经过测试
- [ ] 是否可以在生产环境快速执行

---

### 🎯 使用场景示例

#### 场景 1：新算法上线

```python
# 1. 创建 A/B 测试实验
experiment = Experiment(
    name="新算法测试",
    status=ExperimentStatus.RUNNING,
    traffic_percent=50.0,
    variants={"A": 50, "B": 50}
)

# 2. 在代码中使用
variant = manager.assign_variant("新算法测试", user_id)
if variant == "A":
    result = old_algorithm.calculate()
else:
    result = new_algorithm.calculate()

# 3. 记录事件
manager.record_event("新算法测试", user_id, "calculate", {"result": result})

# 4. 分析统计，决定是否全量上线
stats = manager.get_experiment_stats("新算法测试")
```

#### 场景 2：新功能灰度发布

```python
# 1. 创建功能开关（10% 流量）
flag = FeatureFlag(
    name="新功能",
    enabled=True,
    flag_type=FlagType.PERCENTAGE,
    value=10.0
)

# 2. 在代码中检查
if manager.is_enabled("新功能", user_id):
    result = new_feature.process()
else:
    result = old_feature.process()

# 3. 监控指标，逐步增加流量
# 10% → 20% → 50% → 100%
```

#### 场景 3：数据库变更

```sql
-- 1. 迁移脚本
-- scripts/migration/add_index.sql
ALTER TABLE `user_table` ADD INDEX `idx_email` (`email`);

-- 2. 回滚脚本
-- scripts/migration/rollback/rollback_20250115_143000_add_index.sql
START TRANSACTION;
ALTER TABLE `user_table` DROP INDEX IF EXISTS `idx_email`;
COMMIT;
```

---

### 📚 相关文档

- [A/B 测试和灰度发布指南](../docs/A_B测试和灰度发布指南.md) - 详细使用说明
- [部署文档](../docs/Docker生产部署完整指南.md) - 部署指南

---

### ⚠️ 注意事项

1. **A/B 测试**：
   - 确保变体流量总和为 100%
   - 同一用户在同一实验中总是分配到相同变体
   - 定期分析统计，及时调整实验

2. **功能开关**：
   - 百分比开关基于用户ID哈希，确保一致性
   - 白名单/黑名单需要明确的用户ID列表
   - 紧急情况可以快速关闭功能

3. **灰度发布**：
   - 从 10% 流量开始，逐步增加
   - 监控关键指标，随时准备回滚
   - 保留回滚脚本和回滚方案

4. **数据库回滚**：
   - 执行回滚前必须备份数据
   - 先在测试环境验证回滚脚本
   - 某些操作（如删除数据）无法完全回滚

---

## 📚 文档维护规范

### 🔄 文档同步原则

**核心原则**：操作更新时，文档必须同步更新

### 📝 需要同步更新的场景

| 场景 | 需要更新的文档 | 更新内容 |
|------|--------------|---------|
| 新增部署步骤 | `docs/Docker生产部署完整指南.md` | 添加新步骤 |
| 修改部署命令 | `docs/Docker生产部署完整指南.md` | 更新命令 |
| 新增故障排查 | `docs/Docker生产部署完整指南.md` | 添加问题解决方案 |
| 修改配置项 | `docs/Docker生产部署完整指南.md` | 更新配置说明 |
| 新增脚本 | `docs/Docker生产部署完整指南.md` | 添加脚本使用说明 |
| 修改开发流程 | `.cursorrules` | 更新相关章节 |

### ✅ 文档更新检查清单

每次修改部署相关操作时，必须检查：

- [ ] 是否更新了 `docs/Docker生产部署完整指南.md`
- [ ] 是否更新了 `.cursorrules` 中的相关章节
- [ ] 是否更新了脚本中的注释
- [ ] 是否更新了 README（如有）

### 📋 文档维护流程

1. **修改操作** → 立即更新文档
2. **提交代码** → 同时提交文档更新
3. **验证部署** → 验证文档准确性
4. **标记更新日期** → 在文档顶部更新日期

### 🎯 主要部署文档

| 文档 | 用途 | 维护频率 |
|------|------|---------|
| `docs/Docker生产部署完整指南.md` | **主要部署文档** | 每次操作变更 |
| `docs/Docker基础镜像优化.md` | 基础镜像详细说明 | 基础镜像变更时 |
| `.cursorrules` | 开发规范 | 规范变更时 |

---

**核心要点**：
- **🔴 最高优先级**：**所有新功能必须遵守开发规范**（见"新功能开发强制规范"）
- **📋 开发前必读**：开发新功能前必须阅读相关规范章节并完成检查清单
- **✅ 强制检查**：所有新功能必须通过开发规范检查清单验证
- **🚫 禁止硬编码路径**：所有路径必须基于项目根目录动态获取（见"路径配置规范"）
- **🐳 容器代码挂载**：所有微服务必须挂载 proto 目录，确保代码一致性（见"容器代码挂载规范"）
- **🔧 gRPC 兼容性**：gRPC 代码生成工具版本必须与运行时版本一致（见"gRPC 代码兼容性规范"）
- **🔧 环境变量配置**：容器启动必须使用 --env-file，确保关键配置正确加载（见"环境变量配置规范"）
- 新增 API 必须同时注册 gRPC 端点（见"后端注册规范"）
- 新增规则类型必须同步更新前后端（见"类型映射"和"问题4"）
- 数据库配置使用 `hifate_bazi` 而非 `bazi_system`（见"数据库配置默认值"）
- 规则 `rule_type` 使用英文小写（见"规则类型命名"）
- **所有规则必须从数据库读取，禁止从文件读取**（见"规则存储规范"）
- **所有规则匹配必须使用 `RuleService`，禁止使用 `FormulaRuleService`**（见"规则存储规范"）
- **每次问题必须复盘并更新开发规范**（见"问题复盘机制"）
- **操作更新时，文档必须同步更新**（见"文档维护规范"）
- **新功能必须支持 A/B 测试和功能开关**（见"A/B 测试和灰度发布规范"）
- **重要变更必须通过灰度发布**（见"A/B 测试和灰度发布规范"）
- **数据库变更必须准备回滚脚本**（见"A/B 测试和灰度发布规范"）
- **意图识别必须使用混合架构，响应时间 < 1秒**（见"意图识别混合架构规范"）
- **所有新功能必须同步编写测试案例，测试覆盖率 ≥ 50%**（见"测试开发规范"）
- **所有关键流程必须记录性能监控**（见"智能运势分析性能监控规范"）

---

## 🚀 意图识别混合架构规范 【必须遵守】

### 🔴 核心原则

> **意图识别响应时间必须 < 1秒，使用混合架构实现高性能。**

### 📋 架构设计

**混合架构流程**：
```
用户输入
    ↓
【第1层：关键词过滤】（0ms，处理60%的明确问题）
    ├─ 强指示词 → 直接通过（99%准确）
    ├─ 黑名单 → 直接拒绝（95%准确）
    └─ 白名单 → 直接通过（90%准确）
    ↓
【第2层：本地BERT模型】（50-100ms，处理20%的简单问题）
    ├─ 模型分类（如果可用）
    └─ 关键词回退（如果模型不可用）
    ↓
【第3层：判断是否需要LLM兜底】
    ├─ 置信度 < 0.6 → LLM
    ├─ 问题模糊 → LLM
    └─ 复杂时间表达 → LLM
    ↓
【第4层：规则后处理】（10-20ms）
    ├─ 时间意图解析（支持中文数字）
    ├─ 多意图合并
    └─ JSON格式化
    ↓
【第5层：LLM兜底】（500-1000ms，仅处理5%的模糊问题）
    └─ 仅处理复杂/模糊问题
    ↓
最终结果
```

### 🎯 性能要求

| 场景 | 占比 | 响应时间 | 准确率 | 使用技术 |
|------|------|---------|--------|---------|
| 关键词明确 | 60% | <10ms | 95%+ | 关键词过滤 |
| 简单问题 | 20% | 50-100ms | 85-90% | 本地模型 + 规则 |
| 复杂问题 | 15% | 100-200ms | 80-85% | 本地模型 + 规则 |
| 模糊问题 | 5% | 500-1000ms | 90%+ | LLM兜底 |

**平均响应时间**：< 100ms（满足 < 1秒要求）

### 📁 核心文件

| 文件 | 作用 | 说明 |
|------|------|------|
| `services/intent_service/local_classifier.py` | 本地BERT模型分类器 | 处理简单问题（50-100ms） |
| `services/intent_service/rule_postprocessor.py` | 规则后处理器 | 时间意图解析、JSON格式化（10-20ms） |
| `services/intent_service/classifier.py` | 混合架构路由 | 智能路由到不同处理层 |
| `services/intent_service/question_filter.py` | 关键词过滤器 | 快速过滤明确问题（0ms） |
| `services/intent_service/llm_client.py` | LLM客户端 | 兜底处理复杂问题（500-1000ms） |

### 🔧 实现要求

#### 1. 本地模型分类器

**要求**：
- 使用BERT/RoBERTa中文模型（可选，如果不可用则使用关键词回退）
- 支持关键词回退方案（确保模型不可用时仍能工作）
- 响应时间 < 100ms

**实现示例**：
```python
from services.intent_service.local_classifier import LocalIntentClassifier

classifier = LocalIntentClassifier()
result = classifier.classify(question)
# 返回：{"intents": ["wealth"], "confidence": 0.85, "method": "local_model"}
```

#### 2. 规则后处理器

**要求**：
- 支持中文数字和阿拉伯数字的时间表达
- 支持多种时间类型（今天、本月、今年、明年、后N年、XXXX年、XXXX-YYYY年等）
- 响应时间 < 20ms

**时间意图类型**：
- `today` - 今天/今日
- `this_month` - 本月/这个月
- `this_year` - 今年/本年（默认）
- `next_year` - 明年（只有1年）
- `future_years` - 后N年/未来N年（N年）
- `recent_years` - 最近N年
- `specific_year` - XXXX年（单个年份）
- `year_range` - XXXX-YYYY年（年份范围）

**实现示例**：
```python
from services.intent_service.rule_postprocessor import RulePostProcessor

processor = RulePostProcessor()
result = processor.process(question, base_result)
# 返回：包含time_intent的完整结果
```

#### 3. 混合架构路由

**要求**：
- 智能判断是否需要LLM兜底
- 优先使用本地模型，仅在必要时调用LLM
- 确保平均响应时间 < 100ms

**LLM兜底条件**：
- 本地模型置信度 < 0.6
- 问题过于模糊（长度 < 5 或缺少关键词）
- 多意图冲突（意图数量 > 2 且置信度低）
- 复杂时间表达（需要上下文理解）

**实现示例**：
```python
from services.intent_service.classifier import IntentClassifier

classifier = IntentClassifier()
result = classifier.classify(question)
# 自动路由到合适的处理层
```

### ⚙️ 配置项

在 `services/intent_service/config.py` 中：

```python
# 混合架构配置
HYBRID_ARCHITECTURE_ENABLED = os.getenv("HYBRID_ARCHITECTURE_ENABLED", "true").lower() == "true"
LOCAL_MODEL_NAME = os.getenv("LOCAL_MODEL_NAME", "hfl/chinese-roberta-wwm-ext")
LLM_FALLBACK_THRESHOLD = float(os.getenv("LLM_FALLBACK_THRESHOLD", "0.6"))  # 置信度阈值
```

### ✅ 检查清单

每次修改意图识别相关代码时，必须检查：

- [ ] 平均响应时间是否 < 100ms
- [ ] 是否优先使用本地模型/关键词过滤
- [ ] LLM兜底是否仅在必要时调用（< 5%的情况）
- [ ] 时间意图识别是否支持中文数字
- [ ] 是否支持所有时间类型（今天、明年、后N年、XXXX年等）
- [ ] 错误处理是否完善（模型不可用时使用回退方案）

### 🚨 常见问题

#### 问题1：时间意图识别失败

**症状**："后三年"无法识别为`future_years`

**原因**：正则表达式不支持中文数字

**解决**：在`rule_postprocessor.py`中支持中文数字转换

#### 问题2：响应时间过长

**症状**：平均响应时间 > 1秒

**原因**：过多调用LLM API

**解决**：
- 降低LLM兜底阈值（`LLM_FALLBACK_THRESHOLD`）
- 优化关键词过滤规则
- 增强本地模型能力

#### 问题3：本地模型不可用

**症状**：`transformers`未安装或模型加载失败

**解决**：自动使用关键词回退方案，确保服务可用

---

**核心要点**：
- **意图识别必须使用混合架构，响应时间 < 1秒**
- **优先使用本地模型/关键词过滤，LLM仅作为兜底**
- **时间意图识别必须支持中文数字和阿拉伯数字**
- **所有时间类型必须正确识别（今天、明年、后N年、XXXX年等）**

---

## 📊 智能运势分析性能监控规范 【必须遵守】

### 🔴 核心原则

> **所有智能运势分析流程必须记录端到端日志和性能监控，确保每个阶段的响应时间可控。**

### 📋 性能监控要求

**必须监控的阶段**：
1. **意图识别** (`intent_recognition`) - 目标：< 100ms
2. **八字计算** (`bazi_calculation`) - 目标：< 50ms
3. **规则匹配** (`rule_matching`) - 目标：< 200ms
4. **流年大运分析** (`fortune_context`) - 目标：< 1000ms（可选）
5. **LLM深度解读** (`llm_analysis`) - 目标：< 2000ms（可选）
6. **生成响应文本** (`response_generation`) - 目标：< 50ms

### 🔧 实现方式

**使用 `PerformanceMonitor` 工具类**：

```python
from server.utils.performance_monitor import PerformanceMonitor

# 初始化监控器
monitor = PerformanceMonitor()

# 使用上下文管理器记录阶段
with monitor.stage("intent_recognition", "意图识别", question=question):
    intent_result = intent_client.classify(question=question)
    monitor.add_metric("intent_recognition", "intents_count", len(intent_result.get("intents", [])))

# 输出性能摘要
monitor.log_summary()

# 在响应中包含性能摘要
result = {
    "success": True,
    "response": response_text,
    "performance": monitor.get_summary()  # ⭐ 添加性能摘要
}
```

### 📊 性能摘要格式

性能摘要包含以下信息：
- `total_duration_ms`: 总耗时（毫秒）
- `stages`: 各阶段详细信息（耗时、成功/失败、指标等）
- `bottlenecks`: 性能瓶颈（>1秒的阶段）
- `failed_stages`: 失败的阶段

### ✅ 检查清单

每次修改智能运势分析相关代码时，必须检查：

- [ ] 是否使用 `PerformanceMonitor` 记录所有阶段
- [ ] 是否在响应中包含性能摘要
- [ ] 是否输出性能摘要到日志
- [ ] 是否识别并记录性能瓶颈（>1秒）
- [ ] 是否记录失败的阶段和错误信息

### 🚨 性能优化建议

**常见性能瓶颈**：
1. **LLM深度解读**：通常是最慢的阶段（500-2000ms），建议：
   - 使用流式输出提升用户体验
   - 考虑缓存常见问题的结果
   - 优化提示词减少响应时间

2. **流年大运分析**：可能较慢（500-1000ms），建议：
   - 仅在需要时启用（`include_fortune_context=True`）
   - 优化数据库查询
   - 考虑缓存计算结果

3. **规则匹配**：可能较慢（100-300ms），建议：
   - 优化规则匹配算法
   - 使用索引加速数据库查询
   - 考虑缓存匹配结果

### 📝 日志输出示例

```
================================================================================
[PerformanceMonitor] [req_1234567890] 性能摘要
================================================================================
总耗时: 2249ms (2.249s)
阶段数: 6

各阶段耗时:
  ✅ intent_recognition: 50ms (intents_count: 1, confidence: 0.85, method: local_model)
  ✅ bazi_calculation: 23ms
  ✅ rule_matching: 155ms (matched_rules_count: 25, rule_types_count: 1)
  ✅ fortune_context: 803ms (liunian_count: 3)
  ✅ llm_analysis: 1202ms (analysis_length: 500)
  ✅ response_generation: 12ms (response_length: 2000)

⚠️ 性能瓶颈（>1秒）:
  - llm_analysis: 1202ms - LLM深度解读
================================================================================
```

### 🎯 性能目标

| 阶段 | 目标耗时 | 警告阈值 | 说明 |
|------|---------|---------|------|
| 意图识别 | < 100ms | > 200ms | 使用混合架构，大部分请求应 < 100ms |
| 八字计算 | < 50ms | > 100ms | 本地计算，应该很快 |
| 规则匹配 | < 200ms | > 500ms | 数据库查询，可能较慢 |
| 流年大运 | < 1000ms | > 2000ms | 可选功能，可能较慢 |
| LLM深度解读 | < 2000ms | > 5000ms | 可选功能，通常最慢 |
| 生成响应 | < 50ms | > 100ms | 文本生成，应该很快 |

**总耗时目标**：
- 不包含流年大运和LLM：< 500ms
- 包含流年大运：< 2000ms
- 包含流年大运和LLM：< 5000ms

---

**核心要点**：
- **所有智能运势分析流程必须使用 `PerformanceMonitor` 记录性能**
- **性能摘要必须包含在API响应中**
- **必须识别并记录性能瓶颈（>1秒）**
- **必须记录失败的阶段和错误信息**

---

## 🧪 测试开发规范 【必须遵守】

### 🔴 核心原则

> **所有新功能必须同步编写测试案例，测试覆盖率必须达到 50% 以上。**

### 📋 测试要求

#### 1. 新增功能必须同步编写测试

**要求**：
- ✅ 新增 API 端点必须编写对应的测试案例
- ✅ 新增服务功能必须编写单元测试
- ✅ 新增业务逻辑必须编写集成测试
- ✅ 修改现有功能必须更新相关测试

**检查清单**：
- [ ] 新功能是否有对应的测试文件
- [ ] 测试是否覆盖正常流程
- [ ] 测试是否覆盖异常流程
- [ ] 测试是否覆盖边界情况
- [ ] 测试是否通过 CI/CD 验证

#### 2. 测试覆盖率要求

**覆盖率目标**：
- **单元测试覆盖率**：≥ 50%（核心模块 ≥ 70%）
- **API 测试覆盖率**：≥ 80%（所有公开 API 必须有测试）
- **集成测试覆盖率**：≥ 60%（关键业务流程必须有测试）

**检查命令**：
```bash
# 运行测试并生成覆盖率报告
pytest tests/ --cov=server --cov=src --cov-report=html --cov-report=term-missing

# 查看覆盖率报告
open htmlcov/index.html  # macOS
# 或访问 htmlcov/index.html
```

#### 3. 测试分类和命名规范

**测试文件命名**：
- 单元测试：`tests/unit/test_<module_name>.py`
- 集成测试：`tests/integration/test_<feature_name>.py`
- API 测试：`tests/api/test_<api_name>.py`
- 功能测试：`tests/features/test_<feature_name>.py`
- 端到端测试：`tests/e2e/test_<scenario_name>.py`

**测试函数命名**：
```python
# ✅ 正确：使用 test_ 前缀
def test_calculate_bazi_success():
    """测试成功计算八字"""
    ...

def test_calculate_bazi_invalid_date():
    """测试无效日期输入"""
    ...

# ❌ 错误：不使用 test_ 前缀
def calculate_bazi_test():
    ...
```

**测试类命名**：
```python
# ✅ 正确：使用 Test 前缀
class TestBaziService:
    """八字服务测试类"""
    ...

# ❌ 错误：不使用 Test 前缀
class BaziServiceTest:
    ...
```

#### 4. 测试标记（Markers）

**使用 pytest markers 分类测试**：
```python
import pytest

@pytest.mark.unit
def test_calculate_bazi():
    """单元测试"""
    ...

@pytest.mark.integration
def test_api_integration():
    """集成测试"""
    ...

@pytest.mark.api
def test_bazi_api():
    """API 测试"""
    ...

@pytest.mark.e2e
def test_end_to_end():
    """端到端测试"""
    ...

@pytest.mark.slow
def test_performance():
    """慢速测试（性能测试）"""
    ...
```

**运行特定类型的测试**：
```bash
# 只运行单元测试
pytest -m unit

# 只运行集成测试
pytest -m integration

# 只运行 API 测试
pytest -m api

# 排除慢速测试
pytest -m "not slow"
```

#### 5. 测试数据管理

**使用 fixtures 管理测试数据**：
```python
# tests/conftest.py
import pytest
from server.services.bazi_service import BaziService

@pytest.fixture
def sample_bazi_data():
    """示例八字数据"""
    return {
        "solar_date": "1990-01-15",
        "solar_time": "12:00",
        "gender": "male"
    }

@pytest.fixture
def bazi_service():
    """八字服务实例"""
    return BaziService()
```

**使用参数化测试**：
```python
import pytest

@pytest.mark.parametrize("solar_date,solar_time,gender,expected", [
    ("1990-01-15", "12:00", "male", "庚午"),
    ("1995-05-20", "14:30", "female", "乙亥"),
])
def test_calculate_bazi(solar_date, solar_time, gender, expected):
    """参数化测试"""
    result = calculate_bazi(solar_date, solar_time, gender)
    assert result["day_pillar"] == expected
```

#### 6. 测试执行规范

**本地开发时**：
```bash
# 运行所有测试
pytest

# 运行特定文件
pytest tests/unit/test_bazi_service.py

# 运行特定测试函数
pytest tests/unit/test_bazi_service.py::test_calculate_bazi

# 运行并显示覆盖率
pytest --cov=server --cov=src --cov-report=term-missing
```

**提交代码前**：
```bash
# 必须运行测试，确保通过
pytest tests/

# 检查覆盖率
pytest --cov=server --cov=src --cov-report=term-missing --cov-fail-under=50
```

#### 7. CI/CD 自动测试

**触发条件**：
- ✅ 推送到 `master` 或 `develop` 分支
- ✅ 创建 Pull Request
- ✅ 手动触发（GitHub Actions）

**测试流程**：
1. **代码质量检查**（lint）
   - Black 代码格式检查
   - isort 导入排序检查
   - pylint 代码质量检查
   - mypy 类型检查

2. **单元测试**（test）
   - 运行所有单元测试
   - 生成覆盖率报告
   - 上传到 Codecov

3. **集成测试**（integration-test）
   - 运行集成测试
   - 验证 API 集成

**测试结果监控**：
- **GitHub Actions**：`.github/workflows/ci.yml`
- **Codecov**：覆盖率报告和趋势
- **测试报告**：`htmlcov/index.html`（本地）

#### 8. 测试失败处理

**测试失败时**：
1. **查看测试日志**：GitHub Actions 输出
2. **本地复现**：在本地运行失败的测试
3. **修复问题**：修复代码或更新测试
4. **重新提交**：确保所有测试通过

**禁止操作**：
- ❌ 禁止跳过失败的测试（除非是已知问题）
- ❌ 禁止降低测试覆盖率要求
- ❌ 禁止删除失败的测试

#### 9. 测试最佳实践

**编写测试的原则**：
1. **独立性**：每个测试应该独立运行，不依赖其他测试
2. **可重复性**：测试结果应该一致，不依赖外部状态
3. **快速执行**：单元测试应该快速执行（< 1秒）
4. **清晰命名**：测试名称应该清晰描述测试内容
5. **单一职责**：每个测试只测试一个功能点

**示例**：
```python
# ✅ 好的测试
def test_calculate_bazi_with_valid_date():
    """测试：使用有效日期计算八字"""
    result = calculate_bazi("1990-01-15", "12:00", "male")
    assert result["success"] == True
    assert "bazi" in result

# ❌ 不好的测试
def test_all():
    """测试所有功能"""
    # 测试太多内容，难以定位问题
    ...
```

#### 10. 测试覆盖率监控

**覆盖率报告位置**：
- **本地**：`htmlcov/index.html`
- **CI/CD**：GitHub Actions 输出
- **在线**：Codecov（如果配置）

**覆盖率要求**：
- **整体覆盖率**：≥ 50%
- **核心模块**（server/services/）：≥ 70%
- **API 端点**（server/api/）：≥ 80%
- **工具函数**（server/utils/）：≥ 60%

**查看覆盖率**：
```bash
# 生成 HTML 报告
pytest --cov=server --cov=src --cov-report=html

# 查看报告
open htmlcov/index.html
```

---

### 📝 测试开发检查清单

每次开发新功能时，必须检查：

- [ ] 是否创建了对应的测试文件
- [ ] 是否编写了正常流程测试
- [ ] 是否编写了异常流程测试
- [ ] 是否编写了边界情况测试
- [ ] 测试是否通过本地运行
- [ ] 测试是否通过 CI/CD 验证
- [ ] 覆盖率是否达到要求（≥ 50%）
- [ ] 是否更新了测试文档

---

### 🚨 测试规范违反处理

**如果发现违反测试规范**：
1. **立即修复**：补充缺失的测试
2. **更新规范**：如果规范不合理，更新规范
3. **记录问题**：在开发日志中记录问题
4. **防止再次发生**：更新检查清单

---

**核心要点**：
- **所有新功能必须同步编写测试案例**
- **测试覆盖率必须达到 50% 以上**
- **所有测试必须通过 CI/CD 验证**
- **测试失败必须修复后才能合并代码**

---

## 🏗️ 生产环境架构规范 【必须遵守】

### 🔴 核心原则

> **生产环境架构信息必须记录在开发规范中，确保系统的继承性、稳定性和可用性。**

### 📋 生产环境架构

#### 双机部署架构

```
┌─────────────────────────────────────────────────────────────────┐
│                        生产环境双机架构                          │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  ┌──────────────────────┐         ┌──────────────────────┐    │
│  │      Node1 (主节点)   │         │      Node2 (从节点)   │    │
│  │  8.210.52.217        │         │  47.243.160.43       │    │
│  │  172.18.121.222      │         │  172.18.121.223      │    │
│  ├──────────────────────┤         ├──────────────────────┤    │
│  │  Nginx (80/443)      │◄───────►│  Nginx (80/443)      │    │
│  │  Web (8001)          │         │  Web (8001)          │    │
│  │  MySQL 主库 (3306)   │◄──复制──►│  MySQL 从库 (3306)   │    │
│  │  Redis 主库 (6379)   │◄──复制──►│  Redis 从库 (6379)   │    │
│  │  微服务 (9001-9010)  │         │  微服务 (9001-9010)  │    │
│  └──────────────────────┘         └──────────────────────┘    │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

#### 服务器信息

| 节点 | 公网IP | 内网IP | 角色 | 状态 |
|------|--------|--------|------|------|
| Node1 | 8.210.52.217 | 172.18.121.222 | 主节点（MySQL主/Redis主） | ✅ 运行中 |
| Node2 | 47.243.160.43 | 172.18.121.223 | 从节点（MySQL从/Redis从） | ✅ 运行中 |
| 测试环境 | 123.57.216.15 | - | 测试环境 | ✅ 运行中 |

#### 服务端口清单

| 服务 | 端口 | 说明 |
|------|------|------|
| Nginx | 80, 443 | 负载均衡和反向代理 |
| Web 服务 | 8001 | FastAPI 主服务 |
| bazi-core | 9001 | 八字核心计算服务 |
| bazi-fortune | 9002 | 运势计算服务 |
| bazi-analyzer | 9003 | 八字分析服务 |
| bazi-rule | 9004 | 规则匹配服务 |
| fortune-analysis | 9005 | 运势分析服务 |
| payment-service | 9006 | 支付服务 |
| fortune-rule | 9007 | 运势规则服务 |
| intent-service | 9008 | 意图识别服务 |
| prompt-optimizer | 9009 | 提示优化服务 |
| desk-fengshui | 9010 | 办公桌风水分析服务 |
| MySQL | 3306 | 数据库 |
| Redis | 6379 | 缓存 |

#### 负载均衡配置

**Nginx 负载均衡**：
- **上游服务器**：使用内网IP（172.18.121.222/223）
- **负载均衡算法**：轮询（weight=1）
- **故障转移**：`max_fails=3 fail_timeout=30s`
- **健康检查**：自动检测服务状态，故障时切换到备用节点

**超时配置**（已优化）：
```nginx
proxy_connect_timeout 10s;   # 连接超时：10秒（快速检测服务不可用）
proxy_send_timeout 30s;      # 发送超时：30秒（适合大多数API）
proxy_read_timeout 30s;      # 读取超时：30秒（适合大多数API）
proxy_next_upstream_timeout 5s;  # 故障转移超时：5秒（快速切换）
```

#### 数据库主从复制

**MySQL 主从复制**：
- **主库**：Node1 (172.18.121.222:3306)
- **从库**：Node2 (172.18.121.223:3306)
- **复制用户**：`repl@%`
- **复制方式**：GTID 自动定位
- **状态检查**：
  ```sql
  SHOW SLAVE STATUS\G
  -- Slave_IO_Running: Yes
  -- Slave_SQL_Running: Yes
  -- Seconds_Behind_Master: 0
  ```

**Redis 主从复制**：
- **主库**：Node1 (172.18.121.222:6379)
- **从库**：Node2 (172.18.121.223:6379)
- **复制方式**：自动同步

#### 部署配置信息

**环境变量**：
- **MySQL 密码**：`Yuanqizhan@163`
- **MySQL 复制密码**：`Yuanqizhan@163`
- **SECRET_KEY**：`kx9078L34ZoROnneJu8fMmJ70JImvVan88JYvxiewbE`
- **ACR 用户名**：从环境变量 `ACR_USERNAME` 或 `ACR_ACCESS_KEY_ID` 读取
- **ACR 密码**：从环境变量 `ACR_PASSWORD` 或 `ACR_ACCESS_KEY_SECRET` 读取
- **Git 仓库**：`https://github.com/zhoudengt/HiFate-bazi`

**项目目录**：
- **代码目录**：`/opt/HiFate-bazi`
- **部署配置**：`/opt/HiFate-bazi/deploy/docker`
- **环境变量**：`/opt/HiFate-bazi/.env`
- **日志目录**：`/opt/HiFate-bazi/logs`

---

### 🔧 生产环境部署规范

#### 部署前检查清单

- [ ] 确认服务器已初始化（Docker 已安装）
- [ ] 确认代码已克隆到 `/opt/HiFate-bazi`
- [ ] 确认环境变量已配置（`.env` 文件）
- [ ] 确认 Nginx 配置中的 IP 已替换为内网 IP
- [ ] 确认 gRPC 代码已修复（运行 `scripts/grpc/fix_version_check.py`）
- [ ] 确认 MySQL 主从复制用户已创建
- [ ] 确认 Redis 主从复制已配置

#### 部署步骤

1. **初始化服务器**（首次部署）：
   ```bash
   bash deploy/scripts/init-ecs.sh
   ```

2. **克隆代码**：
   ```bash
   cd /opt/HiFate-bazi
   git clone https://github.com/zhoudengt/HiFate-bazi .
   ```

3. **配置环境变量**：
   ```bash
   cp deploy/env/env.template .env
   vim .env  # 编辑配置
   ```

4. **修复 gRPC 代码**（必须）：
   ```bash
   python3 scripts/grpc/fix_version_check.py
   ```

5. **配置 Nginx**（必须）：
   ```bash
   # 替换 IP 占位符
   sed -i 's/NODE1_IP/172.18.121.222/g' deploy/nginx/conf.d/hifate.conf
   sed -i 's/NODE2_IP/172.18.121.223/g' deploy/nginx/conf.d/hifate.conf
   ```

6. **部署服务**：
   ```bash
   # Node1
   bash deploy/scripts/deploy.sh node1
   
   # Node2（在 Node1 部署完成后）
   bash deploy/scripts/deploy.sh node2
   ```

7. **配置 MySQL 主从复制**（Node2）：
   ```sql
   -- 在 Node1 创建复制用户
   CREATE USER 'repl'@'%' IDENTIFIED BY 'Yuanqizhan@163';
   GRANT REPLICATION SLAVE ON *.* TO 'repl'@'%';
   FLUSH PRIVILEGES;
   
   -- 在 Node2 配置从库
   CHANGE MASTER TO
       MASTER_HOST='172.18.121.222',
       MASTER_USER='repl',
       MASTER_PASSWORD='Yuanqizhan@163',
       MASTER_AUTO_POSITION=1;
   START SLAVE;
   ```

8. **验证部署**：
   ```bash
   # 检查服务状态
   docker ps | grep hifate
   
   # 检查健康状态
   curl http://8.210.52.217/health
   curl http://47.243.160.43/health
   
   # 检查 MySQL 主从复制
   docker exec -it hifate-mysql-slave mysql -uroot -pYuanqizhan@163 -e "SHOW SLAVE STATUS\G"
   ```

#### 日常运维命令

**查看服务状态**：
```bash
# Node1
ssh root@8.210.52.217 "docker ps | grep hifate"

# Node2
ssh root@47.243.160.43 "docker ps | grep hifate"
```

**查看日志**：
```bash
# Web 服务日志
docker logs hifate-web --tail 100

# 微服务日志
docker logs hifate-bazi-core --tail 100

# Nginx 日志
docker logs hifate-nginx --tail 100
```

**重启服务**：
```bash
# 重启单个服务
docker restart hifate-web

# 重启所有服务
cd /opt/HiFate-bazi/deploy/docker
docker-compose -f docker-compose.prod.yml -f docker-compose.node1.yml --env-file /opt/HiFate-bazi/.env restart
```

**更新代码**：
```bash
cd /opt/HiFate-bazi
git pull origin master
# 如果需要重启服务
bash deploy/scripts/deploy.sh node1  # 或 node2
```

---

### ⚠️ 生产环境注意事项

#### 1. 负载均衡配置

**必须使用内网 IP**：
- ✅ 正确：`server 172.18.121.222:8001`
- ❌ 错误：`server 8.210.52.217:8001`（公网IP，延迟高）
- ❌ 错误：`server NODE1_IP:8001`（占位符未替换）

**检查方法**：
```bash
docker exec hifate-nginx cat /etc/nginx/conf.d/hifate.conf | grep upstream
```

#### 2. gRPC 版本兼容性

**部署前必须修复**：
```bash
python3 scripts/grpc/fix_version_check.py
```

**问题现象**：
- 微服务持续重启
- 错误：`AttributeError: '_Server' object has no attribute 'add_registered_method_handlers'`

**解决方案**：
- 运行修复脚本
- 重启微服务

#### 3. Nginx 超时优化

**已优化配置**（提升用户体验）：
- 连接超时：10秒（快速检测服务不可用）
- 发送/读取超时：30秒（适合大多数API）
- 故障转移超时：5秒（快速切换）

#### 4. 服务健康检查

**定期检查**：
- 服务状态：`docker ps | grep hifate`
- 健康检查：`curl http://8.210.52.217/health`
- MySQL 主从复制：`SHOW SLAVE STATUS\G`
- Nginx 状态：`curl http://8.210.52.217/nginx_status`

#### 5. 性能监控

**关键指标**：
- API 响应时间：< 2秒（正常）
- 服务重启次数：0（正常）
- MySQL 主从延迟：0秒（正常）
- 负载均衡状态：两个节点都正常

---

### 📚 相关文档

- **部署文档**：`docs/root_docs/生产环境双机部署指南.md`
- **部署报告**：`docs/root_docs/生产环境双机部署最终报告.md`
- **问题诊断**：`docs/root_docs/双机部署问题诊断报告.md`

---

---

## 📁 前端目录规范 【必须遵守】

### 🔴 核心原则

> **本地前端目录命名为 `local_frontend`，与生产前端部署分离。**

### 📋 目录命名规范

| 目录 | 用途 | 说明 |
|------|------|------|
| **`local_frontend/`** | ✅ **本地前端目录** | 用于本地开发、测试、双机部署 |
| **生产前端** | ✅ **独立部署** | 由前端团队独立部署，不在此仓库 |

### 🔧 配置要求

#### 1. Docker Compose 配置

**生产环境配置** (`deploy/docker/docker-compose.prod.yml`)：
```yaml
volumes:
  - ../../local_frontend:/usr/share/nginx/html/local_frontend:ro
```

**本地前端配置** (`docker-compose.frontend.yml`)：
```yaml
volumes:
  - ./local_frontend:/usr/share/nginx/html:ro
```

#### 2. Nginx 配置

**所有 Nginx 配置文件中的路径**：
```nginx
root /usr/share/nginx/html/local_frontend;
```

#### 3. 后端代码配置

**`server/main.py`** 中的静态文件挂载：
```python
local_frontend_dir = os.path.join(project_root, "local_frontend")
if os.path.exists(local_frontend_dir):
    app.mount("/local_frontend", StaticFiles(directory=local_frontend_dir, html=True), name="local_frontend")
```

### ⚠️ 重要说明

1. **禁止修改生产前端**：生产环境的前端由前端团队独立部署，后端开发人员不得修改
2. **本地前端仅用于开发测试**：`local_frontend` 目录仅用于本地开发、测试环境、双机部署
3. **路径一致性**：所有配置文件中的路径必须统一使用 `local_frontend`
4. **部署脚本更新**：所有部署脚本必须引用 `local_frontend` 目录

### ✅ 检查清单

每次修改前端相关配置时，必须检查：

- [ ] Docker Compose 配置中的路径是否为 `local_frontend`
- [ ] Nginx 配置中的路径是否为 `local_frontend`
- [ ] 后端代码中的路径是否为 `local_frontend`
- [ ] 部署脚本中的路径是否为 `local_frontend`
- [ ] 文档中的路径是否为 `local_frontend`

---

**核心要点**：
- **生产环境架构信息必须记录在开发规范中**
- **部署前必须检查所有配置项**
- **必须使用内网 IP 进行负载均衡**
- **部署前必须修复 gRPC 代码**
- **定期检查服务健康状态**
- **本地前端目录必须使用 `local_frontend`，与生产前端分离**
