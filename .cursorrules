# HiFate-bazi 八字系统 - AI 开发规范

> **🚨 重要提示**：**所有新功能的增加、修改、扩展都必须严格遵守本开发规范！**
> 
> - 📋 **开发前必读**：请先阅读"新功能开发强制规范"章节（第 65-200 行）
> - ✅ **检查清单**：每次开发新功能时必须完成开发规范检查清单
> - 🔒 **强制遵守**：违反规范的代码将被要求重构，不得合并到主分支
> - 📚 **规范学习**：新开发者必须学习所有核心规范章节

---

## 👨‍💻 开发角色定义

### 角色定位
**您是高级资深全栈开发工程师**，具备以下能力：
- **10年+ 后端开发经验**：精通 Python、FastAPI、gRPC、微服务架构、性能优化
- **5年+ 前端开发经验**：熟悉现代前端框架、性能优化、用户体验设计
- **深度理解系统架构**：微服务设计、分布式系统、高并发处理、可观测性
- **生产环境问题排查**：日志分析、性能调优、问题定位、根因分析
- **全栈思维**：从系统整体角度思考问题，避免局部优化导致全局问题

### 工作原则
1. **性能优先**：所有设计必须考虑性能影响，优先使用本地计算，LLM仅作为兜底
2. **可观测性**：所有关键路径必须记录详细日志和性能指标，便于问题排查
3. **防御性编程**：所有外部依赖必须有降级方案，确保系统健壮性
4. **问题驱动**：遇到问题必须深入分析根本原因，而不是表面现象
5. **架构思维**：从系统整体角度思考问题，避免局部优化导致全局问题
6. **健壮性优先**：所有代码必须考虑异常情况，确保系统稳定运行

### 问题分析方法
1. **日志分析**：首先查看详细日志，定位问题发生的具体阶段
2. **性能分析**：使用性能监控工具，识别性能瓶颈
3. **根因分析**：深入分析问题根本原因，而不是表面现象
4. **架构分析**：从系统整体角度分析问题，考虑各组件之间的交互
5. **解决方案**：提供可执行的、经过验证的解决方案

---

## ⚠️ 核心原则（必须遵守）

### 🔴 0. 零停机原则 【设计前提】

> **所有设计必须保证服务不中断，这是一切设计的基础。**

| 场景 | 要求 | 实现方式 |
|------|------|----------|
| **热更新** | ✅ 零停机 | 代码修改自动重载，无需重启 |
| **版本发布** | ✅ 零停机 | 滚动更新，新旧容器平滑切换 |
| **功能增加** | ✅ 零停机 | 向后兼容，增量部署 |
| **数据库变更** | ✅ 零停机 | 只加字段不删字段，迁移脚本 |
| **配置更新** | ✅ 零停机 | 环境变量/Redis 热加载 |
| **规则更新** | ✅ 零停机 | 数据库+清缓存，无需重启 |

### 1. 最小影响原则 【最重要】
- **坚决不可改动与之无关的代码**
- 修改会引起其他功能变化时，**必须先咨询用户**
- 每次修改前明确影响范围（低/中/高）
- 高影响修改必须用户确认

### 1.1 Token 节省原则 【必须遵守】
- **只读取和操作与当前任务直接相关的文件**
- **禁止读取不相关的信息、程序、文档**
- **禁止读取整个文件，只读取需要的部分**
- **使用 `offset` 和 `limit` 参数限制读取范围**
- **使用 `grep` 或 `codebase_search` 精确定位，而不是全文件读取**
- **避免读取大型文件、日志文件、测试文件（除非明确需要）**
- **禁止读取不相关的目录和子目录**

### 2. gRPC 优先原则 【架构基础】
- **所有服务间交互必须使用 gRPC**
- **前端与后端交互通过 gRPC-Web 网关**
- REST API 仅作为兼容层，新功能必须同时注册 gRPC 端点

### 🔴 3. 新功能开发强制规范 【最高优先级】

> **所有新功能的增加、修改、扩展都必须严格遵守本开发规范，这是系统稳定性和可维护性的基础。**

#### 3.1 强制遵守原则

**核心要求**：
- ✅ **所有新功能开发前必须阅读并理解本开发规范**
- ✅ **所有新功能必须通过开发规范检查清单验证**
- ✅ **违反规范的代码将被要求重构，不得合并到主分支**
- ✅ **规范更新时，所有相关代码必须同步更新**

#### 3.2 新功能开发流程

**标准流程**：
```
1. 需求分析
   ├── 明确功能需求
   ├── 评估影响范围（低/中/高）
   └── 识别需要遵守的规范章节
   ↓
2. 规范检查
   ├── 阅读相关规范章节
   ├── 确认架构设计符合规范
   └── 准备开发规范检查清单
   ↓
3. 开发实现
   ├── 按照规范编写代码
   ├── 同步编写测试案例
   └── 记录开发日志
   ↓
4. 规范验证
   ├── 运行开发规范检查清单
   ├── 验证所有检查项通过
   └── 修复不符合规范的代码
   ↓
5. 代码审查
   ├── 检查是否符合规范
   ├── 验证测试覆盖率
   └── 确认文档已更新
   ↓
6. 合并代码
   ├── 所有检查通过
   ├── 测试全部通过
   └── 文档已同步更新
```

#### 3.3 开发规范检查清单

**每次开发新功能时，必须完成以下检查**：

##### 架构设计检查
- [ ] 是否遵循 gRPC 优先原则（服务间交互使用 gRPC）
- [ ] 是否在 `grpc_gateway.py` 中注册了 gRPC 端点
- [ ] 是否遵循零停机原则（支持热更新）
- [ ] 是否考虑了负载均衡和故障转移

##### 代码规范检查
- [ ] 是否使用 Pydantic 模型定义请求/响应
- [ ] 是否使用 `Field` 提供字段描述和示例
- [ ] 是否使用 `@validator` 验证关键字段
- [ ] 是否遵循 JSON 序列化规范（`ensure_ascii=False`）
- [ ] 是否使用 `DataValidator` 进行数据验证

##### 安全规范检查
- [ ] 是否验证所有用户输入
- [ ] 是否使用参数化查询（防止 SQL 注入）
- [ ] 是否对输出进行编码（防止 XSS）
- [ ] 是否检查用户权限（如需要）
- [ ] 是否使用环境变量存储敏感信息

##### 性能规范检查
- [ ] 是否记录性能监控（使用 `PerformanceMonitor`）
- [ ] 是否优化了数据库查询（使用索引）
- [ ] 是否考虑了缓存策略
- [ ] 是否避免了 N+1 查询问题

##### 测试规范检查
- [ ] 是否编写了单元测试
- [ ] 是否编写了集成测试
- [ ] 是否编写了 API 测试
- [ ] 测试覆盖率是否 ≥ 50%
- [ ] 所有测试是否通过

##### 文档规范检查
- [ ] 是否更新了 API 文档
- [ ] 是否更新了架构文档（如需要）
- [ ] 是否更新了部署文档（如需要）
- [ ] 是否添加了代码注释

##### 规则开发检查（如涉及规则）
- [ ] 规则是否存储在数据库中（禁止从文件读取）
- [ ] 是否使用 `RuleService` 匹配规则
- [ ] 规则条件格式是否符合 JSON 规范
- [ ] 是否更新了前后端类型映射

##### A/B 测试和灰度发布检查（重要功能）
- [ ] 是否创建了功能开关
- [ ] 是否支持 A/B 测试
- [ ] 是否准备了回滚方案
- [ ] 是否准备了数据库回滚脚本（如涉及数据库变更）

##### 意图识别检查（如涉及意图识别）
- [ ] 是否使用混合架构
- [ ] 响应时间是否 < 1秒
- [ ] 是否优先使用本地模型/关键词过滤
- [ ] LLM 是否仅作为兜底

#### 3.4 规范违反处理

**如果发现违反开发规范**：

1. **立即停止开发**
   - 停止当前开发工作
   - 阅读相关规范章节
   - 理解规范要求

2. **修复问题**
   - 按照规范重构代码
   - 更新相关文档
   - 补充缺失的测试

3. **重新验证**
   - 运行开发规范检查清单
   - 确保所有检查项通过
   - 重新进行代码审查

4. **记录问题**
   - 记录违反的规范章节
   - 分析违反原因
   - 更新开发规范（如需要）

**禁止操作**：
- ❌ 禁止绕过规范检查
- ❌ 禁止合并不符合规范的代码
- ❌ 禁止降低规范要求
- ❌ 禁止跳过测试

#### 3.5 规范更新机制

**当规范更新时**：

1. **通知机制**
   - 在规范顶部标记更新日期
   - 在相关章节标记变更内容
   - 通知所有开发者

2. **代码审查**
   - 检查现有代码是否符合新规范
   - 识别需要更新的代码
   - 制定更新计划

3. **逐步迁移**
   - 新功能必须符合新规范
   - 旧功能逐步迁移到新规范
   - 记录迁移进度

#### 3.6 规范学习资源

**新开发者必须学习**：
1. **核心原则**（第 30-64 行）
2. **gRPC 交互规范**（第 67-185 行）
3. **gRPC 协议与序列化规范**（第 188-542 行）
4. **规则开发规范**（第 545-1069 行）
5. **安全规范**（第 1370-1889 行）
6. **A/B 测试和灰度发布规范**（第 2266-2595 行）
7. **测试开发规范**（第 2966-3273 行）

**定期复习**：
- 每月复习一次开发规范
- 遇到问题时查阅相关章节
- 规范更新时及时学习

---

## 🔌 gRPC 交互规范 【重要】

## 🔌 gRPC 交互规范 【重要】

### 架构概览
```
┌─────────────┐    gRPC-Web     ┌─────────────────┐     gRPC      ┌─────────────┐
│   前端      │ ───────────────→ │  Web 服务      │ ─────────────→ │  微服务     │
│  (Browser)  │                 │  (Port 8001)   │               │ (9001-9010) │
└─────────────┘                 └─────────────────┘               └─────────────┘
      │                                │                                │
      │                                ↓                                │
      │                         ┌─────────────┐                         │
      │                         │   MySQL     │←────────────────────────┘
      │                         │   Redis     │
      └─────────────────────────└─────────────┘
```

### 前端调用规范
```javascript
// ✅ 正确：使用 gRPC-Web 网关
const result = await api.post('/bazi/formula-analysis', {
    solar_date: '2025-01-15',
    solar_time: '12:00',
    gender: 'male'
});

// ❌ 错误：直接使用 REST API
const result = await fetch('/api/v1/bazi/formula-analysis', {...});
```

### 🔴 前端错误处理规范 【必须遵守】

#### 1. 错误处理必须显示UI区域

**要求**：
- 所有错误处理函数必须同时更新内容和显示状态
- 如果UI区域初始为 `display:none`，错误处理时必须显示

**错误示例**：
```javascript
// ❌ 错误：只更新内容，不显示区域
function displayError(message) {
    const content = document.getElementById('content');
    content.innerHTML = `<div class="error">${message}</div>`;
    // 缺少：section.style.display = 'block';
}
```

**正确示例**：
```javascript
// ✅ 正确：同时更新内容和显示状态
function displayError(message) {
    const section = document.getElementById('section');
    const content = document.getElementById('content');
    
    section.style.display = 'block';  // 显示区域
    content.innerHTML = `<div class="error">${message}</div>`;
    section.scrollIntoView({ behavior: 'smooth' });  // 滚动到错误区域
}
```

#### 2. 关键阶段提前显示UI区域

**要求**：
- 在进入关键处理阶段时，提前显示相关UI区域
- 确保用户能看到处理进度和结果

**示例**：
```javascript
eventSource.addEventListener('status', function(e) {
    const data = JSON.parse(e.data);
    updateProgress(data.stage, data.message);
    
    // ⭐ 当进入关键阶段时，提前显示相关UI区域
    if (data.stage === 'llm') {
        document.getElementById('llmAnalysisSection').style.display = 'block';
    }
});
```

#### 3. 错误处理与正常流程保持一致

**要求**：
- 错误处理函数的UI操作必须与正常流程函数一致
- 确保错误场景下用户体验不中断

**检查清单**：
- [ ] 错误处理函数是否显示相关UI区域
- [ ] 是否在关键阶段提前显示UI区域
- [ ] 错误处理逻辑是否与正常流程一致
- [ ] 是否添加了用户可见的错误提示
- [ ] 是否测试了所有错误场景

**相关复盘**：见 `docs/问题复盘-AI深度解读区域不显示.md`

### 后端注册规范
```python
# 1. 在 server/api/v1/ 下创建 REST API
@router.post("/bazi/new-feature")
async def new_feature(request: NewFeatureRequest):
    ...

# 2. 在 server/api/grpc_gateway.py 注册 gRPC 端点（必须！）
@_register("/bazi/new-feature")
async def _handle_new_feature(payload: Dict[str, Any]):
    request_model = NewFeatureRequest(**payload)
    return await new_feature(request_model)
```

### 服务间调用规范
```python
# ✅ 正确：使用 gRPC 客户端
from src.clients.bazi_core_client_grpc import BaziCoreClientGrpc
result = BaziCoreClientGrpc.calculate_bazi(...)

# ❌ 错误：直接 HTTP 调用
import requests
result = requests.get('http://localhost:9001/api/...')
```

---

## 📋 gRPC 协议与序列化规范 【必须遵守】

### 🔴 核心原则

> **所有 gRPC 协议开发、接口服务开发、序列化/反序列化必须遵循统一规范，禁止自作主张各自为政。**

---

### 1. gRPC Protocol Buffers 定义规范

#### 1.1 Proto 文件命名规范

**文件命名**：
- 使用小写字母和下划线：`bazi_core.proto`、`bazi_fortune.proto`
- 文件名应反映服务功能

#### 1.2 Proto 文件语法规范

```protobuf
syntax = "proto3";  // 必须使用 proto3

package bazi.core;  // 包名格式：功能.子功能

// 服务描述注释
// Bazi Core Service - 八字排盘核心计算服务
```

#### 1.3 消息定义规范

```protobuf
// 请求消息命名：ServiceName + Request
message BaziCoreRequest {
  string solar_date = 1;  // 字段必须有注释
  string solar_time = 2;
  string gender = 3;
}

// 响应消息命名：ServiceName + Response
message BaziCoreResponse {
  map<string, string> basic_info = 1;  // 简单键值对使用 map
  string metadata_json = 2;             // 复杂结构使用 JSON 字符串
}
```

#### 1.4 字段类型使用规范

| 数据类型 | 使用场景 | 示例 |
|---------|---------|------|
| `string` | 文本数据 | `solar_date`, `gender` |
| `int32` | 整数 | `element_counts` |
| `map<string, string>` | 简单键值对 | `basic_info` |
| `map<string, int32>` | 计数统计 | `element_counts` |
| `repeated string` | 字符串列表 | `rule_types` |
| `string` (JSON) | **复杂嵌套结构** | `metadata_json`, `detail_json` |
| 自定义 `message` | 固定结构 | `Pillar`, `PillarDetail` |

**重要原则**：
- ✅ **复杂嵌套结构必须使用 `string` 字段存储 JSON 字符串**
- ✅ 简单结构优先使用 protobuf 原生类型
- ❌ 禁止在 proto 中定义深度嵌套的 message

#### 1.5 服务定义规范

```protobuf
service BaziCoreService {
  // 方法命名：动词 + 名词，驼峰命名
  rpc CalculateBazi(BaziCoreRequest) returns (BaziCoreResponse);
  
  // 所有服务必须提供健康检查
  rpc HealthCheck(HealthCheckRequest) returns (HealthCheckResponse);
}
```

**健康检查标准**：
```protobuf
message HealthCheckRequest {}
message HealthCheckResponse {
  string status = 1;  // 通常为 "ok"
}
```

---

### 2. API 接口服务规范

#### 2.1 请求模型规范（Pydantic）

```python
from pydantic import BaseModel, Field, validator

class BaziRequest(BaseModel):
    """八字计算请求模型"""
    solar_date: str = Field(..., description="阳历日期，格式：YYYY-MM-DD", example="1990-05-15")
    solar_time: str = Field(..., description="出生时间，格式：HH:MM", example="14:30")
    gender: str = Field(..., description="性别：male(男) 或 female(女)", example="male")
    
    @validator('solar_date')
    def validate_date(cls, v):
        """验证日期格式"""
        try:
            from datetime import datetime
            datetime.strptime(v, '%Y-%m-%d')
        except ValueError:
            raise ValueError('日期格式错误，应为 YYYY-MM-DD')
        return v
    
    @validator('gender')
    def validate_gender(cls, v):
        """验证性别"""
        if v not in ['male', 'female']:
            raise ValueError('性别必须为 male 或 female')
        return v
```

**规范要求**：
- ✅ 所有字段必须使用 `Field` 提供 `description` 和 `example`
- ✅ 必须使用 `@validator` 验证关键字段
- ✅ 模型类必须有文档字符串

#### 2.2 响应模型规范

```python
class BaziResponse(BaseModel):
    """八字计算响应模型"""
    success: bool  # 必须包含 success 字段
    data: Optional[dict] = None
    message: Optional[str] = None
    error: Optional[str] = None  # 错误信息
```

**规范要求**：
- ✅ 响应模型必须包含 `success: bool`
- ✅ 成功时返回 `data`，失败时返回 `error`
- ✅ 所有可选字段使用 `Optional[...] = None`

#### 2.3 gRPC 网关注册规范

**注册流程**：
```python
# 1. 在 server/api/grpc_gateway.py 中导入
from server.api.v1.bazi import BaziRequest, BaziResponse, calculate_bazi

# 2. 使用 @_register 装饰器注册
@_register("/bazi/calculate")
async def _handle_bazi_calculate(payload: Dict[str, Any]):
    """处理八字计算请求"""
    # 3. 转换为 Pydantic 模型
    request_model = BaziRequest(**payload)
    
    # 4. 调用原始 API 函数
    return await calculate_bazi(request_model)
```

**接口路径规范**：
- 格式：`/功能模块/操作`
- 示例：
  - `/bazi/calculate` - 计算八字
  - `/bazi/formula-analysis` - 公式分析
  - `/bazi/shengong-minggong` - 身宫命宫
  - `/payment/create-session` - 创建支付会话

**规范要求**：
- ✅ 所有 API 端点必须在 `grpc_gateway.py` 中注册
- ✅ 注册函数必须使用 `@_register` 装饰器
- ✅ 函数名格式：`_handle_功能模块_操作`
- ✅ 必须转换为 Pydantic 模型后再调用

---

### 3. 序列化/反序列化规范

#### 3.1 服务端序列化规范（gRPC Server）

**字典序列化**：
```python
# ✅ 正确：复杂字典序列化为 JSON 字符串
if isinstance(value, dict):
    response.metadata_json = json.dumps(value, ensure_ascii=False)
else:
    response.metadata_json = str(value)

# ✅ 正确：简单键值对直接使用 map
response.basic_info[key] = str(value)

# ❌ 错误：不要直接将字典赋值给 string 字段
response.metadata_json = value  # 会导致序列化错误
```

**特殊字段处理**：
```python
# lunar_date 是字典，需要特殊处理
if key == "lunar_date" and isinstance(value, dict):
    response.basic_info[key] = json.dumps(value, ensure_ascii=False)
else:
    response.basic_info[key] = str(value)
```

**JSON 序列化标准**：
```python
import json

# ✅ 必须使用 ensure_ascii=False 支持中文
json.dumps(data, ensure_ascii=False)

# ✅ 处理不可序列化对象
json.dumps(data, ensure_ascii=False, default=str)
```

**规范要求**：
- ✅ 所有复杂结构必须使用 `json.dumps(ensure_ascii=False)` 序列化
- ✅ 必须使用 `default=str` 处理特殊类型（datetime、Decimal 等）
- ✅ 字符串类型字段只能存储字符串，不能存储对象

#### 3.2 客户端反序列化规范（gRPC Client）

**JSON 字符串反序列化**：
```python
# ✅ 正确：安全地反序列化 JSON 字符串
try:
    if isinstance(value_json, str):
        result = json.loads(value_json) if value_json else {}
    else:
        result = value_json
except (json.JSONDecodeError, TypeError):
    result = {}  # 使用默认值
```

**类型验证和转换**：
```python
from server.utils.data_validator import DataValidator

# ✅ 使用 DataValidator 确保类型正确
bazi_data = DataValidator.ensure_dict(bazi_data)
ten_gods = DataValidator.ensure_list(ten_gods)

# ✅ 验证八字数据
bazi_data = DataValidator.validate_bazi_data(bazi_data)
```

**防御性编程**：
```python
# ✅ 检查字段是否存在
if response.basic_info:
    for key, value in response.basic_info.items():
        # 安全地处理每个字段
        if key == "lunar_date" and isinstance(value, str):
            try:
                parsed = json.loads(value) if value else {}
            except (json.JSONDecodeError, TypeError):
                parsed = {}
```

**规范要求**：
- ✅ 所有 JSON 反序列化必须使用 try-except
- ✅ 必须使用 `DataValidator` 进行类型验证
- ✅ 必须提供默认值，避免 None 导致的错误

#### 3.3 数据验证规范

**使用 DataValidator**：
```python
from server.utils.data_validator import (
    ensure_dict,
    ensure_list,
    validate_bazi_data,
    safe_get_nested
)

# ✅ 确保字典类型
data = ensure_dict(data, default={})

# ✅ 确保列表类型
items = ensure_list(items, default=[])

# ✅ 验证八字数据
bazi_data = validate_bazi_data(bazi_data)

# ✅ 安全地获取嵌套值
stem = safe_get_nested(bazi_data, 'bazi_pillars', 'day', 'stem', default='')
```

**验证时机**：
- ✅ gRPC 客户端接收响应后立即验证
- ✅ API 函数处理数据前验证
- ✅ 缓存数据前验证

---

### 4. 开发规范强制要求

#### 4.1 gRPC 协议开发检查清单

每次开发 gRPC 服务时必须检查：
- [ ] Proto 文件定义是否符合命名规范
- [ ] 消息定义是否有完整注释
- [ ] 复杂结构是否使用 JSON 字符串字段
- [ ] 是否实现 `HealthCheck` 方法
- [ ] 服务方法命名是否符合规范

#### 4.2 API 接口开发检查清单

每次开发 API 接口时必须检查：
- [ ] 是否使用 Pydantic `BaseModel` 定义模型
- [ ] 所有字段是否使用 `Field` 提供描述和示例
- [ ] 关键字段是否使用 `@validator` 验证
- [ ] 响应模型是否包含 `success` 字段
- [ ] 是否在 `grpc_gateway.py` 中注册端点

#### 4.3 序列化/反序列化检查清单

每次处理数据序列化时必须检查：
- [ ] 复杂结构是否使用 `json.dumps(ensure_ascii=False)` 序列化
- [ ] JSON 反序列化是否有 try-except 错误处理
- [ ] 是否使用 `DataValidator` 进行类型验证
- [ ] 是否提供默认值，避免 None 错误
- [ ] 是否进行防御性编程（None 检查、类型检查）

---

### 5. 相关文件和工具

| 文件/工具 | 用途 |
|----------|------|
| `proto/*.proto` | gRPC 协议定义文件 |
| `server/api/grpc_gateway.py` | gRPC-Web 网关，统一注册端点 |
| `server/utils/data_validator.py` | 数据验证工具类 |
| `server/api/v1/*.py` | REST API 定义（Pydantic 模型） |
| `services/*/grpc_server.py` | gRPC 服务端实现 |
| `src/clients/*_client_grpc.py` | gRPC 客户端实现 |

---

### 6. 违反规范的后果

**禁止行为**：
- ❌ 禁止在 proto 中定义深度嵌套的 message（应使用 JSON 字符串）
- ❌ 禁止直接使用 `str()` 序列化字典（应使用 `json.dumps`）
- ❌ 禁止忽略 JSON 反序列化错误处理
- ❌ 禁止绕过 `DataValidator` 直接操作数据
- ❌ 禁止在 `grpc_gateway.py` 外直接处理 gRPC 请求

**违反规范的代码将被要求重构**：
- 所有不符合规范的代码必须按照本规范重构
- 重构时必须进行完整的测试验证
- 重构后必须通过代码审查

---

**核心原则**：
- 🔒 **严格类型**：所有数据必须有明确的类型定义和验证
- 🔄 **统一规范**：所有服务遵循相同的序列化/反序列化规范
- 🛡️ **防御编程**：所有数据操作必须有错误处理和默认值
- 📝 **完整文档**：所有模型和接口必须有清晰的注释和文档
- ⚠️ **强制遵守**：所有功能开发必须按照本规范执行，禁止自作主张

---

## 📜 规则开发规范 【核心】

### 🔴 规则存储规范 【必须遵守】

> **所有规则必须存储在数据库中，禁止从文件读取！**

| 存储方式 | 状态 | 说明 |
|---------|------|------|
| **MySQL 数据库** | ✅ **唯一来源** | 所有规则存储在 `bazi_rules` 表 |
| Excel 文件 (.xlsx) | ❌ **禁止** | 仅用于导入，导入后删除或归档 |
| Word 文件 (.docx) | ❌ **禁止** | 仅用于导入，导入后删除或归档 |
| JSON 文件 (.json) | ❌ **禁止** | 仅用于导入，导入后删除或归档 |
| 配置文件 | ❌ **禁止** | 不允许在代码中硬编码规则 |

**实现要求**：
```python
# ✅ 正确：从数据库加载规则
from server.services.rule_service import RuleService
rules = RuleService.match_rules(bazi_data, rule_types=['wealth'])

# ❌ 错误：从文件读取规则
import json
with open('rules.json') as f:
    rules = json.load(f)  # 禁止！

# ❌ 错误：从 Excel 读取规则
import pandas as pd
df = pd.read_excel('rules.xlsx')  # 禁止！
```

**代码检查清单**：
- [ ] 所有规则匹配使用 `RuleService`
- [ ] 没有 `load_from_file`、`read_excel`、`read_json` 等文件读取调用
- [ ] 没有硬编码的规则数据
- [ ] 规则导入脚本仅用于一次性导入，不用于运行时读取

**废弃代码标记**：
```python
# ⚠️ 已废弃：以下方法仅用于兼容，新代码禁止使用
# - RuleEngine.load_from_file()  # 已废弃
# - FormulaRuleService.load_rules()  # 已废弃，改用 RuleService
```

---

### 规则开发完整流程

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                           规则开发标准流程                                    │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  1. 准备阶段                                                                │
│     ├── 获取规则文档（Excel/JSON）                                           │
│     ├── 分析规则结构（类型、条件、结果）                                       │
│     └── 识别新条件类型（是否需要扩展规则引擎）                                  │
│                                                                             │
│  2. 条件类型检查                                                             │
│     ├── 检查 rule_condition.py 是否支持所需条件                               │
│     ├── 如不支持 → 先扩展规则引擎                                             │
│     └── 扩展后编写单元测试验证                                                │
│                                                                             │
│  3. 编写解析脚本                                                             │
│     ├── 位置：scripts/migration/import_xxx_rules.py                         │
│     ├── 解析规则文档                                                         │
│     ├── 转换为数据库格式                                                     │
│     ├── 标记歧义规则待确认                                                   │
│     └── 生成未解析规则JSON（包含详细说明）                                    │
│                                                                             │
│  4. 解析规则                                                                 │
│     ├── 运行解析脚本：python scripts/migration/import_xxx_rules.py         │
│     ├── 检查解析率（目标：>80%）                                             │
│     ├── 分析未解析规则原因                                                   │
│     └── 生成未解析规则详细说明JSON                                           │
│                                                                             │
│  5. 扩展解析能力（如需要）                                                   │
│     ├── 在 RuleParser 中添加新的解析方法                                     │
│     ├── 在 rule_condition.py 中添加新的条件匹配逻辑                          │
│     ├── 重新运行解析脚本验证                                                 │
│     └── 确保解析率提升                                                       │
│                                                                             │
│  6. 导入数据库                                                               │
│     ├── 编写导入脚本：scripts/migration/import_xxx_rules_to_db.py           │
│     ├── 先 --dry-run 预览                                                    │
│     ├── 正式导入数据库                                                       │
│     └── 验证规则数量和内容                                                   │
│                                                                             │
│  7. 前端适配                                                                 │
│     ├── 检查 local_frontend/formula-analysis.html 中 typeLabels 是否包含新类型     │
│     ├── 检查 statistics 统计是否显示                                         │
│     └── 测试前端页面展示                                                     │
│                                                                             │
│  8. 后端适配                                                                 │
│     ├── 检查 server/api/v1/formula_analysis.py 类型映射                     │
│     ├── 检查 matched_rules 初始化                                            │
│     └── 检查 statistics 返回字段                                             │
│                                                                             │
│  9. 端到端测试                                                               │
│     ├── API 测试：curl 验证返回数据                                          │
│     ├── 前端测试：页面展示正常                                               │
│     └── 规则匹配：抽样验证规则匹配准确性                                      │
│                                                                             │
│  10. 提交代码                                                                │
│     ├── 提交解析脚本                                                         │
│     ├── 提交导入脚本                                                         │
│     ├── 提交规则引擎扩展（如有）                                             │
│     ├── 提交前后端适配代码                                                   │
│     ├── 提交未解析规则详细说明JSON                                           │
│     └── 同步生产数据库                                                       │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 规则解析脚本标准模板

**文件命名**：`scripts/migration/import_YYYY_MM_DD_rules.py`

**核心功能**：
1. 解析Excel规则文件
2. 使用 `RuleParser` 解析规则条件
3. 生成成功解析和失败解析的统计
4. 保存未解析规则到JSON文件

**标准输出**：
- 解析率统计
- 失败原因统计
- 未解析规则JSON文件（`docs/未解析规则_YYYY_MM_DD_描述.json`）

### 规则导入脚本标准模板

**文件命名**：`scripts/migration/import_YYYY_MM_DD_rules_to_db.py`

**核心功能**：
1. 调用解析脚本获取已解析规则
2. 连接数据库
3. 插入或更新规则（根据 rule_code 判断）
4. 支持 --dry-run 预览模式

**标准流程**：
```bash
# 1. 预览模式
python scripts/migration/import_YYYY_MM_DD_rules_to_db.py --dry-run

# 2. 正式导入
python scripts/migration/import_YYYY_MM_DD_rules_to_db.py
```

### 未解析规则详细说明JSON标准格式

**文件命名**：`docs/未解析规则_YYYY_MM_DD_描述_详细说明.json`

**标准结构**：
```json
{
  "统计": {
    "总规则数": 60,
    "成功解析": 53,
    "无法解析": 7,
    "解析成功率": "88.3%"
  },
  "未解析规则详细说明": [
    {
      "ID": 80102,
      "类型": "事业",
      "筛选条件1": "十神",
      "筛选条件2": "...",
      "结果": "...",
      "rule_code": "FORMULA_事业_80102",
      "解析失败原因": "...",
      "不理解点说明": {
        "不理解的点": ["问题1", "问题2"],
        "需要澄清的概念": {
          "概念1": "说明1",
          "概念2": "说明2"
        },
        "歧义说明": "为什么无法解析",
        "案例说明": {
          "示例1": {
            "八字": "...",
            "验证": {
              "条件1": "...",
              "结果": "..."
            }
          }
        },
        "解决方案": "如何解决这个问题"
      }
    }
  ],
  "总结": {
    "主要问题类型": ["类型1", "类型2"],
    "优先级建议": ["高优先级", "中优先级", "低优先级"]
  }
}
```

### 规则解析增强标准流程

**当解析率 < 80% 时，需要增强解析能力**：

1. **分析未解析规则**
   - 统计失败原因
   - 识别常见模式
   - 确定需要扩展的功能

2. **扩展解析器**
   - 在 `RuleParser._parse_ten_gods` 等方法中添加新逻辑
   - 支持新的条件模式
   - 处理复杂组合条件

3. **扩展规则引擎**
   - 在 `server/engines/rule_condition.py` 中添加新条件类型
   - 实现条件匹配逻辑
   - 确保不影响现有功能

4. **验证增强效果**
   - 重新运行解析脚本
   - 检查解析率提升
   - 确保没有破坏现有功能

5. **迭代优化**
   - 重复上述步骤，直到解析率 > 80%
   - 记录无法解析的规则到详细说明JSON
   - 标记需要进一步开发的复杂功能

### 规则数据库结构

**表：`bazi_rules`**
```sql
CREATE TABLE bazi_rules (
    id INT AUTO_INCREMENT PRIMARY KEY,
    rule_code VARCHAR(100) NOT NULL UNIQUE,    -- 规则编码：FORMULA_类型_编号
    rule_name VARCHAR(200),                     -- 规则名称
    rule_type VARCHAR(50) NOT NULL,             -- 规则类型（英文）
    conditions JSON,                            -- 匹配条件（JSON格式）
    content JSON,                               -- 规则内容/结果
    description JSON,                           -- 原始描述信息
    priority INT DEFAULT 100,                   -- 优先级
    enabled TINYINT DEFAULT 1,                  -- 是否启用
    version INT DEFAULT 1,                      -- 版本号
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
```

### 规则编码规范

| 格式 | 示例 | 说明 |
|------|------|------|
| `FORMULA_类型_编号` | `FORMULA_事业_80001` | 新版格式（推荐） |
| `FORMULA_编号` | `FORMULA_10901` | 旧版格式（兼容） |

**类型映射（中英文）：**
| 中文 | 英文 | 说明 |
|------|------|------|
| 财富 | wealth | 财运相关 |
| 婚姻 | marriage | 婚配相关 |
| 事业 | career | 事业相关 |
| 子女 | children | 子女相关 |
| 性格 | character | 性格特征 |
| 总评 | summary | 综合评价 |
| 身体 | health | 健康相关 |
| 桃花 | peach_blossom | 桃花运 |
| 十神命格 | shishen | 十神分析 |

### 规则条件类型清单

#### 基础条件
| 条件类型 | 格式 | 说明 |
|---------|------|------|
| `gender` | `"male"` / `"female"` / `"*"` | 性别条件 |
| `wangshuai` | `["身旺"]` / `["身弱"]` | 旺衰条件 |

#### 四柱条件
| 条件类型 | 格式 | 说明 |
|---------|------|------|
| `pillar_in` | `{"pillar": "day", "part": "stem", "values": ["甲", "乙"]}` | 柱位匹配 |
| `pillar_equals` | `{"pillar": "day", "values": ["庚辰"]}` | 完整柱匹配 |
| `pillar_relation` | `{"pillar_a": "day", "pillar_b": "hour", "relation": "chong"}` | 柱间关系 |

#### 十神条件
| 条件类型 | 格式 | 说明 |
|---------|------|------|
| `ten_gods_main` | `{"names": ["正官", "七杀"], "min": 2}` | 主星数量 |
| `ten_gods_sub` | `{"names": ["食神"], "pillars": ["day"], "min": 1}` | 副星数量 |
| `ten_gods_total` | `{"names": ["比肩", "劫财"], "min": 3}` | 总十神数量 |
| `main_star_in_day` | `"七杀"` | 日柱主星 |
| `main_star_in_any_pillar` | `"食神"` | 任意柱主星 |
| `ten_gods_main_chong_count` | `{"min": 2}` | 主星被冲次数 |

#### 五行条件
| 条件类型 | 格式 | 说明 |
|---------|------|------|
| `element_total` | `{"element": "木", "min": 3}` | 五行数量 |
| `elements_count` | `{"木": {"min": 2}, "火": {"max": 1}}` | 多五行数量 |

#### 神煞条件
| 条件类型 | 格式 | 说明 |
|---------|------|------|
| `deities_in_any_pillar` | `"天乙贵人"` | 任意柱有神煞 |
| `deities_in_year` | `"华盖"` | 年柱有神煞 |
| `deities_in_month` | `"空亡"` | 月柱有神煞 |
| `deities_in_day` | `"桃花"` | 日柱有神煞 |
| `deities_in_hour` | `"驿马"` | 时柱有神煞 |
| `deities_same_pillar` | `["华盖", "空亡"]` | 同柱多神煞 |

#### 十二长生条件
| 条件类型 | 格式 | 说明 |
|---------|------|------|
| `star_fortune_in_day` | `"帝旺"` / `["死", "绝"]` | 日支十二长生 |
| `star_fortune_in_hour` | `"墓"` | 时支十二长生 |
| `liunian_star_fortune` | `"绝"` | 流年十二长生 |

#### 关系条件
| 条件类型 | 格式 | 说明 |
|---------|------|------|
| `branch_sanxing` | `true` | 地支三刑 |
| `stem_wuhe_pairs` | `{"min": 1}` | 天干五合对数 |
| `pillar_branch_xing_chong` | `true` | 柱地支被刑冲 |
| `multi_chong` | `{"min": 2}` | 多重冲 |

#### 特殊条件
| 条件类型 | 格式 | 说明 |
|---------|------|------|
| `xishen` | `"比肩"` | 喜用神匹配 |
| `xishen_in` | `["食神", "伤官"]` | 喜用神在列表中 |
| `taiyuan_shengong_minggong` | `{"taiyuan": "癸丑"}` | 胎元身宫命宫 |
| `stems_branches_count` | `{"names": ["壬", "癸", "子"], "min": 3}` | 天干地支混合计数 |
| `not` | `{...条件...}` | 否定条件 |

#### 组合条件
| 条件类型 | 格式 | 说明 |
|---------|------|------|
| `all` | `[条件1, 条件2, ...]` | 所有条件都满足（AND） |
| `any` | `[条件1, 条件2, ...]` | 任一条件满足（OR） |

### 规则导入脚本模板

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
规则导入脚本：import_xxx_rules.py

使用方法：
  python scripts/migration/import_xxx_rules.py --dry-run  # 预览
  python scripts/migration/import_xxx_rules.py            # 正式导入
"""

import sys
import os
import json
import argparse
from typing import Dict, Any, Tuple, Optional, List

# 添加项目根目录到路径
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from server.config.mysql_config import get_mysql_connection, return_mysql_connection


class RuleConverter:
    """规则转换器"""
    
    # 类型映射
    TYPE_MAPPING = {
        '财富': 'wealth',
        '婚姻': 'marriage',
        '事业': 'career',
        '子女': 'children',
        '性格': 'character',
        '总评': 'summary',
        '身体': 'health',
        '桃花': 'peach_blossom',
    }
    
    def convert(self, raw_rule: Dict) -> Tuple[Optional[Dict], Optional[str]]:
        """
        转换原始规则为数据库格式
        
        Returns:
            (rule_dict, ambiguity_reason) - 如果有歧义返回原因
        """
        # 1. 提取字段
        rule_id = raw_rule.get('ID')
        rule_type_cn = raw_rule.get('类型', '')
        condition1 = raw_rule.get('筛选条件1', '')
        condition2 = raw_rule.get('筛选条件2', '')
        result = raw_rule.get('结果', '')
        gender = raw_rule.get('性别', '')
        
        # 2. 转换类型
        rule_type = self.TYPE_MAPPING.get(rule_type_cn, rule_type_cn.lower())
        
        # 3. 解析条件
        conditions, ambiguity = self._parse_conditions(condition1, condition2, gender)
        if ambiguity:
            return None, f"ID {rule_id}: {ambiguity}"
        
        # 4. 构建规则
        rule = {
            'rule_code': f'FORMULA_{rule_type_cn}_{rule_id}',
            'rule_name': f'{rule_type_cn}规则-{rule_id}',
            'rule_type': rule_type,
            'conditions': conditions,
            'content': {'text': result},
            'description': {
                '筛选条件1': condition1,
                '筛选条件2': condition2,
                '性别': gender
            }
        }
        
        return rule, None
    
    def _parse_conditions(self, cond1: str, cond2: str, gender: str) -> Tuple[Dict, Optional[str]]:
        """解析条件文本为JSON格式"""
        conditions = {}
        
        # 解析性别
        if gender == '男':
            conditions['gender'] = 'male'
        elif gender == '女':
            conditions['gender'] = 'female'
        
        # 解析具体条件（根据实际规则格式实现）
        # ...
        
        return conditions, None


def import_rules(rules: List[Dict], dry_run: bool = False) -> Tuple[int, int, List[str]]:
    """
    导入规则到数据库
    
    Returns:
        (inserted, updated, ambiguous_rules)
    """
    inserted = 0
    updated = 0
    ambiguous = []
    
    if dry_run:
        print("=== DRY RUN 模式，不会修改数据库 ===\n")
    
    conn = get_mysql_connection()
    try:
        with conn.cursor() as cursor:
            for rule in rules:
                if dry_run:
                    print(f"将导入: {rule['rule_code']}")
                    continue
                
                # 检查是否存在
                cursor.execute(
                    "SELECT id FROM bazi_rules WHERE rule_code = %s",
                    (rule['rule_code'],)
                )
                existing = cursor.fetchone()
                
                if existing:
                    # 更新
                    cursor.execute("""
                        UPDATE bazi_rules SET
                            rule_name = %s,
                            rule_type = %s,
                            conditions = %s,
                            content = %s,
                            description = %s,
                            version = version + 1
                        WHERE rule_code = %s
                    """, (
                        rule['rule_name'],
                        rule['rule_type'],
                        json.dumps(rule['conditions'], ensure_ascii=False),
                        json.dumps(rule['content'], ensure_ascii=False),
                        json.dumps(rule['description'], ensure_ascii=False),
                        rule['rule_code']
                    ))
                    updated += 1
                else:
                    # 插入
                    cursor.execute("""
                        INSERT INTO bazi_rules 
                        (rule_code, rule_name, rule_type, conditions, content, description)
                        VALUES (%s, %s, %s, %s, %s, %s)
                    """, (
                        rule['rule_code'],
                        rule['rule_name'],
                        rule['rule_type'],
                        json.dumps(rule['conditions'], ensure_ascii=False),
                        json.dumps(rule['content'], ensure_ascii=False),
                        json.dumps(rule['description'], ensure_ascii=False)
                    ))
                    inserted += 1
            
            if not dry_run:
                conn.commit()
    finally:
        return_mysql_connection(conn)
    
    return inserted, updated, ambiguous


def main():
    parser = argparse.ArgumentParser(description='规则导入脚本')
    parser.add_argument('--dry-run', action='store_true', help='预览模式，不修改数据库')
    args = parser.parse_args()
    
    # 加载规则数据
    # ...
    
    # 导入规则
    inserted, updated, ambiguous = import_rules(rules, args.dry_run)
    
    print(f"\n=== 导入结果 ===")
    print(f"新增: {inserted} 条")
    print(f"更新: {updated} 条")
    print(f"歧义: {len(ambiguous)} 条")


if __name__ == '__main__':
    main()
```

---

## 🔄 问题复盘机制 【重要】

### 复盘流程

每次遇到问题后，必须完成以下步骤：

1. **问题记录**
   - 记录问题现象、错误信息、复现步骤
   - 记录问题发生时间、影响范围

2. **根因分析**
   - 分析问题根本原因（不是表面现象）
   - 检查是否违反开发规范
   - 检查是否有类似问题历史

3. **解决方案**
   - 实施修复方案
   - 验证修复效果
   - 确保不会再次出现

4. **规范更新**
   - 将问题复盘记录到开发规范
   - 更新相关检查清单
   - 添加预防措施

5. **代码审查**
   - 检查是否有类似代码需要修复
   - 确保所有相关代码都符合规范

### 复盘记录格式

```markdown
## 问题复盘：[问题标题] - YYYY-MM-DD

### 问题描述
- **现象**：具体问题表现
- **影响**：影响范围和严重程度
- **复现**：复现步骤

### 根因分析
- **直接原因**：表面原因
- **根本原因**：深层原因
- **规范违反**：违反了哪些开发规范

### 解决方案
- **修复内容**：具体修改
- **验证结果**：测试验证情况

### 预防措施
- **规范更新**：更新的规范内容
- **检查清单**：新增的检查项
- **代码审查**：需要检查的代码范围
```

---

## 🚨 常见问题与解决方案

### 问题复盘：十神命格规则匹配失败 - 2025-11-28

#### 问题描述
- **现象**：生日 1987-01-07 09:00 无法匹配十神命格规则
- **影响**：所有十神命格规则都无法匹配，影响规则分析功能
- **复现**：调用 `/bazi/formula-analysis` API，`shishen_count` 始终为 0

#### 根因分析
1. **直接原因**：
   - `formula_analysis.py` 中十神命格使用 `FormulaRuleService` 匹配
   - `FormulaRuleService` 期望旧格式（文本条件），但数据库规则已迁移为 JSON 格式
   - 规则条件格式问题：`hidden_stars_in_year` 包含文本描述（如"日柱副星有正财"）

2. **根本原因**：
   - 规则迁移后未统一匹配服务
   - 规则引擎未支持混合条件格式（文本描述+十神名称）
   - 缺少规则匹配的统一测试

3. **规范违反**：
   - ❌ 未使用统一的 `RuleService` 匹配规则
   - ❌ 规则条件格式不统一
   - ❌ 缺少规则匹配的验证测试

#### 解决方案
1. **修改 `formula_analysis.py`**：
   - 移除 `FormulaRuleService` 特殊处理
   - 统一使用 `RuleService` 匹配所有规则（包括十神命格）

2. **增强 `rule_condition.py`**：
   - 增强 `hidden_stars_in_*` 条件处理
   - 支持解析文本描述（如"日柱副星有正财"）并检查对应柱

#### 预防措施
1. **规范更新**：
   - ✅ 所有规则必须使用 `RuleService` 匹配
   - ✅ 规则条件格式必须统一为 JSON
   - ✅ 新增规则类型必须同步更新前后端

2. **检查清单**：
   - [ ] 新规则类型是否使用 `RuleService` 匹配
   - [ ] 规则条件格式是否符合 JSON 规范
   - [ ] 前后端是否同步支持新规则类型
   - [ ] 是否编写了规则匹配测试

3. **代码审查**：
   - 检查所有使用 `FormulaRuleService` 的代码
   - 检查规则条件格式是否统一
   - 检查规则匹配逻辑是否完整

---

### 问题1：数据库名配置错误

**症状**：`Unknown database 'bazi_system'`

**原因**：`server/config/mysql_config.py` 中默认数据库名不正确

**解决**：见下方"数据库配置默认值"规范

**预防**：检查 `env.template` 中的 `MYSQL_DATABASE` 值，确保默认值与实际数据库一致

---

### 问题2：规则ID包含中文导致解析失败

**症状**：
```
invalid literal for int() with base 10: '财富_20106'
```

**原因**：规则ID格式不统一（`FORMULA_80001` vs `FORMULA_财富_20106`）

**解决**：
```python
# 兼容两种格式
try:
    numeric_id = int(original_id)
except ValueError:
    parts = original_id.rsplit('_', 1)
    if len(parts) == 2 and parts[1].isdigit():
        numeric_id = int(parts[1])
    else:
        numeric_id = hash(original_id) % 1000000
```

**预防**：
- 导入时统一使用 `FORMULA_类型_编号` 格式
- 在数据库中保持 `rule_type` 字段为英文

---

### 问题3：规则类型不一致

**症状**：前端显示不出新增的规则类型（如事业、子女）

**原因**：数据库 `rule_type` 字段值不统一（`formula_career` vs `career`）

**解决**：见下方"规则类型命名"规范

**预防**：导入脚本中使用统一的英文类型名，不要使用 `formula_` 前缀

---

### 问题4：前端类型标签缺失

**症状**：前端页面没有显示新类型的标签页

**原因**：`local_frontend/formula-analysis.html` 中 `typeLabels` 未定义新类型

**解决**：在 `typeLabels` 中添加新类型映射（参考上方"类型映射"表格）

**预防**：新增规则类型时同步更新前端 `typeLabels` 和 `displayStatistics` 函数

---

### 问题5：新条件类型不支持

**症状**：规则无法匹配，日志显示条件未处理

**原因**：`rule_condition.py` 中未实现对应条件类型

**解决**：在 `EnhancedRuleCondition.match` 中添加条件处理逻辑

**预防**：
- 导入前检查所有条件类型是否已支持
- 不支持的条件先扩展规则引擎再导入

---

### 问题6：gRPC 端点未注册

**症状**：前端调用 API 返回错误或无响应

**原因**：`grpc_gateway.py` 中未注册对应端点

**解决**：
```python
# 在 grpc_gateway.py 中注册
@_register("/bazi/new-feature")
async def _handle_new_feature(payload: Dict[str, Any]):
    request_model = NewFeatureRequest(**payload)
    return await new_feature(request_model)
```

**预防**：
- 新增 API 时必须同时注册 gRPC 端点
- 测试时验证 gRPC-Web 调用是否正常

---

## 📁 项目架构

### 前端架构 `local_frontend/`
```
local_frontend/
├── js/
│   ├── api.js                  # gRPC-Web 客户端（核心）
│   ├── config.js               # API 配置
│   ├── fortune.js              # 运势数据逻辑
│   ├── fortune-timeline.js     # 运势 UI 渲染
│   └── ...
├── css/                        # 样式文件
└── *.html                      # 页面文件
```

**⚠️ 重要说明**：
- **`local_frontend/`** 是本地前端目录，用于本地开发、测试环境、双机部署
- **生产前端**由前端团队独立部署，不在此仓库中
- 所有配置文件和脚本必须使用 `local_frontend` 路径

### 后端架构 `server/`
```
server/
├── api/
│   ├── grpc_gateway.py         # gRPC-Web 网关（核心）
│   └── v1/                     # REST API
│       ├── formula_analysis.py # 算法公式分析
│       └── ...
├── services/                   # 业务逻辑
│   ├── rule_service.py         # 规则匹配服务
│   └── ...
├── engines/                    # 规则引擎
│   ├── rule_engine.py          # 核心引擎
│   └── rule_condition.py       # 条件匹配（扩展点）
├── config/
│   └── mysql_config.py         # MySQL 配置（注意默认值）
└── db/                         # 数据库连接
```

### 微服务架构 `services/`
```
services/
├── bazi_core/                  # 八字核心服务 (gRPC 9001)
├── bazi_fortune/               # 运势服务 (gRPC 9002)
├── bazi_analyzer/              # 八字分析 (gRPC 9003)
├── bazi_rule/                  # 规则匹配 (gRPC 9004)
├── fortune_analysis/           # 运势分析 (gRPC 9005)
├── payment_service/            # 支付服务 (gRPC 9006)
├── fortune_rule/               # 运势规则 (gRPC 9007)
├── intent_service/             # 意图识别 (gRPC 9008)
├── prompt_optimizer/           # 提示优化 (gRPC 9009)
└── desk_fengshui/              # 风水分析 (gRPC 9010)
```

**服务端口清单**：
| 服务 | 端口 | 用途 |
|------|------|------|
| Web 服务 | 8001 | HTTP + gRPC-Web 网关 |
| bazi-core | 9001 | 八字核心计算 |
| bazi-fortune | 9002 | 运势计算 |
| bazi-analyzer | 9003 | 八字分析 |
| bazi-rule | 9004 | 规则匹配 |
| fortune-analysis | 9005 | 运势分析 |
| payment | 9006 | 支付服务 |
| fortune-rule | 9007 | 运势规则 |
| intent | 9008 | 意图识别 |
| optimizer | 9009 | 提示优化 |
| desk-fengshui | 9010 | 风水分析 |

### 脚本目录 `scripts/`
```
scripts/
├── migration/                  # 数据迁移脚本
│   ├── import_2025_1128_rules.py   # 规则导入示例
│   └── import_confirmed_rules.py   # 确认规则导入
├── db/                         # 数据库脚本
│   └── sync_db.sh              # 数据库同步
└── ...
```

---

## 🔒 核心文件（修改前必须咨询）

| 文件 | 作用 | 风险 |
|------|------|------|
| `server/api/grpc_gateway.py` | gRPC-Web 网关 | 极高 |
| `server/engines/rule_condition.py` | 规则条件匹配 | 高 |
| `server/config/mysql_config.py` | MySQL 配置 | 高 |
| `src/bazi_calculator.py` | 核心八字计算 | 极高 |
| `local_frontend/js/api.js` | 前端 gRPC 客户端 | 高 |
| `proto/*.proto` | gRPC 协议定义 | 高 |

---

## 🔐 安全规范 【必须遵守】

### 🔴 安全开发原则

> **安全是最高优先级，所有代码必须遵循安全最佳实践。**

| 原则 | 要求 | 说明 |
|------|------|------|
| **最小权限** | ✅ 必须 | 只授予必要的权限，禁止过度授权 |
| **输入验证** | ✅ 必须 | 所有用户输入必须验证和过滤 |
| **输出编码** | ✅ 必须 | 所有输出必须正确编码，防止 XSS |
| **敏感数据保护** | ✅ 必须 | 密码、密钥、Token 等必须加密存储 |
| **错误处理** | ✅ 必须 | 不暴露系统内部信息给用户 |
| **依赖安全** | ✅ 必须 | 定期更新依赖，修复已知漏洞 |

---

### 🛡️ 常见安全漏洞防护

#### 1. SQL 注入防护 【高危】

**禁止**：
```python
# ❌ 错误：直接拼接 SQL
query = f"SELECT * FROM users WHERE id = {user_id}"
cursor.execute(query)

# ❌ 错误：使用 % 格式化
cursor.execute("SELECT * FROM users WHERE name = '%s'" % user_name)
```

**正确做法**：
```python
# ✅ 正确：使用参数化查询
cursor.execute("SELECT * FROM users WHERE id = %s", (user_id,))
cursor.execute("SELECT * FROM users WHERE name = %s AND age = %s", (user_name, age))

# ✅ 正确：使用 ORM（SQLAlchemy）
from server.config.mysql_config import get_mysql_connection
with get_mysql_connection() as conn:
    result = conn.execute(
        text("SELECT * FROM users WHERE id = :id"),
        {"id": user_id}
    )
```

**检查清单**：
- [ ] 所有 SQL 查询使用参数化
- [ ] 禁止字符串拼接构建 SQL
- [ ] 使用 ORM 或参数化查询接口

---

#### 2. XSS（跨站脚本攻击）防护 【高危】

**禁止**：
```python
# ❌ 错误：直接输出用户输入
return f"<div>{user_input}</div>"

# ❌ 错误：在 JavaScript 中直接嵌入
return f"<script>var data = '{user_data}';</script>"
```

**正确做法**：
```python
# ✅ 正确：使用模板引擎自动转义（FastAPI + Jinja2）
from fastapi.templating import Jinja2Templates
templates = Jinja2Templates(directory="templates")
return templates.TemplateResponse("page.html", {
    "request": request,
    "user_input": user_input  # 自动转义
})

# ✅ 正确：手动转义（如需要）
import html
safe_output = html.escape(user_input)

# ✅ 正确：JSON 输出（自动转义）
from fastapi.responses import JSONResponse
return JSONResponse({"data": user_input})  # 自动转义
```

**前端防护**：
```javascript
// ✅ 正确：使用 textContent 而不是 innerHTML
element.textContent = userInput;

// ✅ 正确：使用 DOMPurify 清理 HTML
import DOMPurify from 'dompurify';
element.innerHTML = DOMPurify.sanitize(userInput);
```

**检查清单**：
- [ ] 所有用户输入在输出前转义
- [ ] 使用模板引擎自动转义
- [ ] 前端使用安全的 DOM 操作方式

---

#### 3. CSRF（跨站请求伪造）防护 【高危】

**后端防护**：
```python
# ✅ 正确：使用 CSRF Token（FastAPI）
from fastapi_csrf_protect import CsrfProtect
from fastapi_csrf_protect.exceptions import CsrfProtectError

@router.post("/api/v1/sensitive-action")
async def sensitive_action(
    request: Request,
    csrf_protect: CsrfProtect = Depends()
):
    await csrf_protect.validate_csrf(request)
    # 处理请求
    ...

# ✅ 正确：检查 Referer 头
referer = request.headers.get("referer")
if not referer or not referer.startswith("https://yourdomain.com"):
    raise HTTPException(status_code=403, detail="Invalid referer")
```

**前端防护**：
```javascript
// ✅ 正确：从后端获取 CSRF Token
const csrfToken = await fetch('/api/csrf-token').then(r => r.json());

// ✅ 正确：在请求头中携带 Token
fetch('/api/v1/sensitive-action', {
    method: 'POST',
    headers: {
        'X-CSRF-Token': csrfToken,
        'Content-Type': 'application/json'
    },
    body: JSON.stringify(data)
});
```

**检查清单**：
- [ ] 所有修改操作需要 CSRF Token
- [ ] 验证 Referer 头（可选，作为额外保护）
- [ ] 使用 SameSite Cookie 属性

---

#### 4. 敏感信息泄露防护 【高危】

**禁止**：
```python
# ❌ 错误：在错误信息中暴露系统信息
except Exception as e:
    return {"error": f"Database error: {str(e)}"}  # 暴露数据库结构

# ❌ 错误：在日志中记录敏感信息
logger.info(f"User login: {username}, password: {password}")

# ❌ 错误：在响应中返回敏感字段
return {"user": {"id": 1, "password": "hashed_password", "api_key": "xxx"}}
```

**正确做法**：
```python
# ✅ 正确：通用错误信息
except Exception as e:
    logger.error(f"Database error: {e}", exc_info=True)  # 记录详细日志
    return {"error": "操作失败，请稍后重试"}  # 用户友好的错误信息

# ✅ 正确：不记录敏感信息
logger.info(f"User login: {username}")  # 不记录密码

# ✅ 正确：过滤敏感字段
def sanitize_user_data(user):
    return {
        "id": user.id,
        "username": user.username,
        # 不返回 password, api_key 等敏感字段
    }
```

**环境变量保护**：
```python
# ✅ 正确：使用环境变量，不提交到代码库
import os
from dotenv import load_dotenv

load_dotenv()
SECRET_KEY = os.getenv("SECRET_KEY")  # 从 .env 读取
DATABASE_PASSWORD = os.getenv("MYSQL_PASSWORD")

# ❌ 错误：硬编码密钥
SECRET_KEY = "my-secret-key-12345"  # 禁止！
```

**检查清单**：
- [ ] 错误信息不暴露系统内部信息
- [ ] 日志不记录密码、Token 等敏感信息
- [ ] API 响应不返回敏感字段
- [ ] 所有密钥使用环境变量，不提交到代码库

---

#### 5. 身份认证与授权防护 【高危】

**密码安全**：
```python
# ✅ 正确：使用 bcrypt 加密密码
import bcrypt

def hash_password(password: str) -> str:
    salt = bcrypt.gensalt()
    hashed = bcrypt.hashpw(password.encode('utf-8'), salt)
    return hashed.decode('utf-8')

def verify_password(password: str, hashed: str) -> bool:
    return bcrypt.checkpw(password.encode('utf-8'), hashed.encode('utf-8'))

# ❌ 错误：明文存储密码
user.password = password  # 禁止！
```

**Token 安全**：
```python
# ✅ 正确：使用 JWT，设置过期时间
import jwt
from datetime import datetime, timedelta

def generate_token(user_id: int) -> str:
    payload = {
        "user_id": user_id,
        "exp": datetime.utcnow() + timedelta(hours=24),  # 24小时过期
        "iat": datetime.utcnow()
    }
    return jwt.encode(payload, SECRET_KEY, algorithm="HS256")

# ✅ 正确：验证 Token
def verify_token(token: str) -> dict:
    try:
        payload = jwt.decode(token, SECRET_KEY, algorithms=["HS256"])
        return payload
    except jwt.ExpiredSignatureError:
        raise HTTPException(status_code=401, detail="Token 已过期")
    except jwt.InvalidTokenError:
        raise HTTPException(status_code=401, detail="无效的 Token")
```

**权限检查**：
```python
# ✅ 正确：每个操作都检查权限
@router.post("/api/v1/admin/delete-user")
async def delete_user(user_id: int, current_user: User = Depends(get_current_user)):
    # 检查是否为管理员
    if not current_user.is_admin:
        raise HTTPException(status_code=403, detail="权限不足")
    
    # 执行删除操作
    ...
```

**检查清单**：
- [ ] 密码必须加密存储（bcrypt/argon2）
- [ ] Token 设置合理的过期时间
- [ ] 所有敏感操作验证用户身份
- [ ] 所有操作检查用户权限

---

#### 6. 文件上传安全防护 【高危】

**禁止**：
```python
# ❌ 错误：不验证文件类型
@router.post("/upload")
async def upload(file: UploadFile):
    content = await file.read()
    with open(f"uploads/{file.filename}", "wb") as f:
        f.write(content)  # 危险！可能上传恶意文件
```

**正确做法**：
```python
# ✅ 正确：验证文件类型和大小
from fastapi import UploadFile, File
import magic  # 或使用 python-magic

ALLOWED_MIME_TYPES = ["image/jpeg", "image/png", "image/webp"]
MAX_FILE_SIZE = 10 * 1024 * 1024  # 10MB

@router.post("/upload")
async def upload(file: UploadFile = File(...)):
    # 1. 检查文件大小
    content = await file.read()
    if len(content) > MAX_FILE_SIZE:
        raise HTTPException(status_code=400, detail="文件过大")
    
    # 2. 验证文件类型（使用 MIME 类型，不依赖扩展名）
    mime_type = magic.from_buffer(content, mime=True)
    if mime_type not in ALLOWED_MIME_TYPES:
        raise HTTPException(status_code=400, detail="不支持的文件类型")
    
    # 3. 生成安全的文件名（防止路径遍历）
    import uuid
    import os
    safe_filename = f"{uuid.uuid4()}.{mime_type.split('/')[1]}"
    safe_path = os.path.join("uploads", safe_filename)
    
    # 4. 保存文件
    with open(safe_path, "wb") as f:
        f.write(content)
    
    return {"filename": safe_filename}
```

**检查清单**：
- [ ] 验证文件 MIME 类型（不依赖扩展名）
- [ ] 限制文件大小
- [ ] 生成安全的文件名（防止路径遍历）
- [ ] 文件存储在隔离目录，不在 Web 根目录

---

#### 7. API 限流防护 【中危】

**防止暴力破解和 DDoS**：
```python
# ✅ 正确：使用 slowapi 限流
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address
from slowapi.errors import RateLimitExceeded

limiter = Limiter(key_func=get_remote_address)

@router.post("/api/v1/login")
@limiter.limit("5/minute")  # 每分钟最多 5 次
async def login(request: Request):
    # 登录逻辑
    ...

@router.post("/api/v1/bazi/calculate")
@limiter.limit("100/hour")  # 每小时最多 100 次
async def calculate_bazi(request: Request):
    # 计算逻辑
    ...
```

**检查清单**：
- [ ] 登录接口设置严格限流（如 5次/分钟）
- [ ] 计算接口设置合理限流（如 100次/小时）
- [ ] 使用 IP 地址作为限流键

---

#### 8. 依赖安全更新 【中危】

**定期检查依赖漏洞**：
```bash
# ✅ 使用安全扫描工具
pip install safety
safety check

# ✅ 使用 pip-audit（Python 官方推荐）
pip install pip-audit
pip-audit

# ✅ 定期更新依赖
pip list --outdated
pip install --upgrade package_name
```

**检查清单**：
- [ ] 每月检查一次依赖漏洞
- [ ] 及时更新有安全漏洞的依赖
- [ ] 使用 `requirements.txt` 固定版本号
- [ ] 记录依赖更新日志

---

#### 9. 日志安全 【中危】

**禁止记录敏感信息**：
```python
# ❌ 错误：记录敏感信息
logger.info(f"User {username} login with password {password}")
logger.debug(f"API Key: {api_key}")

# ✅ 正确：不记录敏感信息
logger.info(f"User {username} login successful")
logger.debug(f"API Key: {api_key[:10]}...")  # 只记录部分
```

**日志访问控制**：
```python
# ✅ 正确：日志文件权限控制
# 日志文件只允许应用用户访问
chmod 600 logs/app.log
chown app:app logs/app.log
```

**检查清单**：
- [ ] 日志不包含密码、Token、API Key
- [ ] 日志文件权限设置为 600
- [ ] 定期清理旧日志
- [ ] 生产环境日志级别设置为 WARNING 或 ERROR

---

#### 10. 配置安全 【中危】

**环境变量管理**：
```python
# ✅ 正确：使用 .env 文件（不提交到代码库）
# .env 文件添加到 .gitignore
# .env.example 作为模板提交

# .env.example
SECRET_KEY=your-secret-key-here
MYSQL_PASSWORD=your-password-here
REDIS_PASSWORD=your-redis-password

# .env（不提交）
SECRET_KEY=actual-secret-key-12345
MYSQL_PASSWORD=actual-password-12345
```

**配置文件安全**：
```python
# ✅ 正确：敏感配置从环境变量读取
import os
from dotenv import load_dotenv

load_dotenv()
SECRET_KEY = os.getenv("SECRET_KEY")
if not SECRET_KEY:
    raise ValueError("SECRET_KEY 环境变量未设置")

# ❌ 错误：硬编码配置
SECRET_KEY = "hardcoded-secret-key"  # 禁止！
```

**检查清单**：
- [ ] `.env` 文件添加到 `.gitignore`
- [ ] 提供 `.env.example` 作为模板
- [ ] 所有敏感配置从环境变量读取
- [ ] 生产环境使用强密码和密钥

---

### 🔍 安全代码审查清单

每次提交代码前，必须检查：

#### 输入验证
- [ ] 所有用户输入都经过验证
- [ ] 验证数据类型、长度、格式
- [ ] 禁止直接使用用户输入构建 SQL/命令

#### 输出编码
- [ ] 所有输出都正确编码
- [ ] 防止 XSS 攻击
- [ ] JSON 输出使用 `ensure_ascii=False` 时确保安全

#### 身份认证
- [ ] 密码加密存储
- [ ] Token 设置过期时间
- [ ] 敏感操作验证用户身份

#### 权限控制
- [ ] 每个操作检查用户权限
- [ ] 防止越权访问
- [ ] 使用最小权限原则

#### 错误处理
- [ ] 不暴露系统内部信息
- [ ] 记录详细错误日志（服务器端）
- [ ] 返回用户友好的错误信息

#### 依赖安全
- [ ] 定期检查依赖漏洞
- [ ] 及时更新有安全问题的依赖
- [ ] 使用固定版本号

---

### 🚨 安全事件响应

#### 发现安全漏洞时

1. **立即处理**
   - 评估漏洞严重程度（高危/中危/低危）
   - 立即修复或临时禁用相关功能
   - 通知相关人员

2. **修复流程**
   - 创建修复分支：`git checkout -b security/fix-xxx-vulnerability`
   - 修复漏洞并编写测试
   - 代码审查（重点关注安全性）
   - 合并到主分支并部署

3. **记录与复盘**
   - 记录漏洞详情和修复方案
   - 更新安全规范，防止类似问题
   - 检查是否有其他类似问题

---

### 📚 安全资源

- **OWASP Top 10**：https://owasp.org/www-project-top-ten/
- **Python 安全最佳实践**：https://python.readthedocs.io/en/latest/library/security.html
- **FastAPI 安全文档**：https://fastapi.tiangolo.com/tutorial/security/

---

**安全开发核心原则**：
- 🔒 **默认拒绝**：默认情况下拒绝所有访问，只允许明确授权的操作
- 🔍 **深度防御**：多层安全防护，不依赖单一安全措施
- 🛡️ **最小权限**：只授予必要的权限，禁止过度授权
- 📝 **安全审计**：定期审查代码和配置，及时发现安全问题
- 🚨 **快速响应**：发现安全问题立即处理，不拖延

## 🏠 办公桌风水模块（核心模块，禁止随意修改）

### ⚠️ 重要说明

**办公桌风水模块（`services/desk_fengshui/`）是稳定运行的核心功能模块，除非用户明确要求，否则禁止修改此模块的任何代码、规则或配置。**

### 模块配置

**技术栈**：
- **YOLO版本**：YOLOv8（不是YOLOv5）
- **库**：`ultralytics>=8.0.0`
- **模型文件**：`yolov8n.pt`（YOLOv8 nano版本）
- **置信度阈值**：0.15
- **备用方案**：OpenCV（当YOLO未安装时）

**核心文件**：
- `services/desk_fengshui/item_detector.py` - 物品检测器（YOLOv8）
- `services/desk_fengshui/rule_engine.py` - 风水规则引擎
- `services/desk_fengshui/position_calculator.py` - 方位计算器
- `services/desk_fengshui/analyzer.py` - 主分析器
- `services/desk_fengshui/bazi_client.py` - 八字客户端
- `services/desk_fengshui/requirements.txt` - 依赖配置

**规则系统**：
- 规则存储在MySQL数据库（`desk_fengshui_rules`表）
- 包含青龙位、白虎位、朱雀位、玄武位等传统风水规则
- 结合八字喜用神、忌神进行个性化分析

**修改原则**：
1. ❌ **禁止修改**：除非用户明确要求
2. ✅ **允许操作**：查看、测试、调试
3. ⚠️ **修改前必须**：先咨询用户，说明影响范围
4. 🔒 **保护范围**：所有 `services/desk_fengshui/` 目录下的文件

---

## 📝 代码规范

### 数据库配置默认值
```python
# ✅ 正确：使用实际的数据库名
'database': os.getenv('MYSQL_DATABASE', 'hifate_bazi'),

# ❌ 错误：使用过时的数据库名
'database': os.getenv('MYSQL_DATABASE', 'bazi_system'),
```
**相关错误**：见"问题1：数据库名配置错误"

### JSON 序列化
```python
# ✅ 正确：支持中文
json.dumps(data, ensure_ascii=False)

# ❌ 错误：中文被转义
json.dumps(data)  # 输出 \u4e2d\u6587
```

### 规则类型命名
```python
# ✅ 正确：使用英文小写（参考上方"类型映射"表格）
rule_type = 'career'
rule_type = 'children'

# ❌ 错误：使用中文或带前缀
rule_type = '事业'
rule_type = 'formula_career'  # 不要使用 formula_ 前缀
```
**相关错误**：见"问题3：规则类型不一致"、"问题4：前端类型标签缺失"

---

## 🚀 CI/CD 标准流程 【必须遵守】

### 🔴 核心原则

> **所有部署必须遵循标准 CI/CD 流程，禁止在服务器上直接构建镜像。**

### 📋 标准流程

```
本地开发 → 推送到 GitHub → GitHub Actions 构建镜像 → 推送到 GHCR → 服务器拉取镜像部署
```

| 步骤 | 操作 | 说明 |
|------|------|------|
| **1. 本地开发** | 在本地 Mac 开发 | 修改代码、测试 |
| **2. 推送到 GitHub** | `git push origin master` | 触发 CI/CD |
| **3. 自动构建镜像** | GitHub Actions 执行 | `.github/workflows/build-and-push.yml` |
| **4. 推送到 GHCR** | 自动推送到 GitHub Container Registry | 镜像标签：`ghcr.io/owner/repo/hifate-bazi:master` |
| **5. 服务器拉取部署** | 服务器从 GHCR 拉取镜像 | `.github/workflows/deploy-test.yml` 自动部署 |

### 🔧 工作流文件

| 文件 | 功能 | 触发条件 |
|------|------|---------|
| `.github/workflows/build-and-push.yml` | 构建镜像并推送到 GHCR | 推送到 `master` 或 `develop` 分支 |
| `.github/workflows/deploy-test.yml` | 部署到测试环境 | 推送到 `master` 分支 |
| `.github/workflows/deploy-production.yml` | 部署到生产环境 | 推送到 `master` 分支（手动触发） |

### ✅ 标准流程检查清单

每次部署前必须检查：

- [ ] 代码已推送到 GitHub
- [ ] GitHub Actions 构建成功
- [ ] 镜像已推送到 GHCR
- [ ] 服务器成功拉取镜像
- [ ] 健康检查通过

### 🚫 禁止的操作

| 操作 | 原因 | 正确方式 |
|------|------|---------|
| ❌ 在服务器上构建镜像 | 占用服务器资源、构建慢 | 使用 GitHub Actions 构建 |
| ❌ 手动上传镜像文件 | 不标准、容易出错 | 使用 GHCR 自动推送 |
| ❌ 直接修改服务器代码 | 无法版本控制 | 推送到 GitHub，自动部署 |

### 📝 部署命令

**测试环境部署**（自动）：
```bash
# 1. 本地开发完成后
git add .
git commit -m "feat: 新功能"
git push origin master

# 2. GitHub Actions 自动执行：
#    - build-and-push.yml: 构建镜像并推送到 GHCR
#    - deploy-test.yml: 部署到测试服务器 (123.57.216.15)
```

**生产环境部署**（手动触发）：
```bash
# 1. 在 GitHub Actions 页面手动触发 deploy-production.yml
# 2. 或推送到 master 分支后，在 Actions 页面手动触发
```

### 🔍 故障排查

**如果部署失败**：
1. 查看 GitHub Actions 日志
2. 检查镜像是否成功推送到 GHCR
3. 检查服务器 SSH 连接
4. 检查服务器磁盘空间
5. 查看服务器日志：`docker compose logs --tail=100`

### 🐳 ACR/GHCR 镜像推送规范 【必须遵守】

> **问题复盘 2025-12-06**：ACR 推送失败导致部署使用旧镜像，引发 uvicorn 缺失等问题。

#### 1. docker/build-push-action 必须配置 provenance: false

**原因**：阿里云 ACR 不支持 Docker BuildKit 的 provenance 特性，会导致 `error from registry: unsupported` 错误。

**正确配置**：
```yaml
- name: 🐳 Build and push Docker image
  uses: docker/build-push-action@v5
  with:
    context: .
    push: true
    tags: ${{ steps.meta.outputs.tags }}
    platforms: linux/amd64
    provenance: false  # ⚠️ ACR 必需！不要删除！
    build-args: |
      ...
```

**检查清单**：
- [ ] `deploy-test.yml` 中 build-push-action 包含 `provenance: false`
- [ ] `deploy-production.yml` 中 build-push-action 包含 `provenance: false`
- [ ] `build-and-push.yml` 中使用 `--provenance=false` 参数

#### 2. 服务器部署前必须清理磁盘空间

**原因**：服务器磁盘空间不足会导致 `no space left on device` 错误，无法拉取新镜像。

**正确配置**：在部署脚本开头添加：
```bash
echo "🔄 开始部署到测试环境..."

# 清理磁盘空间（必须！防止 no space left on device）
docker system prune -af 2>/dev/null || true
docker image prune -af 2>/dev/null || true

# 进入项目目录
cd /opt/HiFate-bazi
```

**检查清单**：
- [ ] `deploy-test.yml` 部署脚本包含磁盘清理
- [ ] `deploy-production.yml` 部署脚本包含磁盘清理

#### 3. 常见错误及解决方案

| 错误 | 原因 | 解决方案 |
|-----|------|---------|
| `error from registry: unsupported` | ACR 不支持 provenance | 添加 `provenance: false` |
| `no space left on device` | 服务器磁盘满 | 部署前执行 `docker system prune -af` |
| `unauthorized: authentication required` | ACR 认证失败 | 检查 secrets 配置 |
| `ModuleNotFoundError: No module named 'uvicorn'` | 使用了旧镜像 | 确保新镜像成功推送并拉取 |

### 📚 相关文档

- `.github/workflows/build-and-push.yml` - 构建和推送流程
- `.github/workflows/deploy-test.yml` - 测试环境部署流程
- `docs/GitHub-Container-Registry部署方案.md` - 详细部署文档

---

## 🚀 服务管理

### 启动服务
```bash
# 启动主服务
python3 server/start.py

# 或使用脚本
./start.sh
```

### 测试 API
```bash
# 测试 gRPC-Web 网关
curl -s -X POST 'http://127.0.0.1:8001/api/v1/bazi/formula-analysis' \
  -H 'Content-Type: application/json' \
  -d '{"solar_date": "1990-01-15", "solar_time": "12:00", "gender": "male"}'
```

### 查看日志
```bash
tail -f logs/server_8001.log
```

---

## 📦 Git 提交规范

### Commit Message 格式
```
[类型] 简短描述

- 修改文件：列出文件
- 功能说明：详细说明
- 测试情况：测试结果
```

### 类型标签
- `[新增]` - 新功能/新规则
- `[修复]` - Bug修复
- `[优化]` - 性能优化
- `[重构]` - 代码重构
- `[规则]` - 规则相关变更
- `[配置]` - 配置修改

---

## 📖 Gitee 仓库

| 项目 | 值 |
|------|-----|
| **仓库地址** | https://gitee.com/zhoudengtang/hifate-prod.git |
| **本地 remote** | gitee |
| **默认分支** | master |

### 提交流程
```bash
git add .
git commit -m "[类型] 描述"
git push gitee master
```

### 部署到生产
```bash
./deploy.sh  # 选择 1) 完整部署
```

**📖 详细部署文档**：`docs/Docker生产部署完整指南.md`

---

## 🐳 Docker 基础镜像优化

### 📋 原理

使用预构建的基础镜像（包含所有 Python 依赖包和框架），大幅加速部署：

```
传统方式：每次部署都安装依赖（5-10分钟）
优化方式：基础镜像已含所有包和框架，只需复制代码（10-20秒）
```

**核心优化**：
- ✅ 所有 Python 包和框架预装在基础镜像中
- ✅ 部署时只需复制代码，无需安装依赖
- ✅ 基础镜像包含：FastAPI、gRPC、数据库驱动、图像处理库等

### 🚀 使用流程

**1. 首次构建基础镜像**（仅需一次，约 5-10 分钟）

```bash
./scripts/docker/build_base.sh
```

**2. 检查基础镜像状态**

```bash
./scripts/docker/check_base.sh
```

**3. 正常部署**（快速，10-20秒）

```bash
docker compose up -d --build web
```

### ⚠️ 何时需要重建基础镜像

| 场景 | 是否需要重建 | 说明 |
|------|------------|------|
| 修改代码 | ❌ 不需要 | 直接部署即可 |
| 修改 requirements.txt | ✅ **必须重建** | 依赖变更 |
| 修改 Dockerfile.base | ✅ 需要重建 | 基础镜像配置变更 |

### 🔒 安全机制

1. **跨平台兼容**：使用 `--platform linux/amd64` 确保 Mac M1/Intel 都能构建
2. **保险层**：应用 Dockerfile 会再次执行 `pip install`，确保依赖完整
3. **自动检查**：`check_base.sh` 会检测 requirements.txt 是否变更
4. **依赖验证**：基础镜像构建时验证核心框架（FastAPI、gRPC、数据库驱动等）
5. **健康检查**：基础镜像包含健康检查，确保可用性

### 📊 性能对比

| 场景 | 传统方式 | 基础镜像 | 提升 |
|------|---------|---------|------|
| 首次部署 | 10-15分钟 | 5-10分钟（构建基础镜像） | 1次性 |
| 代码更新 | 1-2分钟 | **10-20秒** | **6-12倍** |
| 依赖更新 | 10-15分钟 | 5-10分钟（重建基础镜像） | 1次性 |

### 🛠️ 维护命令

```bash
# 构建基础镜像
./scripts/docker/build_base.sh

# 检查是否需要更新
./scripts/docker/check_base.sh

# 查看基础镜像信息
docker images hifate-base

# 删除旧版本（可选）
docker rmi hifate-base:20241128
```

---

## 💡 开发原则

> **⚠️ 重要提示**：所有新功能的增加、修改、扩展都必须严格遵守本开发规范。开发前必须阅读"新功能开发强制规范"章节（第 65-200 行），并完成开发规范检查清单。

1. **📋 规范优先**：**所有新功能必须遵守开发规范**，这是最高优先级（见"新功能开发强制规范"）
2. **🔐 安全优先**：安全是最高优先级，所有代码必须遵循安全最佳实践（见"安全规范"）
3. **🔴 零停机优先**：所有设计必须支持不停机更新（见"零停机原则"）
4. **🔌 gRPC 优先**：服务间交互必须使用 gRPC（见"gRPC 交互规范"）
5. **📜 规则数据库化**：规则存数据库，支持热更新，**禁止从文件读取**（见"规则存储规范"）
6. **🔄 向后兼容**：只加不删，保持兼容
7. **✅ 先测试后提交**：修改后立即测试，测试覆盖率 ≥ 50%（见"测试开发规范"）
8. **📝 规范命名**：类型用英文，ID 统一格式（见"规则编码规范"和"规则类型命名"）
9. **🔄 问题复盘**：每次问题必须复盘并更新规范（见"问题复盘机制"）
10. **💾 Token 节省**：只读取相关文件，使用 `offset`/`limit` 限制范围（见"Token 节省原则"）
11. **🧪 A/B 测试优先**：新功能必须支持 A/B 测试（见"A/B 测试和灰度发布规范"）
12. **🚀 灰度发布优先**：重要变更必须通过灰度发布（见"A/B 测试和灰度发布规范"）
13. **🔄 回滚准备**：所有数据库变更必须准备回滚脚本（见"A/B 测试和灰度发布规范"）
14. **📊 性能监控**：所有关键流程必须记录性能监控（见"智能运势分析性能监控规范"）
15. **🎯 意图识别混合架构**：意图识别必须使用混合架构，响应时间 < 1秒（见"意图识别混合架构规范"）

---

## 🧪 A/B 测试和灰度发布规范 【必须遵守】

### 🔴 核心原则

> **所有新功能、重要变更、数据库变更都必须支持 A/B 测试、灰度发布和回滚机制。**

| 场景 | 要求 | 实现方式 |
|------|------|----------|
| **新功能开发** | ✅ 必须 | 使用功能开关（Feature Flag）控制 |
| **算法优化** | ✅ 必须 | 使用 A/B 测试对比效果 |
| **重要变更** | ✅ 必须 | 通过灰度发布逐步上线 |
| **数据库变更** | ✅ 必须 | 准备回滚脚本，支持快速回滚 |
| **性能优化** | ✅ 推荐 | 使用 A/B 测试验证效果 |

---

### 📋 A/B 测试开发规范

#### 1. 新功能必须支持 A/B 测试

**要求**：
- 所有新功能、算法优化、UI 变更必须支持 A/B 测试
- 使用 `server/utils/ab_test.py` 框架
- 创建实验，分配变体，记录事件

**开发流程**：

```python
# 1. 导入 A/B 测试框架
from server.utils.ab_test import get_ab_test_manager, Experiment, ExperimentStatus

# 2. 创建实验（在服务启动时或通过 API）
manager = get_ab_test_manager()
experiment = Experiment(
    name="新算法测试",
    description="测试新的八字计算算法",
    status=ExperimentStatus.RUNNING,
    traffic_percent=50.0,  # 50% 流量
    variants={"A": 50, "B": 50}  # A/B 各 50%
)
manager.create_experiment(experiment)

# 3. 在代码中使用
variant = manager.assign_variant("新算法测试", user_id=user_id)
if variant == "A":
    result = old_algorithm.calculate()
elif variant == "B":
    result = new_algorithm.calculate()

# 4. 记录用户行为事件
manager.record_event("新算法测试", user_id, "click", {"button": "submit"})
```

**检查清单**：
- [ ] 新功能是否创建了 A/B 测试实验
- [ ] 是否在代码中正确分配变体
- [ ] 是否记录了关键事件（点击、转化等）
- [ ] 是否可以通过 API 查看实验统计

---

### 🚩 功能开关开发规范

#### 1. 新功能必须使用功能开关

**要求**：
- 所有新功能必须通过功能开关控制
- 支持快速开启/关闭，无需重新部署
- 支持百分比灰度、白名单、黑名单

**开发流程**：

```python
# 1. 导入功能开关框架
from server.utils.feature_flag import get_feature_flag_manager, FeatureFlag, FlagType

# 2. 创建功能开关（在服务启动时或通过 API）
manager = get_feature_flag_manager()
flag = FeatureFlag(
    name="新功能",
    description="新功能开关",
    enabled=True,
    flag_type=FlagType.PERCENTAGE,  # 百分比开关
    value=10.0  # 10% 流量
)
manager.create_flag(flag)

# 3. 在代码中检查开关
if manager.is_enabled("新功能", user_id=user_id):
    # 使用新功能
    result = new_feature.process()
else:
    # 使用旧功能或跳过
    result = old_feature.process()
```

**功能开关类型**：
- `FlagType.BOOLEAN` - 布尔开关（全部开启/关闭）
- `FlagType.PERCENTAGE` - 百分比开关（灰度发布）
- `FlagType.WHITELIST` - 白名单（指定用户）
- `FlagType.BLACKLIST` - 黑名单（排除用户）

**检查清单**：
- [ ] 新功能是否创建了功能开关
- [ ] 是否在代码中正确检查开关状态
- [ ] 是否支持快速关闭（紧急情况）
- [ ] 是否可以通过 API 切换开关状态

---

### 🚀 灰度发布规范

#### 1. 重要变更必须通过灰度发布

**要求**：
- 所有重要功能变更、性能优化、架构调整必须通过灰度发布
- 从 10% 流量开始，逐步增加到 100%
- 监控关键指标，随时准备回滚

**灰度发布流程**：

```bash
# 1. 开发新功能
git checkout -b feature/new-feature
# ... 开发代码 ...

# 2. 创建功能开关（10% 流量）
# 使用 API 或代码创建功能开关

# 3. 执行灰度发布
./deploy.sh
# 选择 8) 灰度发布

# 4. 监控灰度版本
docker logs -f hifate-bazi-web-gray

# 5. 逐步增加流量（如果正常）
# 调整负载均衡器配置：10% → 20% → 50% → 100%

# 6. 如果异常，立即回滚
./deploy.sh
# 选择 10) 灰度发布回滚
```

**灰度发布检查清单**：
- [ ] 是否创建了功能开关（百分比开关）
- [ ] 是否执行了灰度发布脚本
- [ ] 是否配置了负载均衡器流量分配
- [ ] 是否监控了关键指标（错误率、响应时间、业务指标）
- [ ] 是否准备了回滚方案

**监控指标**：
- 错误率（应 < 1%）
- 响应时间（不应明显增加）
- 业务指标（转化率、用户满意度等）
- 系统资源（CPU、内存、数据库连接等）

---

### 🔄 数据库回滚规范

#### 1. 所有数据库变更必须准备回滚脚本

**要求**：
- 所有数据库迁移必须同时准备回滚脚本
- 回滚脚本必须经过测试验证
- 回滚脚本命名规范：`rollback_YYYYMMDD_HHMMSS_description.sql`

**开发流程**：

```bash
# 1. 创建数据库迁移脚本
# scripts/migration/add_user_table.sql
CREATE TABLE `new_user_table` (...);

# 2. 同时创建回滚脚本
./scripts/migration/create_rollback.sh
# 输入描述：回滚添加用户表

# 3. 编辑回滚脚本
# scripts/migration/rollback/rollback_20250115_143000_add_user_table.sql
START TRANSACTION;
DROP TABLE IF EXISTS `new_user_table`;
COMMIT;

# 4. 在测试环境验证回滚脚本
mysql -h test_host -u root -p test_db < scripts/migration/rollback/rollback_*.sql

# 5. 执行迁移（生产环境）
# 如果失败，立即执行回滚
./deploy.sh
# 选择 9) 数据库回滚
```

**回滚脚本规范**：
- 必须使用事务（`START TRANSACTION` / `COMMIT`）
- 必须使用 `IF EXISTS` 避免错误
- 必须包含验证 SQL（可选）
- 必须记录回滚日志

**检查清单**：
- [ ] 是否创建了回滚脚本
- [ ] 回滚脚本是否经过测试验证
- [ ] 回滚脚本是否使用事务
- [ ] 是否可以在生产环境快速执行回滚

---

### 📝 开发检查清单

每次开发新功能或重要变更时，必须检查：

#### A/B 测试检查
- [ ] 是否创建了 A/B 测试实验
- [ ] 是否在代码中正确分配变体
- [ ] 是否记录了关键事件
- [ ] 是否可以通过 API 查看统计

#### 功能开关检查
- [ ] 是否创建了功能开关
- [ ] 是否在代码中正确检查开关
- [ ] 是否支持快速关闭
- [ ] 是否可以通过 API 切换

#### 灰度发布检查
- [ ] 是否执行了灰度发布
- [ ] 是否配置了流量分配
- [ ] 是否监控了关键指标
- [ ] 是否准备了回滚方案

#### 数据库回滚检查
- [ ] 是否创建了回滚脚本
- [ ] 回滚脚本是否经过测试
- [ ] 是否可以在生产环境快速执行

---

### 🎯 使用场景示例

#### 场景 1：新算法上线

```python
# 1. 创建 A/B 测试实验
experiment = Experiment(
    name="新算法测试",
    status=ExperimentStatus.RUNNING,
    traffic_percent=50.0,
    variants={"A": 50, "B": 50}
)

# 2. 在代码中使用
variant = manager.assign_variant("新算法测试", user_id)
if variant == "A":
    result = old_algorithm.calculate()
else:
    result = new_algorithm.calculate()

# 3. 记录事件
manager.record_event("新算法测试", user_id, "calculate", {"result": result})

# 4. 分析统计，决定是否全量上线
stats = manager.get_experiment_stats("新算法测试")
```

#### 场景 2：新功能灰度发布

```python
# 1. 创建功能开关（10% 流量）
flag = FeatureFlag(
    name="新功能",
    enabled=True,
    flag_type=FlagType.PERCENTAGE,
    value=10.0
)

# 2. 在代码中检查
if manager.is_enabled("新功能", user_id):
    result = new_feature.process()
else:
    result = old_feature.process()

# 3. 监控指标，逐步增加流量
# 10% → 20% → 50% → 100%
```

#### 场景 3：数据库变更

```sql
-- 1. 迁移脚本
-- scripts/migration/add_index.sql
ALTER TABLE `user_table` ADD INDEX `idx_email` (`email`);

-- 2. 回滚脚本
-- scripts/migration/rollback/rollback_20250115_143000_add_index.sql
START TRANSACTION;
ALTER TABLE `user_table` DROP INDEX IF EXISTS `idx_email`;
COMMIT;
```

---

### 📚 相关文档

- [A/B 测试和灰度发布指南](../docs/A_B测试和灰度发布指南.md) - 详细使用说明
- [部署文档](../docs/Docker生产部署完整指南.md) - 部署指南

---

### ⚠️ 注意事项

1. **A/B 测试**：
   - 确保变体流量总和为 100%
   - 同一用户在同一实验中总是分配到相同变体
   - 定期分析统计，及时调整实验

2. **功能开关**：
   - 百分比开关基于用户ID哈希，确保一致性
   - 白名单/黑名单需要明确的用户ID列表
   - 紧急情况可以快速关闭功能

3. **灰度发布**：
   - 从 10% 流量开始，逐步增加
   - 监控关键指标，随时准备回滚
   - 保留回滚脚本和回滚方案

4. **数据库回滚**：
   - 执行回滚前必须备份数据
   - 先在测试环境验证回滚脚本
   - 某些操作（如删除数据）无法完全回滚

---

## 📚 文档维护规范

### 🔄 文档同步原则

**核心原则**：操作更新时，文档必须同步更新

### 📝 需要同步更新的场景

| 场景 | 需要更新的文档 | 更新内容 |
|------|--------------|---------|
| 新增部署步骤 | `docs/Docker生产部署完整指南.md` | 添加新步骤 |
| 修改部署命令 | `docs/Docker生产部署完整指南.md` | 更新命令 |
| 新增故障排查 | `docs/Docker生产部署完整指南.md` | 添加问题解决方案 |
| 修改配置项 | `docs/Docker生产部署完整指南.md` | 更新配置说明 |
| 新增脚本 | `docs/Docker生产部署完整指南.md` | 添加脚本使用说明 |
| 修改开发流程 | `.cursorrules` | 更新相关章节 |

### ✅ 文档更新检查清单

每次修改部署相关操作时，必须检查：

- [ ] 是否更新了 `docs/Docker生产部署完整指南.md`
- [ ] 是否更新了 `.cursorrules` 中的相关章节
- [ ] 是否更新了脚本中的注释
- [ ] 是否更新了 README（如有）

### 📋 文档维护流程

1. **修改操作** → 立即更新文档
2. **提交代码** → 同时提交文档更新
3. **验证部署** → 验证文档准确性
4. **标记更新日期** → 在文档顶部更新日期

### 🎯 主要部署文档

| 文档 | 用途 | 维护频率 |
|------|------|---------|
| `docs/Docker生产部署完整指南.md` | **主要部署文档** | 每次操作变更 |
| `docs/Docker基础镜像优化.md` | 基础镜像详细说明 | 基础镜像变更时 |
| `.cursorrules` | 开发规范 | 规范变更时 |

---

**核心要点**：
- **🔴 最高优先级**：**所有新功能必须遵守开发规范**（见"新功能开发强制规范"）
- **📋 开发前必读**：开发新功能前必须阅读相关规范章节并完成检查清单
- **✅ 强制检查**：所有新功能必须通过开发规范检查清单验证
- 新增 API 必须同时注册 gRPC 端点（见"后端注册规范"）
- 新增规则类型必须同步更新前后端（见"类型映射"和"问题4"）
- 数据库配置使用 `hifate_bazi` 而非 `bazi_system`（见"数据库配置默认值"）
- 规则 `rule_type` 使用英文小写（见"规则类型命名"）
- **所有规则必须从数据库读取，禁止从文件读取**（见"规则存储规范"）
- **所有规则匹配必须使用 `RuleService`，禁止使用 `FormulaRuleService`**（见"规则存储规范"）
- **每次问题必须复盘并更新开发规范**（见"问题复盘机制"）
- **操作更新时，文档必须同步更新**（见"文档维护规范"）
- **新功能必须支持 A/B 测试和功能开关**（见"A/B 测试和灰度发布规范"）
- **重要变更必须通过灰度发布**（见"A/B 测试和灰度发布规范"）
- **数据库变更必须准备回滚脚本**（见"A/B 测试和灰度发布规范"）
- **意图识别必须使用混合架构，响应时间 < 1秒**（见"意图识别混合架构规范"）
- **所有新功能必须同步编写测试案例，测试覆盖率 ≥ 50%**（见"测试开发规范"）
- **所有关键流程必须记录性能监控**（见"智能运势分析性能监控规范"）

---

## 🚀 意图识别混合架构规范 【必须遵守】

### 🔴 核心原则

> **意图识别响应时间必须 < 1秒，使用混合架构实现高性能。**

### 📋 架构设计

**混合架构流程**：
```
用户输入
    ↓
【第1层：关键词过滤】（0ms，处理60%的明确问题）
    ├─ 强指示词 → 直接通过（99%准确）
    ├─ 黑名单 → 直接拒绝（95%准确）
    └─ 白名单 → 直接通过（90%准确）
    ↓
【第2层：本地BERT模型】（50-100ms，处理20%的简单问题）
    ├─ 模型分类（如果可用）
    └─ 关键词回退（如果模型不可用）
    ↓
【第3层：判断是否需要LLM兜底】
    ├─ 置信度 < 0.6 → LLM
    ├─ 问题模糊 → LLM
    └─ 复杂时间表达 → LLM
    ↓
【第4层：规则后处理】（10-20ms）
    ├─ 时间意图解析（支持中文数字）
    ├─ 多意图合并
    └─ JSON格式化
    ↓
【第5层：LLM兜底】（500-1000ms，仅处理5%的模糊问题）
    └─ 仅处理复杂/模糊问题
    ↓
最终结果
```

### 🎯 性能要求

| 场景 | 占比 | 响应时间 | 准确率 | 使用技术 |
|------|------|---------|--------|---------|
| 关键词明确 | 60% | <10ms | 95%+ | 关键词过滤 |
| 简单问题 | 20% | 50-100ms | 85-90% | 本地模型 + 规则 |
| 复杂问题 | 15% | 100-200ms | 80-85% | 本地模型 + 规则 |
| 模糊问题 | 5% | 500-1000ms | 90%+ | LLM兜底 |

**平均响应时间**：< 100ms（满足 < 1秒要求）

### 📁 核心文件

| 文件 | 作用 | 说明 |
|------|------|------|
| `services/intent_service/local_classifier.py` | 本地BERT模型分类器 | 处理简单问题（50-100ms） |
| `services/intent_service/rule_postprocessor.py` | 规则后处理器 | 时间意图解析、JSON格式化（10-20ms） |
| `services/intent_service/classifier.py` | 混合架构路由 | 智能路由到不同处理层 |
| `services/intent_service/question_filter.py` | 关键词过滤器 | 快速过滤明确问题（0ms） |
| `services/intent_service/llm_client.py` | LLM客户端 | 兜底处理复杂问题（500-1000ms） |

### 🔧 实现要求

#### 1. 本地模型分类器

**要求**：
- 使用BERT/RoBERTa中文模型（可选，如果不可用则使用关键词回退）
- 支持关键词回退方案（确保模型不可用时仍能工作）
- 响应时间 < 100ms

**实现示例**：
```python
from services.intent_service.local_classifier import LocalIntentClassifier

classifier = LocalIntentClassifier()
result = classifier.classify(question)
# 返回：{"intents": ["wealth"], "confidence": 0.85, "method": "local_model"}
```

#### 2. 规则后处理器

**要求**：
- 支持中文数字和阿拉伯数字的时间表达
- 支持多种时间类型（今天、本月、今年、明年、后N年、XXXX年、XXXX-YYYY年等）
- 响应时间 < 20ms

**时间意图类型**：
- `today` - 今天/今日
- `this_month` - 本月/这个月
- `this_year` - 今年/本年（默认）
- `next_year` - 明年（只有1年）
- `future_years` - 后N年/未来N年（N年）
- `recent_years` - 最近N年
- `specific_year` - XXXX年（单个年份）
- `year_range` - XXXX-YYYY年（年份范围）

**实现示例**：
```python
from services.intent_service.rule_postprocessor import RulePostProcessor

processor = RulePostProcessor()
result = processor.process(question, base_result)
# 返回：包含time_intent的完整结果
```

#### 3. 混合架构路由

**要求**：
- 智能判断是否需要LLM兜底
- 优先使用本地模型，仅在必要时调用LLM
- 确保平均响应时间 < 100ms

**LLM兜底条件**：
- 本地模型置信度 < 0.6
- 问题过于模糊（长度 < 5 或缺少关键词）
- 多意图冲突（意图数量 > 2 且置信度低）
- 复杂时间表达（需要上下文理解）

**实现示例**：
```python
from services.intent_service.classifier import IntentClassifier

classifier = IntentClassifier()
result = classifier.classify(question)
# 自动路由到合适的处理层
```

### ⚙️ 配置项

在 `services/intent_service/config.py` 中：

```python
# 混合架构配置
HYBRID_ARCHITECTURE_ENABLED = os.getenv("HYBRID_ARCHITECTURE_ENABLED", "true").lower() == "true"
LOCAL_MODEL_NAME = os.getenv("LOCAL_MODEL_NAME", "hfl/chinese-roberta-wwm-ext")
LLM_FALLBACK_THRESHOLD = float(os.getenv("LLM_FALLBACK_THRESHOLD", "0.6"))  # 置信度阈值
```

### ✅ 检查清单

每次修改意图识别相关代码时，必须检查：

- [ ] 平均响应时间是否 < 100ms
- [ ] 是否优先使用本地模型/关键词过滤
- [ ] LLM兜底是否仅在必要时调用（< 5%的情况）
- [ ] 时间意图识别是否支持中文数字
- [ ] 是否支持所有时间类型（今天、明年、后N年、XXXX年等）
- [ ] 错误处理是否完善（模型不可用时使用回退方案）

### 🚨 常见问题

#### 问题1：时间意图识别失败

**症状**："后三年"无法识别为`future_years`

**原因**：正则表达式不支持中文数字

**解决**：在`rule_postprocessor.py`中支持中文数字转换

#### 问题2：响应时间过长

**症状**：平均响应时间 > 1秒

**原因**：过多调用LLM API

**解决**：
- 降低LLM兜底阈值（`LLM_FALLBACK_THRESHOLD`）
- 优化关键词过滤规则
- 增强本地模型能力

#### 问题3：本地模型不可用

**症状**：`transformers`未安装或模型加载失败

**解决**：自动使用关键词回退方案，确保服务可用

---

**核心要点**：
- **意图识别必须使用混合架构，响应时间 < 1秒**
- **优先使用本地模型/关键词过滤，LLM仅作为兜底**
- **时间意图识别必须支持中文数字和阿拉伯数字**
- **所有时间类型必须正确识别（今天、明年、后N年、XXXX年等）**

---

## 📊 智能运势分析性能监控规范 【必须遵守】

### 🔴 核心原则

> **所有智能运势分析流程必须记录端到端日志和性能监控，确保每个阶段的响应时间可控。**

### 📋 性能监控要求

**必须监控的阶段**：
1. **意图识别** (`intent_recognition`) - 目标：< 100ms
2. **八字计算** (`bazi_calculation`) - 目标：< 50ms
3. **规则匹配** (`rule_matching`) - 目标：< 200ms
4. **流年大运分析** (`fortune_context`) - 目标：< 1000ms（可选）
5. **LLM深度解读** (`llm_analysis`) - 目标：< 2000ms（可选）
6. **生成响应文本** (`response_generation`) - 目标：< 50ms

### 🔧 实现方式

**使用 `PerformanceMonitor` 工具类**：

```python
from server.utils.performance_monitor import PerformanceMonitor

# 初始化监控器
monitor = PerformanceMonitor()

# 使用上下文管理器记录阶段
with monitor.stage("intent_recognition", "意图识别", question=question):
    intent_result = intent_client.classify(question=question)
    monitor.add_metric("intent_recognition", "intents_count", len(intent_result.get("intents", [])))

# 输出性能摘要
monitor.log_summary()

# 在响应中包含性能摘要
result = {
    "success": True,
    "response": response_text,
    "performance": monitor.get_summary()  # ⭐ 添加性能摘要
}
```

### 📊 性能摘要格式

性能摘要包含以下信息：
- `total_duration_ms`: 总耗时（毫秒）
- `stages`: 各阶段详细信息（耗时、成功/失败、指标等）
- `bottlenecks`: 性能瓶颈（>1秒的阶段）
- `failed_stages`: 失败的阶段

### ✅ 检查清单

每次修改智能运势分析相关代码时，必须检查：

- [ ] 是否使用 `PerformanceMonitor` 记录所有阶段
- [ ] 是否在响应中包含性能摘要
- [ ] 是否输出性能摘要到日志
- [ ] 是否识别并记录性能瓶颈（>1秒）
- [ ] 是否记录失败的阶段和错误信息

### 🚨 性能优化建议

**常见性能瓶颈**：
1. **LLM深度解读**：通常是最慢的阶段（500-2000ms），建议：
   - 使用流式输出提升用户体验
   - 考虑缓存常见问题的结果
   - 优化提示词减少响应时间

2. **流年大运分析**：可能较慢（500-1000ms），建议：
   - 仅在需要时启用（`include_fortune_context=True`）
   - 优化数据库查询
   - 考虑缓存计算结果

3. **规则匹配**：可能较慢（100-300ms），建议：
   - 优化规则匹配算法
   - 使用索引加速数据库查询
   - 考虑缓存匹配结果

### 📝 日志输出示例

```
================================================================================
[PerformanceMonitor] [req_1234567890] 性能摘要
================================================================================
总耗时: 2249ms (2.249s)
阶段数: 6

各阶段耗时:
  ✅ intent_recognition: 50ms (intents_count: 1, confidence: 0.85, method: local_model)
  ✅ bazi_calculation: 23ms
  ✅ rule_matching: 155ms (matched_rules_count: 25, rule_types_count: 1)
  ✅ fortune_context: 803ms (liunian_count: 3)
  ✅ llm_analysis: 1202ms (analysis_length: 500)
  ✅ response_generation: 12ms (response_length: 2000)

⚠️ 性能瓶颈（>1秒）:
  - llm_analysis: 1202ms - LLM深度解读
================================================================================
```

### 🎯 性能目标

| 阶段 | 目标耗时 | 警告阈值 | 说明 |
|------|---------|---------|------|
| 意图识别 | < 100ms | > 200ms | 使用混合架构，大部分请求应 < 100ms |
| 八字计算 | < 50ms | > 100ms | 本地计算，应该很快 |
| 规则匹配 | < 200ms | > 500ms | 数据库查询，可能较慢 |
| 流年大运 | < 1000ms | > 2000ms | 可选功能，可能较慢 |
| LLM深度解读 | < 2000ms | > 5000ms | 可选功能，通常最慢 |
| 生成响应 | < 50ms | > 100ms | 文本生成，应该很快 |

**总耗时目标**：
- 不包含流年大运和LLM：< 500ms
- 包含流年大运：< 2000ms
- 包含流年大运和LLM：< 5000ms

---

**核心要点**：
- **所有智能运势分析流程必须使用 `PerformanceMonitor` 记录性能**
- **性能摘要必须包含在API响应中**
- **必须识别并记录性能瓶颈（>1秒）**
- **必须记录失败的阶段和错误信息**

---

## 🧪 测试开发规范 【必须遵守】

### 🔴 核心原则

> **所有新功能必须同步编写测试案例，测试覆盖率必须达到 50% 以上。**

### 📋 测试要求

#### 1. 新增功能必须同步编写测试

**要求**：
- ✅ 新增 API 端点必须编写对应的测试案例
- ✅ 新增服务功能必须编写单元测试
- ✅ 新增业务逻辑必须编写集成测试
- ✅ 修改现有功能必须更新相关测试

**检查清单**：
- [ ] 新功能是否有对应的测试文件
- [ ] 测试是否覆盖正常流程
- [ ] 测试是否覆盖异常流程
- [ ] 测试是否覆盖边界情况
- [ ] 测试是否通过 CI/CD 验证

#### 2. 测试覆盖率要求

**覆盖率目标**：
- **单元测试覆盖率**：≥ 50%（核心模块 ≥ 70%）
- **API 测试覆盖率**：≥ 80%（所有公开 API 必须有测试）
- **集成测试覆盖率**：≥ 60%（关键业务流程必须有测试）

**检查命令**：
```bash
# 运行测试并生成覆盖率报告
pytest tests/ --cov=server --cov=src --cov-report=html --cov-report=term-missing

# 查看覆盖率报告
open htmlcov/index.html  # macOS
# 或访问 htmlcov/index.html
```

#### 3. 测试分类和命名规范

**测试文件命名**：
- 单元测试：`tests/unit/test_<module_name>.py`
- 集成测试：`tests/integration/test_<feature_name>.py`
- API 测试：`tests/api/test_<api_name>.py`
- 功能测试：`tests/features/test_<feature_name>.py`
- 端到端测试：`tests/e2e/test_<scenario_name>.py`

**测试函数命名**：
```python
# ✅ 正确：使用 test_ 前缀
def test_calculate_bazi_success():
    """测试成功计算八字"""
    ...

def test_calculate_bazi_invalid_date():
    """测试无效日期输入"""
    ...

# ❌ 错误：不使用 test_ 前缀
def calculate_bazi_test():
    ...
```

**测试类命名**：
```python
# ✅ 正确：使用 Test 前缀
class TestBaziService:
    """八字服务测试类"""
    ...

# ❌ 错误：不使用 Test 前缀
class BaziServiceTest:
    ...
```

#### 4. 测试标记（Markers）

**使用 pytest markers 分类测试**：
```python
import pytest

@pytest.mark.unit
def test_calculate_bazi():
    """单元测试"""
    ...

@pytest.mark.integration
def test_api_integration():
    """集成测试"""
    ...

@pytest.mark.api
def test_bazi_api():
    """API 测试"""
    ...

@pytest.mark.e2e
def test_end_to_end():
    """端到端测试"""
    ...

@pytest.mark.slow
def test_performance():
    """慢速测试（性能测试）"""
    ...
```

**运行特定类型的测试**：
```bash
# 只运行单元测试
pytest -m unit

# 只运行集成测试
pytest -m integration

# 只运行 API 测试
pytest -m api

# 排除慢速测试
pytest -m "not slow"
```

#### 5. 测试数据管理

**使用 fixtures 管理测试数据**：
```python
# tests/conftest.py
import pytest
from server.services.bazi_service import BaziService

@pytest.fixture
def sample_bazi_data():
    """示例八字数据"""
    return {
        "solar_date": "1990-01-15",
        "solar_time": "12:00",
        "gender": "male"
    }

@pytest.fixture
def bazi_service():
    """八字服务实例"""
    return BaziService()
```

**使用参数化测试**：
```python
import pytest

@pytest.mark.parametrize("solar_date,solar_time,gender,expected", [
    ("1990-01-15", "12:00", "male", "庚午"),
    ("1995-05-20", "14:30", "female", "乙亥"),
])
def test_calculate_bazi(solar_date, solar_time, gender, expected):
    """参数化测试"""
    result = calculate_bazi(solar_date, solar_time, gender)
    assert result["day_pillar"] == expected
```

#### 6. 测试执行规范

**本地开发时**：
```bash
# 运行所有测试
pytest

# 运行特定文件
pytest tests/unit/test_bazi_service.py

# 运行特定测试函数
pytest tests/unit/test_bazi_service.py::test_calculate_bazi

# 运行并显示覆盖率
pytest --cov=server --cov=src --cov-report=term-missing
```

**提交代码前**：
```bash
# 必须运行测试，确保通过
pytest tests/

# 检查覆盖率
pytest --cov=server --cov=src --cov-report=term-missing --cov-fail-under=50
```

#### 7. CI/CD 自动测试

**触发条件**：
- ✅ 推送到 `master` 或 `develop` 分支
- ✅ 创建 Pull Request
- ✅ 手动触发（GitHub Actions）

**测试流程**：
1. **代码质量检查**（lint）
   - Black 代码格式检查
   - isort 导入排序检查
   - pylint 代码质量检查
   - mypy 类型检查

2. **单元测试**（test）
   - 运行所有单元测试
   - 生成覆盖率报告
   - 上传到 Codecov

3. **集成测试**（integration-test）
   - 运行集成测试
   - 验证 API 集成

**测试结果监控**：
- **GitHub Actions**：`.github/workflows/ci.yml`
- **Codecov**：覆盖率报告和趋势
- **测试报告**：`htmlcov/index.html`（本地）

#### 8. 测试失败处理

**测试失败时**：
1. **查看测试日志**：GitHub Actions 输出
2. **本地复现**：在本地运行失败的测试
3. **修复问题**：修复代码或更新测试
4. **重新提交**：确保所有测试通过

**禁止操作**：
- ❌ 禁止跳过失败的测试（除非是已知问题）
- ❌ 禁止降低测试覆盖率要求
- ❌ 禁止删除失败的测试

#### 9. 测试最佳实践

**编写测试的原则**：
1. **独立性**：每个测试应该独立运行，不依赖其他测试
2. **可重复性**：测试结果应该一致，不依赖外部状态
3. **快速执行**：单元测试应该快速执行（< 1秒）
4. **清晰命名**：测试名称应该清晰描述测试内容
5. **单一职责**：每个测试只测试一个功能点

**示例**：
```python
# ✅ 好的测试
def test_calculate_bazi_with_valid_date():
    """测试：使用有效日期计算八字"""
    result = calculate_bazi("1990-01-15", "12:00", "male")
    assert result["success"] == True
    assert "bazi" in result

# ❌ 不好的测试
def test_all():
    """测试所有功能"""
    # 测试太多内容，难以定位问题
    ...
```

#### 10. 测试覆盖率监控

**覆盖率报告位置**：
- **本地**：`htmlcov/index.html`
- **CI/CD**：GitHub Actions 输出
- **在线**：Codecov（如果配置）

**覆盖率要求**：
- **整体覆盖率**：≥ 50%
- **核心模块**（server/services/）：≥ 70%
- **API 端点**（server/api/）：≥ 80%
- **工具函数**（server/utils/）：≥ 60%

**查看覆盖率**：
```bash
# 生成 HTML 报告
pytest --cov=server --cov=src --cov-report=html

# 查看报告
open htmlcov/index.html
```

---

### 📝 测试开发检查清单

每次开发新功能时，必须检查：

- [ ] 是否创建了对应的测试文件
- [ ] 是否编写了正常流程测试
- [ ] 是否编写了异常流程测试
- [ ] 是否编写了边界情况测试
- [ ] 测试是否通过本地运行
- [ ] 测试是否通过 CI/CD 验证
- [ ] 覆盖率是否达到要求（≥ 50%）
- [ ] 是否更新了测试文档

---

### 🚨 测试规范违反处理

**如果发现违反测试规范**：
1. **立即修复**：补充缺失的测试
2. **更新规范**：如果规范不合理，更新规范
3. **记录问题**：在开发日志中记录问题
4. **防止再次发生**：更新检查清单

---

**核心要点**：
- **所有新功能必须同步编写测试案例**
- **测试覆盖率必须达到 50% 以上**
- **所有测试必须通过 CI/CD 验证**
- **测试失败必须修复后才能合并代码**

---

## 🏗️ 生产环境架构规范 【必须遵守】

### 🔴 核心原则

> **生产环境架构信息必须记录在开发规范中，确保系统的继承性、稳定性和可用性。**

### 📋 生产环境架构

#### 双机部署架构

```
┌─────────────────────────────────────────────────────────────────┐
│                        生产环境双机架构                          │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  ┌──────────────────────┐         ┌──────────────────────┐    │
│  │      Node1 (主节点)   │         │      Node2 (从节点)   │    │
│  │  8.210.52.217        │         │  47.243.160.43       │    │
│  │  172.18.121.222      │         │  172.18.121.223      │    │
│  ├──────────────────────┤         ├──────────────────────┤    │
│  │  Nginx (80/443)      │◄───────►│  Nginx (80/443)      │    │
│  │  Web (8001)          │         │  Web (8001)          │    │
│  │  MySQL 主库 (3306)   │◄──复制──►│  MySQL 从库 (3306)   │    │
│  │  Redis 主库 (6379)   │◄──复制──►│  Redis 从库 (6379)   │    │
│  │  微服务 (9001-9010)  │         │  微服务 (9001-9010)  │    │
│  └──────────────────────┘         └──────────────────────┘    │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

#### 服务器信息

| 节点 | 公网IP | 内网IP | 角色 | 状态 |
|------|--------|--------|------|------|
| Node1 | 8.210.52.217 | 172.18.121.222 | 主节点（MySQL主/Redis主） | ✅ 运行中 |
| Node2 | 47.243.160.43 | 172.18.121.223 | 从节点（MySQL从/Redis从） | ✅ 运行中 |
| 测试环境 | 123.57.216.15 | - | 测试环境 | ✅ 运行中 |

#### 服务端口清单

| 服务 | 端口 | 说明 |
|------|------|------|
| Nginx | 80, 443 | 负载均衡和反向代理 |
| Web 服务 | 8001 | FastAPI 主服务 |
| bazi-core | 9001 | 八字核心计算服务 |
| bazi-fortune | 9002 | 运势计算服务 |
| bazi-analyzer | 9003 | 八字分析服务 |
| bazi-rule | 9004 | 规则匹配服务 |
| fortune-analysis | 9005 | 运势分析服务 |
| payment-service | 9006 | 支付服务 |
| fortune-rule | 9007 | 运势规则服务 |
| intent-service | 9008 | 意图识别服务 |
| prompt-optimizer | 9009 | 提示优化服务 |
| desk-fengshui | 9010 | 办公桌风水分析服务 |
| MySQL | 3306 | 数据库 |
| Redis | 6379 | 缓存 |

#### 负载均衡配置

**Nginx 负载均衡**：
- **上游服务器**：使用内网IP（172.18.121.222/223）
- **负载均衡算法**：轮询（weight=1）
- **故障转移**：`max_fails=3 fail_timeout=30s`
- **健康检查**：自动检测服务状态，故障时切换到备用节点

**超时配置**（已优化）：
```nginx
proxy_connect_timeout 10s;   # 连接超时：10秒（快速检测服务不可用）
proxy_send_timeout 30s;      # 发送超时：30秒（适合大多数API）
proxy_read_timeout 30s;      # 读取超时：30秒（适合大多数API）
proxy_next_upstream_timeout 5s;  # 故障转移超时：5秒（快速切换）
```

#### 数据库主从复制

**MySQL 主从复制**：
- **主库**：Node1 (172.18.121.222:3306)
- **从库**：Node2 (172.18.121.223:3306)
- **复制用户**：`repl@%`
- **复制方式**：GTID 自动定位
- **状态检查**：
  ```sql
  SHOW SLAVE STATUS\G
  -- Slave_IO_Running: Yes
  -- Slave_SQL_Running: Yes
  -- Seconds_Behind_Master: 0
  ```

**Redis 主从复制**：
- **主库**：Node1 (172.18.121.222:6379)
- **从库**：Node2 (172.18.121.223:6379)
- **复制方式**：自动同步

#### 部署配置信息

**环境变量**：
- **MySQL 密码**：`Yuanqizhan@163`
- **MySQL 复制密码**：`Yuanqizhan@163`
- **SECRET_KEY**：`kx9078L34ZoROnneJu8fMmJ70JImvVan88JYvxiewbE`
- **ACR 用户名**：从环境变量 `ACR_USERNAME` 或 `ACR_ACCESS_KEY_ID` 读取
- **ACR 密码**：从环境变量 `ACR_PASSWORD` 或 `ACR_ACCESS_KEY_SECRET` 读取
- **Git 仓库**：`https://github.com/zhoudengt/HiFate-bazi`

**项目目录**：
- **代码目录**：`/opt/HiFate-bazi`
- **部署配置**：`/opt/HiFate-bazi/deploy/docker`
- **环境变量**：`/opt/HiFate-bazi/.env`
- **日志目录**：`/opt/HiFate-bazi/logs`

---

### 🔧 生产环境部署规范

#### 部署前检查清单

- [ ] 确认服务器已初始化（Docker 已安装）
- [ ] 确认代码已克隆到 `/opt/HiFate-bazi`
- [ ] 确认环境变量已配置（`.env` 文件）
- [ ] 确认 Nginx 配置中的 IP 已替换为内网 IP
- [ ] 确认 gRPC 代码已修复（运行 `scripts/grpc/fix_version_check.py`）
- [ ] 确认 MySQL 主从复制用户已创建
- [ ] 确认 Redis 主从复制已配置

#### 部署步骤

1. **初始化服务器**（首次部署）：
   ```bash
   bash deploy/scripts/init-ecs.sh
   ```

2. **克隆代码**：
   ```bash
   cd /opt/HiFate-bazi
   git clone https://github.com/zhoudengt/HiFate-bazi .
   ```

3. **配置环境变量**：
   ```bash
   cp deploy/env/env.template .env
   vim .env  # 编辑配置
   ```

4. **修复 gRPC 代码**（必须）：
   ```bash
   python3 scripts/grpc/fix_version_check.py
   ```

5. **配置 Nginx**（必须）：
   ```bash
   # 替换 IP 占位符
   sed -i 's/NODE1_IP/172.18.121.222/g' deploy/nginx/conf.d/hifate.conf
   sed -i 's/NODE2_IP/172.18.121.223/g' deploy/nginx/conf.d/hifate.conf
   ```

6. **部署服务**：
   ```bash
   # Node1
   bash deploy/scripts/deploy.sh node1
   
   # Node2（在 Node1 部署完成后）
   bash deploy/scripts/deploy.sh node2
   ```

7. **配置 MySQL 主从复制**（Node2）：
   ```sql
   -- 在 Node1 创建复制用户
   CREATE USER 'repl'@'%' IDENTIFIED BY 'Yuanqizhan@163';
   GRANT REPLICATION SLAVE ON *.* TO 'repl'@'%';
   FLUSH PRIVILEGES;
   
   -- 在 Node2 配置从库
   CHANGE MASTER TO
       MASTER_HOST='172.18.121.222',
       MASTER_USER='repl',
       MASTER_PASSWORD='Yuanqizhan@163',
       MASTER_AUTO_POSITION=1;
   START SLAVE;
   ```

8. **验证部署**：
   ```bash
   # 检查服务状态
   docker ps | grep hifate
   
   # 检查健康状态
   curl http://8.210.52.217/health
   curl http://47.243.160.43/health
   
   # 检查 MySQL 主从复制
   docker exec -it hifate-mysql-slave mysql -uroot -pYuanqizhan@163 -e "SHOW SLAVE STATUS\G"
   ```

#### 日常运维命令

**查看服务状态**：
```bash
# Node1
ssh root@8.210.52.217 "docker ps | grep hifate"

# Node2
ssh root@47.243.160.43 "docker ps | grep hifate"
```

**查看日志**：
```bash
# Web 服务日志
docker logs hifate-web --tail 100

# 微服务日志
docker logs hifate-bazi-core --tail 100

# Nginx 日志
docker logs hifate-nginx --tail 100
```

**重启服务**：
```bash
# 重启单个服务
docker restart hifate-web

# 重启所有服务
cd /opt/HiFate-bazi/deploy/docker
docker-compose -f docker-compose.prod.yml -f docker-compose.node1.yml --env-file /opt/HiFate-bazi/.env restart
```

**更新代码**：
```bash
cd /opt/HiFate-bazi
git pull origin master
# 如果需要重启服务
bash deploy/scripts/deploy.sh node1  # 或 node2
```

---

### ⚠️ 生产环境注意事项

#### 1. 负载均衡配置

**必须使用内网 IP**：
- ✅ 正确：`server 172.18.121.222:8001`
- ❌ 错误：`server 8.210.52.217:8001`（公网IP，延迟高）
- ❌ 错误：`server NODE1_IP:8001`（占位符未替换）

**检查方法**：
```bash
docker exec hifate-nginx cat /etc/nginx/conf.d/hifate.conf | grep upstream
```

#### 2. gRPC 版本兼容性

**部署前必须修复**：
```bash
python3 scripts/grpc/fix_version_check.py
```

**问题现象**：
- 微服务持续重启
- 错误：`AttributeError: '_Server' object has no attribute 'add_registered_method_handlers'`

**解决方案**：
- 运行修复脚本
- 重启微服务

#### 3. Nginx 超时优化

**已优化配置**（提升用户体验）：
- 连接超时：10秒（快速检测服务不可用）
- 发送/读取超时：30秒（适合大多数API）
- 故障转移超时：5秒（快速切换）

#### 4. 服务健康检查

**定期检查**：
- 服务状态：`docker ps | grep hifate`
- 健康检查：`curl http://8.210.52.217/health`
- MySQL 主从复制：`SHOW SLAVE STATUS\G`
- Nginx 状态：`curl http://8.210.52.217/nginx_status`

#### 5. 性能监控

**关键指标**：
- API 响应时间：< 2秒（正常）
- 服务重启次数：0（正常）
- MySQL 主从延迟：0秒（正常）
- 负载均衡状态：两个节点都正常

---

### 📚 相关文档

- **部署文档**：`docs/root_docs/生产环境双机部署指南.md`
- **部署报告**：`docs/root_docs/生产环境双机部署最终报告.md`
- **问题诊断**：`docs/root_docs/双机部署问题诊断报告.md`

---

---

## 📁 前端目录规范 【必须遵守】

### 🔴 核心原则

> **本地前端目录命名为 `local_frontend`，与生产前端部署分离。**

### 📋 目录命名规范

| 目录 | 用途 | 说明 |
|------|------|------|
| **`local_frontend/`** | ✅ **本地前端目录** | 用于本地开发、测试、双机部署 |
| **生产前端** | ✅ **独立部署** | 由前端团队独立部署，不在此仓库 |

### 🔧 配置要求

#### 1. Docker Compose 配置

**生产环境配置** (`deploy/docker/docker-compose.prod.yml`)：
```yaml
volumes:
  - ../../local_frontend:/usr/share/nginx/html/local_frontend:ro
```

**本地前端配置** (`docker-compose.frontend.yml`)：
```yaml
volumes:
  - ./local_frontend:/usr/share/nginx/html:ro
```

#### 2. Nginx 配置

**所有 Nginx 配置文件中的路径**：
```nginx
root /usr/share/nginx/html/local_frontend;
```

#### 3. 后端代码配置

**`server/main.py`** 中的静态文件挂载：
```python
local_frontend_dir = os.path.join(project_root, "local_frontend")
if os.path.exists(local_frontend_dir):
    app.mount("/local_frontend", StaticFiles(directory=local_frontend_dir, html=True), name="local_frontend")
```

### ⚠️ 重要说明

1. **禁止修改生产前端**：生产环境的前端由前端团队独立部署，后端开发人员不得修改
2. **本地前端仅用于开发测试**：`local_frontend` 目录仅用于本地开发、测试环境、双机部署
3. **路径一致性**：所有配置文件中的路径必须统一使用 `local_frontend`
4. **部署脚本更新**：所有部署脚本必须引用 `local_frontend` 目录

### ✅ 检查清单

每次修改前端相关配置时，必须检查：

- [ ] Docker Compose 配置中的路径是否为 `local_frontend`
- [ ] Nginx 配置中的路径是否为 `local_frontend`
- [ ] 后端代码中的路径是否为 `local_frontend`
- [ ] 部署脚本中的路径是否为 `local_frontend`
- [ ] 文档中的路径是否为 `local_frontend`

---

**核心要点**：
- **生产环境架构信息必须记录在开发规范中**
- **部署前必须检查所有配置项**
- **必须使用内网 IP 进行负载均衡**
- **部署前必须修复 gRPC 代码**
- **定期检查服务健康状态**
- **本地前端目录必须使用 `local_frontend`，与生产前端分离**
