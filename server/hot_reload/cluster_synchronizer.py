#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŒæœºåŒæ­¥å™¨ - æ”¯æŒå¤šèŠ‚ç‚¹çƒ­æ›´æ–°åŒæ­¥

åŠŸèƒ½ï¼š
1. é€šè¿‡ Redis å‘å¸ƒ/è®¢é˜…åŒæ­¥çƒ­æ›´æ–°äº‹ä»¶
2. åˆ†å¸ƒå¼é”é˜²æ­¢å¹¶å‘æ›´æ–°å†²çª
3. ç¡®è®¤æœºåˆ¶ç¡®ä¿æ‰€æœ‰èŠ‚ç‚¹æ›´æ–°æˆåŠŸ
4. è‡ªåŠ¨é‡è¯•å’Œè¶…æ—¶å¤„ç†
"""

import os
import sys
import json
import time
import uuid
import socket
import threading
import logging
from typing import Dict, Optional, Callable, List
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.insert(0, project_root)

logger = logging.getLogger(__name__)


# Redis é¢‘é“
CHANNEL_TRIGGER = "hifate:hot-reload:trigger"
CHANNEL_CONFIRM = "hifate:hot-reload:confirm"
CHANNEL_ROLLBACK = "hifate:hot-reload:rollback"
CHANNEL_HEALTH = "hifate:hot-reload:health"

# åˆ†å¸ƒå¼é”
LOCK_KEY = "hifate:hot-reload:lock"
LOCK_TIMEOUT = 60  # 60ç§’è¶…æ—¶

# èŠ‚ç‚¹çŠ¶æ€é”®
NODE_STATUS_PREFIX = "hifate:hot-reload:node:"
NODE_STATUS_EXPIRE = 300  # 5åˆ†é’Ÿè¿‡æœŸ


class ClusterSynchronizer:
    """åŒæœºåŒæ­¥å™¨"""
    
    def __init__(
        self,
        node_id: str = None,
        on_trigger_callback: Optional[Callable] = None,
        on_rollback_callback: Optional[Callable] = None
    ):
        """
        åˆå§‹åŒ–åŒæœºåŒæ­¥å™¨
        
        Args:
            node_id: èŠ‚ç‚¹ IDï¼ˆé»˜è®¤ä½¿ç”¨ä¸»æœºåï¼‰
            on_trigger_callback: æ”¶åˆ°è§¦å‘äº‹ä»¶æ—¶çš„å›è°ƒ
            on_rollback_callback: æ”¶åˆ°å›æ»šäº‹ä»¶æ—¶çš„å›è°ƒ
        """
        self.node_id = node_id or self._get_node_id()
        self.on_trigger_callback = on_trigger_callback
        self.on_rollback_callback = on_rollback_callback
        
        self._redis_client = None
        self._pubsub = None
        self._running = False
        self._subscribe_thread: Optional[threading.Thread] = None
        
        # æ›´æ–°äº‹ä»¶è¿½è¸ª
        self._pending_events: Dict[str, Dict] = {}
        self._event_lock = threading.Lock()
    
    def _get_node_id(self) -> str:
        """ç”ŸæˆèŠ‚ç‚¹ ID"""
        hostname = socket.gethostname()
        # è·å– IP åœ°å€çš„æœ€åä¸€æ®µ
        try:
            ip = socket.gethostbyname(hostname)
            ip_suffix = ip.split('.')[-1]
        except Exception:
            ip_suffix = "unknown"
        
        return f"{hostname}-{ip_suffix}"
    
    def _get_redis_client(self):
        """è·å– Redis å®¢æˆ·ç«¯"""
        if self._redis_client is None:
            try:
                # ä½¿ç”¨ç»Ÿä¸€çš„ Redis è¿æ¥æ± ï¼ˆå­—ç¬¦ä¸²æ¨¡å¼ï¼‰
                from shared.config.redis import get_redis_client_str
                self._redis_client = get_redis_client_str()
            except ImportError:
                # å¦‚æœæ²¡æœ‰é…ç½®æ¨¡å—ï¼Œä½¿ç”¨é»˜è®¤è¿æ¥
                import redis
                self._redis_client = redis.Redis(
                    host=os.getenv('REDIS_HOST', 'localhost'),
                    port=int(os.getenv('REDIS_PORT', 6379)),
                    password=os.getenv('REDIS_PASSWORD'),
                    decode_responses=True
                )
        return self._redis_client
    
    def start(self):
        """å¯åŠ¨åŒæ­¥å™¨"""
        if self._running:
            return
        
        self._running = True
        
        # å¯åŠ¨è®¢é˜…çº¿ç¨‹
        self._subscribe_thread = threading.Thread(target=self._subscribe_loop, daemon=True)
        self._subscribe_thread.start()
        
        # æ³¨å†ŒèŠ‚ç‚¹çŠ¶æ€
        self._update_node_status("online")
        
        logger.info(f"âœ“ åŒæœºåŒæ­¥å™¨å·²å¯åŠ¨ (èŠ‚ç‚¹: {self.node_id})")
    
    def stop(self):
        """åœæ­¢åŒæ­¥å™¨"""
        self._running = False
        
        # æ›´æ–°èŠ‚ç‚¹çŠ¶æ€
        self._update_node_status("offline")
        
        # å…³é—­è®¢é˜…
        if self._pubsub:
            try:
                self._pubsub.unsubscribe()
                self._pubsub.close()
            except Exception:
                pass
        
        if self._subscribe_thread:
            self._subscribe_thread.join(timeout=2)
        
        logger.info(f"âœ“ åŒæœºåŒæ­¥å™¨å·²åœæ­¢ (èŠ‚ç‚¹: {self.node_id})")
    
    def _subscribe_loop(self):
        """è®¢é˜…å¾ªç¯"""
        while self._running:
            try:
                redis_client = self._get_redis_client()
                self._pubsub = redis_client.pubsub()
                
                # è®¢é˜…é¢‘é“
                self._pubsub.subscribe(
                    CHANNEL_TRIGGER,
                    CHANNEL_ROLLBACK,
                    CHANNEL_HEALTH
                )
                
                logger.info(f"âœ“ [{self.node_id}] å·²è®¢é˜…çƒ­æ›´æ–°é¢‘é“")
                
                # ç›‘å¬æ¶ˆæ¯
                for message in self._pubsub.listen():
                    if not self._running:
                        break
                    
                    if message['type'] == 'message':
                        self._handle_message(message['channel'], message['data'])
                
            except Exception as e:
                logger.warning(f"âš  [{self.node_id}] è®¢é˜…å¼‚å¸¸: {e}")
                time.sleep(5)  # é‡è¯•é—´éš”
    
    def _handle_message(self, channel: str, data: str):
        """å¤„ç†æ¥æ”¶åˆ°çš„æ¶ˆæ¯"""
        try:
            payload = json.loads(data) if isinstance(data, str) else data
            
            # å¿½ç•¥è‡ªå·±å‘é€çš„æ¶ˆæ¯
            if payload.get('source_node') == self.node_id:
                return
            
            if channel == CHANNEL_TRIGGER:
                self._handle_trigger(payload)
            elif channel == CHANNEL_ROLLBACK:
                self._handle_rollback(payload)
            elif channel == CHANNEL_HEALTH:
                self._handle_health_check(payload)
                
        except Exception as e:
            logger.warning(f"âš  [{self.node_id}] å¤„ç†æ¶ˆæ¯å¤±è´¥: {e}")
    
    def _handle_trigger(self, payload: Dict):
        """å¤„ç†çƒ­æ›´æ–°è§¦å‘äº‹ä»¶"""
        event_id = payload.get('event_id')
        modules = payload.get('modules', [])
        source_node = payload.get('source_node')
        
        logger.info(f"\nğŸ“¥ [{self.node_id}] æ”¶åˆ°çƒ­æ›´æ–°äº‹ä»¶ (æ¥è‡ª: {source_node}, æ¨¡å—: {modules})")
        
        try:
            # æ‰§è¡Œçƒ­æ›´æ–°
            if self.on_trigger_callback:
                success = self.on_trigger_callback(modules)
            else:
                # é»˜è®¤è¡Œä¸ºï¼šæ‰§è¡Œå…¨é‡çƒ­æ›´æ–°
                from .reloaders import reload_all_modules
                results = reload_all_modules()
                success = all(results.values())
            
            # å‘é€ç¡®è®¤
            self._send_confirm(event_id, success)
            
        except Exception as e:
            logger.error(f"âŒ [{self.node_id}] çƒ­æ›´æ–°æ‰§è¡Œå¤±è´¥: {e}")
            self._send_confirm(event_id, False, str(e))
    
    def _handle_rollback(self, payload: Dict):
        """å¤„ç†å›æ»šäº‹ä»¶"""
        event_id = payload.get('event_id')
        version = payload.get('version')
        source_node = payload.get('source_node')
        
        logger.warning(f"\nâš  [{self.node_id}] æ”¶åˆ°å›æ»šäº‹ä»¶ (æ¥è‡ª: {source_node}, ç‰ˆæœ¬: {version})")
        
        try:
            if self.on_rollback_callback:
                success = self.on_rollback_callback(version)
            else:
                logger.warning(f"âš  [{self.node_id}] æœªé…ç½®å›æ»šå›è°ƒ")
                success = False
            
            self._send_confirm(event_id, success, "rollback")
            
        except Exception as e:
            logger.error(f"âŒ [{self.node_id}] å›æ»šæ‰§è¡Œå¤±è´¥: {e}")
            self._send_confirm(event_id, False, str(e))
    
    def _handle_health_check(self, payload: Dict):
        """å¤„ç†å¥åº·æ£€æŸ¥"""
        request_id = payload.get('request_id')
        
        # å‘é€å¥åº·çŠ¶æ€
        self._publish(CHANNEL_CONFIRM, {
            'event_id': request_id,
            'node_id': self.node_id,
            'type': 'health',
            'status': 'healthy',
            'timestamp': datetime.now().isoformat()
        })
    
    def _send_confirm(self, event_id: str, success: bool, message: str = None):
        """å‘é€ç¡®è®¤æ¶ˆæ¯"""
        self._publish(CHANNEL_CONFIRM, {
            'event_id': event_id,
            'node_id': self.node_id,
            'success': success,
            'message': message,
            'timestamp': datetime.now().isoformat()
        })
    
    def _publish(self, channel: str, data: Dict):
        """å‘å¸ƒæ¶ˆæ¯"""
        try:
            redis_client = self._get_redis_client()
            redis_client.publish(channel, json.dumps(data, ensure_ascii=False))
        except Exception as e:
            logger.warning(f"âš  [{self.node_id}] å‘å¸ƒæ¶ˆæ¯å¤±è´¥: {e}")
    
    def _update_node_status(self, status: str):
        """æ›´æ–°èŠ‚ç‚¹çŠ¶æ€"""
        try:
            redis_client = self._get_redis_client()
            key = f"{NODE_STATUS_PREFIX}{self.node_id}"
            value = json.dumps({
                'node_id': self.node_id,
                'status': status,
                'timestamp': datetime.now().isoformat()
            }, ensure_ascii=False)
            redis_client.setex(key, NODE_STATUS_EXPIRE, value)
        except Exception as e:
            logger.warning(f"âš  [{self.node_id}] æ›´æ–°èŠ‚ç‚¹çŠ¶æ€å¤±è´¥: {e}")
    
    def trigger_cluster_update(self, modules: List[str] = None) -> str:
        """
        è§¦å‘é›†ç¾¤çƒ­æ›´æ–°
        
        Args:
            modules: è¦æ›´æ–°çš„æ¨¡å—åˆ—è¡¨ï¼ˆNone è¡¨ç¤ºå…¨éƒ¨ï¼‰
        
        Returns:
            str: äº‹ä»¶ ID
        """
        # è·å–åˆ†å¸ƒå¼é”
        if not self._acquire_lock():
            raise RuntimeError("æ— æ³•è·å–åˆ†å¸ƒå¼é”ï¼Œå¯èƒ½æœ‰å…¶ä»–èŠ‚ç‚¹æ­£åœ¨æ›´æ–°")
        
        try:
            event_id = str(uuid.uuid4())
            
            # è®°å½•äº‹ä»¶
            with self._event_lock:
                self._pending_events[event_id] = {
                    'modules': modules,
                    'timestamp': datetime.now().isoformat(),
                    'confirms': {}
                }
            
            # å‘å¸ƒè§¦å‘äº‹ä»¶
            self._publish(CHANNEL_TRIGGER, {
                'event_id': event_id,
                'source_node': self.node_id,
                'modules': modules or ['all'],
                'timestamp': datetime.now().isoformat()
            })
            
            logger.info(f"ğŸ“¤ [{self.node_id}] å·²å‘é€é›†ç¾¤çƒ­æ›´æ–°äº‹ä»¶ (ID: {event_id})")
            return event_id
            
        finally:
            self._release_lock()
    
    def trigger_cluster_rollback(self, version: int = None) -> str:
        """
        è§¦å‘é›†ç¾¤å›æ»š
        
        Args:
            version: è¦å›æ»šåˆ°çš„ç‰ˆæœ¬ï¼ˆNone è¡¨ç¤ºä¸Šä¸€ç‰ˆæœ¬ï¼‰
        
        Returns:
            str: äº‹ä»¶ ID
        """
        if not self._acquire_lock():
            raise RuntimeError("æ— æ³•è·å–åˆ†å¸ƒå¼é”")
        
        try:
            event_id = str(uuid.uuid4())
            
            self._publish(CHANNEL_ROLLBACK, {
                'event_id': event_id,
                'source_node': self.node_id,
                'version': version,
                'timestamp': datetime.now().isoformat()
            })
            
            logger.info(f"ğŸ“¤ [{self.node_id}] å·²å‘é€é›†ç¾¤å›æ»šäº‹ä»¶ (ID: {event_id})")
            return event_id
            
        finally:
            self._release_lock()
    
    def check_cluster_health(self) -> Dict[str, Dict]:
        """æ£€æŸ¥é›†ç¾¤å¥åº·çŠ¶æ€"""
        try:
            redis_client = self._get_redis_client()
            
            # è·å–æ‰€æœ‰èŠ‚ç‚¹çŠ¶æ€
            nodes = {}
            keys = redis_client.keys(f"{NODE_STATUS_PREFIX}*")
            
            for key in keys:
                try:
                    value = redis_client.get(key)
                    if value:
                        node_data = json.loads(value)
                        nodes[node_data['node_id']] = node_data
                except Exception:
                    pass
            
            return nodes
            
        except Exception as e:
            logger.warning(f"âš  [{self.node_id}] æ£€æŸ¥é›†ç¾¤å¥åº·å¤±è´¥: {e}")
            return {}
    
    def _acquire_lock(self, timeout: int = LOCK_TIMEOUT) -> bool:
        """è·å–åˆ†å¸ƒå¼é”"""
        try:
            redis_client = self._get_redis_client()
            lock_value = f"{self.node_id}:{time.time()}"
            
            # ä½¿ç”¨ SET NX EX åŸå­æ“ä½œ
            result = redis_client.set(LOCK_KEY, lock_value, nx=True, ex=timeout)
            return result is True
            
        except Exception as e:
            logger.warning(f"âš  [{self.node_id}] è·å–é”å¤±è´¥: {e}")
            return False
    
    def _release_lock(self):
        """é‡Šæ”¾åˆ†å¸ƒå¼é”"""
        try:
            redis_client = self._get_redis_client()
            redis_client.delete(LOCK_KEY)
        except Exception as e:
            logger.warning(f"âš  [{self.node_id}] é‡Šæ”¾é”å¤±è´¥: {e}")
    
    def get_status(self) -> Dict:
        """è·å–åŒæ­¥å™¨çŠ¶æ€"""
        return {
            'node_id': self.node_id,
            'running': self._running,
            'pending_events': len(self._pending_events),
            'cluster_nodes': self.check_cluster_health()
        }


# å…¨å±€åŒæ­¥å™¨å®ä¾‹
_cluster_synchronizer: Optional[ClusterSynchronizer] = None


def get_cluster_synchronizer() -> ClusterSynchronizer:
    """è·å–åŒæœºåŒæ­¥å™¨å•ä¾‹"""
    global _cluster_synchronizer
    if _cluster_synchronizer is None:
        _cluster_synchronizer = ClusterSynchronizer()
    return _cluster_synchronizer


def start_cluster_sync():
    """å¯åŠ¨é›†ç¾¤åŒæ­¥"""
    synchronizer = get_cluster_synchronizer()
    synchronizer.start()
    return synchronizer


def stop_cluster_sync():
    """åœæ­¢é›†ç¾¤åŒæ­¥"""
    global _cluster_synchronizer
    if _cluster_synchronizer:
        _cluster_synchronizer.stop()
        _cluster_synchronizer = None

