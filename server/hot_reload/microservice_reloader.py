#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¾®æœåŠ¡çƒ­æ›´æ–°å™¨ - æ”¯æŒ gRPC å¾®æœåŠ¡çš„çƒ­æ›´æ–°

åŠŸèƒ½ï¼š
1. ç›‘æŽ§å¾®æœåŠ¡ä»£ç æ–‡ä»¶å˜åŒ–
2. åŠ¨æ€é‡æ–°åŠ è½½ Servicer ç±»
3. æ”¯æŒçƒ­æ›¿æ¢ï¼Œä¸ä¸­æ–­æœåŠ¡
4. æ”¯æŒå›žæ»šåˆ°ä¸Šä¸€ç‰ˆæœ¬
"""

import os
import sys
import time
import ast
import hashlib
import importlib
import threading
from typing import Dict, Optional, Callable, Any, List, Type
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.insert(0, project_root)


class MicroserviceReloader:
    """å¾®æœåŠ¡çƒ­æ›´æ–°å™¨"""
    
    def __init__(
        self,
        service_name: str,
        module_path: str,
        servicer_class_name: str,
        watch_directories: List[str] = None,
        check_interval: int = 30,
        on_reload_callback: Optional[Callable] = None
    ):
        """
        åˆå§‹åŒ–å¾®æœåŠ¡çƒ­æ›´æ–°å™¨
        
        Args:
            service_name: æœåŠ¡åç§°ï¼ˆå¦‚ "bazi_core"ï¼‰
            module_path: ä¸»æ¨¡å—è·¯å¾„ï¼ˆå¦‚ "services.bazi_core.grpc_server"ï¼‰
            servicer_class_name: Servicer ç±»åï¼ˆå¦‚ "BaziCoreServicer"ï¼‰
            watch_directories: ç›‘æŽ§çš„ç›®å½•åˆ—è¡¨
            check_interval: æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰
            on_reload_callback: é‡è½½æˆåŠŸåŽçš„å›žè°ƒå‡½æ•°
        """
        self.service_name = service_name
        self.module_path = module_path
        self.servicer_class_name = servicer_class_name
        self.watch_directories = watch_directories or [
            os.path.join(project_root, "services", service_name),
            os.path.join(project_root, "src"),
        ]
        self.check_interval = check_interval
        self.on_reload_callback = on_reload_callback
        
        # æ–‡ä»¶çŠ¶æ€
        self._file_states: Dict[str, Dict] = {}
        self._running = False
        self._thread: Optional[threading.Thread] = None
        
        # ç‰ˆæœ¬ç®¡ç†
        self._current_version = 0
        self._version_history: List[Dict] = []
        self._max_history = 10
        
        # ä»£ç å¤‡ä»½ç›®å½•
        self._backup_dir = os.path.join(project_root, ".hot_reload_backups", service_name)
        os.makedirs(self._backup_dir, exist_ok=True)
        
        # é”™è¯¯æ—¥å¿—ç›®å½•
        self._error_log_dir = os.path.join(project_root, "logs", "hot_reload_errors")
        os.makedirs(self._error_log_dir, exist_ok=True)
        
        # å½“å‰ Servicer å®žä¾‹ï¼ˆç”¨äºŽçƒ­æ›¿æ¢ï¼‰
        self._current_servicer: Optional[Any] = None
        self._servicer_lock = threading.RLock()
        
        # åˆå§‹åŒ–æ–‡ä»¶çŠ¶æ€
        self._scan_files()
    
    def start(self):
        """å¯åŠ¨çƒ­æ›´æ–°ç›‘æŽ§"""
        if self._running:
            return
        
        self._running = True
        self._thread = threading.Thread(target=self._monitor_loop, daemon=True)
        self._thread.start()
        
        print(f"âœ“ [{self.service_name}] å¾®æœåŠ¡çƒ­æ›´æ–°ç›‘æŽ§å·²å¯åŠ¨ï¼ˆæ£€æŸ¥é—´éš”: {self.check_interval}ç§’ï¼‰")
    
    def stop(self):
        """åœæ­¢çƒ­æ›´æ–°ç›‘æŽ§"""
        self._running = False
        if self._thread:
            self._thread.join(timeout=2)
        print(f"âœ“ [{self.service_name}] å¾®æœåŠ¡çƒ­æ›´æ–°ç›‘æŽ§å·²åœæ­¢")
    
    def _monitor_loop(self):
        """ç›‘æŽ§å¾ªçŽ¯"""
        while self._running:
            try:
                if self._check_and_reload():
                    print(f"âœ“ [{self.service_name}] çƒ­æ›´æ–°å®Œæˆ")
            except Exception as e:
                print(f"âš  [{self.service_name}] çƒ­æ›´æ–°æ£€æŸ¥å¤±è´¥: {e}")
            
            time.sleep(self.check_interval)
    
    def _scan_files(self):
        """æ‰«ææ‰€æœ‰ç›‘æŽ§çš„æ–‡ä»¶"""
        for directory in self.watch_directories:
            if not os.path.exists(directory):
                continue
            
            for root, dirs, files in os.walk(directory):
                # æŽ’é™¤ç¼“å­˜ç›®å½•
                dirs[:] = [d for d in dirs if d not in {'__pycache__', '.mypy_cache', '.pytest_cache'}]
                
                for filename in files:
                    if not filename.endswith('.py'):
                        continue
                    
                    file_path = os.path.join(root, filename)
                    self._update_file_state(file_path)
    
    def _update_file_state(self, file_path: str, force_hash: bool = False) -> Optional[Dict]:
        """
        æ›´æ–°æ–‡ä»¶çŠ¶æ€ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼šä¼˜å…ˆä½¿ç”¨ä¿®æ”¹æ—¶é—´ï¼‰
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            force_hash: æ˜¯å¦å¼ºåˆ¶è®¡ç®—å“ˆå¸Œï¼ˆç”¨äºŽç¡®è®¤å˜åŒ–ï¼‰
        """
        if not os.path.exists(file_path):
            return None
        
        try:
            mtime = os.path.getmtime(file_path)
            old_state = self._file_states.get(file_path)
            
            # ä¼˜åŒ–ï¼šå¦‚æžœä¿®æ”¹æ—¶é—´æ²¡å˜ï¼Œç›´æŽ¥è¿”å›žæ—§çŠ¶æ€ï¼ˆé¿å…é‡å¤è®¡ç®—ï¼‰
            if old_state and not force_hash:
                if old_state['mtime'] == mtime:
                    # æ›´æ–°æ£€æŸ¥æ—¶é—´
                    old_state['last_check'] = time.time()
                    return old_state
            
            # åªæœ‰åœ¨ä¿®æ”¹æ—¶é—´å˜åŒ–æ—¶æ‰è®¡ç®—å“ˆå¸Œï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰
            file_hash = None
            if force_hash or (old_state and old_state['mtime'] != mtime):
                # åªè¯»å–æ–‡ä»¶ä¸€æ¬¡ï¼ŒåŒæ—¶è®¡ç®—å“ˆå¸Œå’Œæ£€æŸ¥è¯­æ³•
                with open(file_path, 'rb') as f:
                    file_content = f.read()
                    file_hash = hashlib.md5(file_content).hexdigest()
                
                # æ£€æŸ¥è¯­æ³•ï¼ˆä½¿ç”¨å·²è¯»å–çš„å†…å®¹ï¼‰
                syntax_valid = self._check_syntax_content(file_content, file_path)
            else:
                # å¦‚æžœä¿®æ”¹æ—¶é—´æ²¡å˜ï¼Œä½¿ç”¨æ—§çš„è¯­æ³•æ£€æŸ¥ç»“æžœ
                syntax_valid = old_state.get('syntax_valid', True) if old_state else True
                file_hash = old_state.get('hash') if old_state else None
            
            state = {
                'mtime': mtime,
                'hash': file_hash,
                'syntax_valid': syntax_valid,
                'last_check': time.time()
            }
            
            self._file_states[file_path] = state
            return state
            
        except Exception as e:
            print(f"âš  [{self.service_name}] æ— æ³•è¯»å–æ–‡ä»¶ {file_path}: {e}")
            return None
    
    def _check_syntax_content(self, content: bytes, file_path: str) -> bool:
        """æ£€æŸ¥æ–‡ä»¶å†…å®¹è¯­æ³•ï¼ˆä½¿ç”¨å·²è¯»å–çš„å†…å®¹ï¼‰"""
        try:
            source = content.decode('utf-8')
            ast.parse(source, filename=file_path)
            return True
        except SyntaxError as e:
            print(f"âŒ [{self.service_name}] è¯­æ³•é”™è¯¯ {file_path}: {e}")
            return False
        except Exception as e:
            print(f"âš  [{self.service_name}] æ£€æŸ¥è¯­æ³•å¤±è´¥ {file_path}: {e}")
            return False
    
    def _check_syntax(self, file_path: str) -> bool:
        """æ£€æŸ¥ Python è¯­æ³•"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                source = f.read()
            ast.parse(source, filename=file_path)
            return True
        except SyntaxError as e:
            print(f"âŒ [{self.service_name}] è¯­æ³•é”™è¯¯ {file_path}: {e}")
            return False
        except Exception as e:
            print(f"âš  [{self.service_name}] æ£€æŸ¥è¯­æ³•å¤±è´¥ {file_path}: {e}")
            return False
    
    def _check_and_reload(self) -> bool:
        """æ£€æŸ¥æ–‡ä»¶å˜åŒ–å¹¶é‡æ–°åŠ è½½"""
        changed_files = []
        
        for directory in self.watch_directories:
            if not os.path.exists(directory):
                continue
            
            for root, dirs, files in os.walk(directory):
                dirs[:] = [d for d in dirs if d not in {'__pycache__', '.mypy_cache', '.pytest_cache'}]
                
                for filename in files:
                    if not filename.endswith('.py'):
                        continue
                    
                    file_path = os.path.join(root, filename)
                    old_state = self._file_states.get(file_path)
                    
                    # å…ˆå¿«é€Ÿæ£€æŸ¥ä¿®æ”¹æ—¶é—´ï¼ˆä¸è®¡ç®—å“ˆå¸Œï¼‰
                    new_state = self._update_file_state(file_path, force_hash=False)
                    
                    if new_state is None:
                        continue
                    
                    # æ£€æµ‹å˜åŒ–ï¼ˆä¼˜å…ˆä½¿ç”¨ä¿®æ”¹æ—¶é—´ï¼Œæ€§èƒ½æ›´å¥½ï¼‰
                    if old_state is None:
                        # æ–°æ–‡ä»¶ï¼Œéœ€è¦è®¡ç®—å“ˆå¸Œç¡®è®¤
                        new_state = self._update_file_state(file_path, force_hash=True)
                        if new_state and new_state['syntax_valid']:
                            changed_files.append(('created', file_path))
                    elif old_state['mtime'] != new_state['mtime']:
                        # ä¿®æ”¹æ—¶é—´å˜åŒ–ï¼Œè®¡ç®—å“ˆå¸Œç¡®è®¤
                        new_state = self._update_file_state(file_path, force_hash=True)
                        if new_state and new_state['hash'] != old_state.get('hash'):
                            if new_state['syntax_valid']:
                                changed_files.append(('modified', file_path))
                            else:
                                print(f"âš  [{self.service_name}] æ–‡ä»¶æœ‰è¯­æ³•é”™è¯¯ï¼Œè·³è¿‡: {file_path}")
        
        if changed_files:
            print(f"\nðŸ”„ [{self.service_name}] æ£€æµ‹åˆ° {len(changed_files)} ä¸ªæ–‡ä»¶å˜åŒ–:")
            for change_type, file_path in changed_files:
                rel_path = os.path.relpath(file_path, project_root)
                print(f"   {change_type}: {rel_path}")
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯å…±äº«æ–‡ä»¶å˜åŒ–ï¼Œå¦‚æžœæ˜¯ï¼Œè§¦å‘æ‰€æœ‰ä¾èµ–æœåŠ¡
            for change_type, file_path in changed_files:
                rel_path = os.path.relpath(file_path, project_root)
                # å¦‚æžœå˜åŒ–çš„æ˜¯å…±äº«æ–‡ä»¶ï¼ˆsrc/ æˆ– server/ï¼‰ï¼Œè§¦å‘ä¾èµ–æœåŠ¡
                if rel_path.startswith('src/') or rel_path.startswith('server/'):
                    trigger_dependent_services(rel_path)
            
            return self._reload_servicer()
        
        return False
    
    def _reload_servicer(self) -> bool:
        """é‡æ–°åŠ è½½ Servicer ç±»"""
        try:
            # å¤‡ä»½å½“å‰ç‰ˆæœ¬ï¼ˆåŒ…æ‹¬ä»£ç æ–‡ä»¶ï¼‰
            backup_info = self._backup_current_version()
            
            # é‡æ–°åŠ è½½æ¨¡å—
            if self.module_path in sys.modules:
                module = sys.modules[self.module_path]
                module = importlib.reload(module)
            else:
                module = importlib.import_module(self.module_path)
            
            # èŽ·å–æ–°çš„ Servicer ç±»
            new_servicer_class = getattr(module, self.servicer_class_name)
            
            # æ£€æŸ¥å¹¶é‡ç½®ä¾èµ–å¯¹è±¡çš„å…¨å±€çŠ¶æ€
            self._reset_dependency_states(old_servicer)
            
            # é‡ç½®å•ä¾‹ï¼ˆä½¿ç”¨ SingletonReloaderï¼‰
            try:
                from server.hot_reload.reloaders import SingletonReloader
                SingletonReloader.reload()
            except Exception as e:
                print(f"âš  [{self.service_name}] å•ä¾‹é‡ç½®å¤±è´¥: {e}")
            
            # åˆ›å»ºæ–°å®žä¾‹ï¼ˆåœ¨é”å¤–åˆ›å»ºï¼Œé¿å…é•¿æ—¶é—´æŒé”ï¼‰
            new_servicer = new_servicer_class()
            
            # éªŒè¯æ–°å®žä¾‹æ˜¯å¦å¯ç”¨
            if not self._validate_servicer(new_servicer):
                raise RuntimeError("æ–° Servicer å®žä¾‹éªŒè¯å¤±è´¥")
            
            # åŽŸå­æ›¿æ¢ï¼ˆä½¿ç”¨åŒé‡æ£€æŸ¥é”å®šæ¨¡å¼ï¼‰
            with self._servicer_lock:
                # å†æ¬¡æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–çº¿ç¨‹å·²ç»æ›´æ–°
                if self._current_version != backup_info.get('version', self._current_version):
                    print(f"âš  [{self.service_name}] æ£€æµ‹åˆ°å¹¶å‘æ›´æ–°ï¼Œè·³è¿‡æœ¬æ¬¡æ›´æ–°")
                    return False
                
                # åŽŸå­æ›¿æ¢ï¼šå…ˆæ›´æ–°ç‰ˆæœ¬å·ï¼Œå†æ›¿æ¢å®žä¾‹ï¼ˆç¡®ä¿ä¸€è‡´æ€§ï¼‰
                old_servicer = self._current_servicer
                self._current_version += 1
                self._current_servicer = new_servicer
            
            # æ¸…é™¤ DynamicServicer çš„æ–¹æ³•ç¼“å­˜ï¼ˆå¦‚æžœæœ‰ï¼‰
            # æ³¨æ„ï¼šè¿™é‡Œæ— æ³•ç›´æŽ¥è®¿é—® DynamicServicerï¼Œä½†å¯ä»¥é€šè¿‡å›žè°ƒé€šçŸ¥
            
            # è®°å½•ç‰ˆæœ¬åŽ†å²ï¼ˆåŒ…å«å¤‡ä»½ä¿¡æ¯ï¼‰
            self._record_version(new_servicer_class, backup_info)
            
            print(f"âœ… [{self.service_name}] Servicer çƒ­æ›´æ–°æˆåŠŸ (ç‰ˆæœ¬: {self._current_version})")
            
            # æ‰§è¡Œå›žè°ƒ
            if self.on_reload_callback:
                try:
                    self.on_reload_callback(new_servicer)
                except Exception as e:
                    print(f"âš  [{self.service_name}] å›žè°ƒæ‰§è¡Œå¤±è´¥: {e}")
            
            return True
            
        except Exception as e:
            import traceback
            error_msg = str(e)
            error_traceback = traceback.format_exc()
            
            # è®°å½•è¯¦ç»†é”™è¯¯æ—¥å¿—
            error_log = {
                'service_name': self.service_name,
                'error': error_msg,
                'traceback': error_traceback,
                'timestamp': datetime.now().isoformat(),
                'version': self._current_version,
                'module_path': self.module_path,
            }
            
            # æ‰“å°é”™è¯¯ä¿¡æ¯
            print(f"âŒ [{self.service_name}] çƒ­æ›´æ–°å¤±è´¥: {error_msg}")
            print(error_traceback)
            
            # ä¿å­˜é”™è¯¯æ—¥å¿—åˆ°æ–‡ä»¶
            self._save_error_log(error_log)
            
            # å‘é€å‘Šè­¦ï¼ˆå¦‚æžœæœ‰é…ç½®ï¼‰
            self._send_alert(error_log)
            
            # å°è¯•å›žæ»š
            rollback_success = self._rollback()
            if not rollback_success:
                critical_error = {
                    **error_log,
                    'rollback_failed': True,
                    'status': 'CRITICAL'
                }
                print(f"âš  [{self.service_name}] å›žæ»šå¤±è´¥ï¼ŒæœåŠ¡å¯èƒ½å¤„äºŽä¸ç¨³å®šçŠ¶æ€")
                self._save_error_log(critical_error, is_critical=True)
                self._send_alert(critical_error, is_critical=True)
            
            return False
    
    def _backup_current_version(self) -> Dict:
        """å¤‡ä»½å½“å‰ç‰ˆæœ¬ï¼ˆåŒ…æ‹¬ä»£ç æ–‡ä»¶ï¼‰"""
        backup_info = {
            'version': self._current_version,
            'timestamp': datetime.now().isoformat(),
            'servicer_class': type(self._current_servicer).__name__ if self._current_servicer else None,
            'module_path': self.module_path,
            'backup_files': []
        }
        
        # å¤‡ä»½æ‰€æœ‰ç›‘æŽ§çš„æ–‡ä»¶
        version_backup_dir = os.path.join(self._backup_dir, f"v{self._current_version}")
        os.makedirs(version_backup_dir, exist_ok=True)
        
        for file_path in self._file_states.keys():
            if not os.path.exists(file_path):
                continue
            
            try:
                # è®¡ç®—ç›¸å¯¹è·¯å¾„
                rel_path = os.path.relpath(file_path, project_root)
                backup_file_path = os.path.join(version_backup_dir, rel_path.replace(os.sep, '_'))
                
                # åˆ›å»ºå¤‡ä»½ç›®å½•
                os.makedirs(os.path.dirname(backup_file_path), exist_ok=True)
                
                # å¤åˆ¶æ–‡ä»¶
                import shutil
                shutil.copy2(file_path, backup_file_path)
                
                backup_info['backup_files'].append({
                    'original': file_path,
                    'backup': backup_file_path,
                    'rel_path': rel_path
                })
            except Exception as e:
                print(f"âš  [{self.service_name}] å¤‡ä»½æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        
        # ä¿å­˜å¤‡ä»½ä¿¡æ¯
        backup_info_file = os.path.join(version_backup_dir, 'backup_info.json')
        try:
            import json
            with open(backup_info_file, 'w', encoding='utf-8') as f:
                json.dump(backup_info, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"âš  [{self.service_name}] ä¿å­˜å¤‡ä»½ä¿¡æ¯å¤±è´¥: {e}")
        
        # æ·»åŠ åˆ°åŽ†å²è®°å½•
        self._version_history.append(backup_info)
        
        # åªä¿ç•™æœ€è¿‘çš„åŽ†å²
        if len(self._version_history) > self._max_history:
            # åˆ é™¤æœ€æ—§çš„å¤‡ä»½
            oldest = self._version_history.pop(0)
            self._cleanup_backup(oldest)
            self._version_history = self._version_history[-self._max_history:]
        
        return backup_info
    
    def _cleanup_backup(self, backup_info: Dict):
        """æ¸…ç†å¤‡ä»½æ–‡ä»¶"""
        try:
            version = backup_info.get('version', 0)
            version_backup_dir = os.path.join(self._backup_dir, f"v{version}")
            if os.path.exists(version_backup_dir):
                import shutil
                shutil.rmtree(version_backup_dir)
        except Exception as e:
            print(f"âš  [{self.service_name}] æ¸…ç†å¤‡ä»½å¤±è´¥: {e}")
    
    def _reset_dependency_states(self, old_servicer: Optional[Any]):
        """é‡ç½®ä¾èµ–å¯¹è±¡çš„å…¨å±€çŠ¶æ€"""
        if old_servicer is None:
            return
        
        try:
            # æ£€æŸ¥ Servicer å®žä¾‹çš„å±žæ€§ï¼ŒæŸ¥æ‰¾å¯èƒ½çš„ä¾èµ–å¯¹è±¡
            servicer_attrs = dir(old_servicer)
            reset_count = 0
            
            for attr_name in servicer_attrs:
                if attr_name.startswith('_'):
                    continue
                
                try:
                    attr_value = getattr(old_servicer, attr_name, None)
                    if attr_value is None:
                        continue
                    
                    # æ£€æŸ¥æ˜¯å¦æ˜¯å•ä¾‹å¯¹è±¡
                    if self._is_singleton(attr_value):
                        reset_count += self._reset_singleton(attr_value, attr_name)
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰ reset() æ–¹æ³•
                    if hasattr(attr_value, 'reset') and callable(getattr(attr_value, 'reset')):
                        try:
                            attr_value.reset()
                            print(f"   âœ“ é‡ç½®ä¾èµ–å¯¹è±¡: {attr_name}.reset()")
                            reset_count += 1
                        except Exception as e:
                            print(f"   âš  é‡ç½®ä¾èµ–å¯¹è±¡å¤±è´¥ {attr_name}.reset(): {e}")
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰ clear_cache() æ–¹æ³•
                    if hasattr(attr_value, 'clear_cache') and callable(getattr(attr_value, 'clear_cache')):
                        try:
                            attr_value.clear_cache()
                            print(f"   âœ“ æ¸…ç†ä¾èµ–å¯¹è±¡ç¼“å­˜: {attr_name}.clear_cache()")
                            reset_count += 1
                        except Exception as e:
                            print(f"   âš  æ¸…ç†ä¾èµ–å¯¹è±¡ç¼“å­˜å¤±è´¥ {attr_name}.clear_cache(): {e}")
                            
                except Exception as e:
                    # å¿½ç•¥æ— æ³•è®¿é—®çš„å±žæ€§
                    continue
            
            if reset_count > 0:
                print(f"   ðŸ“Š é‡ç½®äº† {reset_count} ä¸ªä¾èµ–å¯¹è±¡")
                
        except Exception as e:
            print(f"âš  [{self.service_name}] é‡ç½®ä¾èµ–å¯¹è±¡çŠ¶æ€å¤±è´¥: {e}")
    
    def _is_singleton(self, obj: Any) -> bool:
        """æ£€æŸ¥å¯¹è±¡æ˜¯å¦æ˜¯å•ä¾‹æ¨¡å¼"""
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰ _instance ç±»å±žæ€§
            obj_class = type(obj)
            if hasattr(obj_class, '_instance'):
                return True
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ get_instance ç±»æ–¹æ³•
            if hasattr(obj_class, 'get_instance'):
                return True
            
            return False
        except:
            return False
    
    def _reset_singleton(self, singleton_obj: Any, attr_name: str) -> int:
        """é‡ç½®å•ä¾‹å¯¹è±¡"""
        reset_count = 0
        try:
            obj_class = type(singleton_obj)
            
            # å°è¯•é‡ç½® _instance
            if hasattr(obj_class, '_instance'):
                obj_class._instance = None
                print(f"   âœ“ é‡ç½®å•ä¾‹: {attr_name}._instance = None")
                reset_count += 1
            
            # å°è¯•è°ƒç”¨ reset() æ–¹æ³•
            if hasattr(singleton_obj, 'reset') and callable(getattr(singleton_obj, 'reset')):
                try:
                    singleton_obj.reset()
                    print(f"   âœ“ è°ƒç”¨å•ä¾‹é‡ç½®æ–¹æ³•: {attr_name}.reset()")
                    reset_count += 1
                except Exception as e:
                    print(f"   âš  è°ƒç”¨å•ä¾‹é‡ç½®æ–¹æ³•å¤±è´¥ {attr_name}.reset(): {e}")
            
        except Exception as e:
            print(f"   âš  é‡ç½®å•ä¾‹å¤±è´¥ {attr_name}: {e}")
        
        return reset_count
    
    def _save_error_log(self, error_log: Dict, is_critical: bool = False):
        """ä¿å­˜é”™è¯¯æ—¥å¿—åˆ°æ–‡ä»¶"""
        try:
            import json
            log_file = os.path.join(
                self._error_log_dir,
                f"{self.service_name}_{'CRITICAL' if is_critical else 'ERROR'}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            )
            with open(log_file, 'w', encoding='utf-8') as f:
                json.dump(error_log, f, ensure_ascii=False, indent=2)
            
            # åªä¿ç•™æœ€è¿‘ 50 ä¸ªé”™è¯¯æ—¥å¿—
            self._cleanup_error_logs()
        except Exception as e:
            print(f"âš  [{self.service_name}] ä¿å­˜é”™è¯¯æ—¥å¿—å¤±è´¥: {e}")
    
    def _cleanup_error_logs(self):
        """æ¸…ç†æ—§çš„é”™è¯¯æ—¥å¿—"""
        try:
            import glob
            log_files = glob.glob(os.path.join(self._error_log_dir, f"{self.service_name}_*.json"))
            log_files.sort(key=os.path.getmtime, reverse=True)
            
            # åªä¿ç•™æœ€è¿‘ 50 ä¸ª
            if len(log_files) > 50:
                for old_log in log_files[50:]:
                    try:
                        os.remove(old_log)
                    except:
                        pass
        except Exception as e:
            print(f"âš  [{self.service_name}] æ¸…ç†é”™è¯¯æ—¥å¿—å¤±è´¥: {e}")
    
    def _send_alert(self, error_log: Dict, is_critical: bool = False):
        """å‘é€å‘Šè­¦ï¼ˆå¯æ‰©å±•ï¼šé‚®ä»¶ã€é’‰é’‰ã€ä¼ä¸šå¾®ä¿¡ç­‰ï¼‰"""
        try:
            # æ£€æŸ¥æ˜¯å¦é…ç½®äº†å‘Šè­¦
            alert_enabled = os.getenv("HOT_RELOAD_ALERT_ENABLED", "false").lower() == "true"
            if not alert_enabled:
                return
            
            # è¿™é‡Œå¯ä»¥æ‰©å±•ä¸ºå‘é€é‚®ä»¶ã€é’‰é’‰ã€ä¼ä¸šå¾®ä¿¡ç­‰
            # ç›®å‰åªæ‰“å°å‘Šè­¦ä¿¡æ¯
            alert_level = "ðŸš¨ CRITICAL" if is_critical else "âš ï¸ WARNING"
            print(f"{alert_level} [{self.service_name}] çƒ­æ›´æ–°å‘Šè­¦:")
            print(f"   é”™è¯¯: {error_log.get('error', 'Unknown')}")
            print(f"   æ—¶é—´: {error_log.get('timestamp', 'Unknown')}")
            
            # TODO: å®žçŽ°å®žé™…çš„å‘Šè­¦å‘é€é€»è¾‘
            # if alert_webhook:
            #     send_webhook_alert(alert_webhook, error_log)
            
        except Exception as e:
            print(f"âš  [{self.service_name}] å‘é€å‘Šè­¦å¤±è´¥: {e}")
    
    def _validate_servicer(self, servicer: Any) -> bool:
        """éªŒè¯ Servicer å®žä¾‹æ˜¯å¦å¯ç”¨"""
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰å¿…éœ€çš„å±žæ€§æˆ–æ–¹æ³•
            if not hasattr(servicer, '__class__'):
                return False
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ HealthCheck æ–¹æ³•ï¼ˆå¤§å¤šæ•° gRPC Servicer éƒ½æœ‰ï¼‰
            if hasattr(servicer, 'HealthCheck'):
                # å°è¯•è°ƒç”¨ï¼ˆä¸ä¼ å‚æ•°ï¼Œåªæ£€æŸ¥æ˜¯å¦å¯è°ƒç”¨ï¼‰
                if not callable(getattr(servicer, 'HealthCheck')):
                    return False
            
            return True
        except Exception as e:
            print(f"âš  [{self.service_name}] Servicer éªŒè¯å¤±è´¥: {e}")
            return False
    
    def _record_version(self, servicer_class: Type, backup_info: Dict = None):
        """è®°å½•æ–°ç‰ˆæœ¬"""
        record = {
            'version': self._current_version,
            'timestamp': datetime.now().isoformat(),
            'servicer_class': servicer_class.__name__,
            'module_path': self.module_path,
            'backup_info': backup_info
        }
        print(f"ðŸ“ [{self.service_name}] ç‰ˆæœ¬è®°å½•: v{self._current_version} @ {record['timestamp']}")
    
    def _rollback(self) -> bool:
        """å›žæ»šåˆ°ä¸Šä¸€ç‰ˆæœ¬"""
        if not self._version_history:
            print(f"âš  [{self.service_name}] æ²¡æœ‰å¯å›žæ»šçš„ç‰ˆæœ¬ï¼Œå°è¯•ä½¿ç”¨ Git å›žæ»š...")
            return self._rollback_via_git()
        
        try:
            last_version = self._version_history[-1]  # ä¸åˆ é™¤ï¼Œä¿ç•™åœ¨åŽ†å²ä¸­
            print(f"ðŸ”„ [{self.service_name}] æ­£åœ¨å›žæ»šåˆ°ç‰ˆæœ¬ {last_version['version']}...")
            
            # æ¢å¤å¤‡ä»½çš„æ–‡ä»¶
            backup_files = last_version.get('backup_files', [])
            if backup_files:
                restored_count = 0
                for file_info in backup_files:
                    try:
                        backup_path = file_info['backup']
                        original_path = file_info['original']
                        
                        if os.path.exists(backup_path):
                            import shutil
                            shutil.copy2(backup_path, original_path)
                            restored_count += 1
                            print(f"   âœ“ æ¢å¤: {file_info['rel_path']}")
                        else:
                            print(f"   âš  å¤‡ä»½æ–‡ä»¶ä¸å­˜åœ¨: {backup_path}")
                    except Exception as e:
                        print(f"   âŒ æ¢å¤æ–‡ä»¶å¤±è´¥ {file_info['rel_path']}: {e}")
                
                print(f"   ðŸ“Š æ¢å¤äº† {restored_count}/{len(backup_files)} ä¸ªæ–‡ä»¶")
            
            # é‡æ–°åŠ è½½æ¨¡å—
            if self.module_path in sys.modules:
                module = sys.modules[self.module_path]
                module = importlib.reload(module)
            else:
                module = importlib.import_module(self.module_path)
            
            # èŽ·å– Servicer ç±»å¹¶åˆ›å»ºå®žä¾‹
            servicer_class = getattr(module, self.servicer_class_name)
            new_servicer = servicer_class()
            
            # æ›¿æ¢ Servicer
            with self._servicer_lock:
                self._current_servicer = new_servicer
                # ä¸å‡å°‘ç‰ˆæœ¬å·ï¼Œå› ä¸ºè¿™æ˜¯å›žæ»šæ“ä½œ
            
            # æ›´æ–°æ–‡ä»¶çŠ¶æ€
            self._scan_files()
            
            print(f"âœ… [{self.service_name}] å›žæ»šå®Œæˆ")
            return True
            
        except Exception as e:
            import traceback
            print(f"âŒ [{self.service_name}] å›žæ»šå¤±è´¥: {e}")
            print(traceback.format_exc())
            
            # å¦‚æžœæ–‡ä»¶å›žæ»šå¤±è´¥ï¼Œå°è¯• Git å›žæ»š
            print(f"ðŸ”„ [{self.service_name}] å°è¯•ä½¿ç”¨ Git å›žæ»š...")
            return self._rollback_via_git()
    
    def _rollback_via_git(self) -> bool:
        """ä½¿ç”¨ Git å›žæ»šä»£ç """
        try:
            import subprocess
            
            # æ£€æŸ¥æ˜¯å¦åœ¨ Git ä»“åº“ä¸­
            result = subprocess.run(
                ['git', 'rev-parse', '--git-dir'],
                cwd=project_root,
                capture_output=True,
                text=True
            )
            
            if result.returncode != 0:
                print(f"âš  [{self.service_name}] ä¸åœ¨ Git ä»“åº“ä¸­ï¼Œæ— æ³•ä½¿ç”¨ Git å›žæ»š")
                return False
            
            # èŽ·å–ä¸»æ¨¡å—æ–‡ä»¶è·¯å¾„
            module_file = self.module_path.replace('.', os.sep) + '.py'
            module_file_path = os.path.join(project_root, module_file)
            
            if not os.path.exists(module_file_path):
                print(f"âš  [{self.service_name}] æ¨¡å—æ–‡ä»¶ä¸å­˜åœ¨: {module_file_path}")
                return False
            
            # ä½¿ç”¨ Git checkout æ¢å¤æ–‡ä»¶
            print(f"ðŸ”„ [{self.service_name}] ä½¿ç”¨ Git æ¢å¤æ–‡ä»¶: {module_file}")
            result = subprocess.run(
                ['git', 'checkout', 'HEAD', '--', module_file],
                cwd=project_root,
                capture_output=True,
                text=True
            )
            
            if result.returncode == 0:
                # é‡æ–°åŠ è½½æ¨¡å—
                if self.module_path in sys.modules:
                    module = sys.modules[self.module_path]
                    module = importlib.reload(module)
                else:
                    module = importlib.import_module(self.module_path)
                
                servicer_class = getattr(module, self.servicer_class_name)
                new_servicer = servicer_class()
                
                with self._servicer_lock:
                    self._current_servicer = new_servicer
                
                self._scan_files()
                
                print(f"âœ… [{self.service_name}] Git å›žæ»šå®Œæˆ")
                return True
            else:
                print(f"âŒ [{self.service_name}] Git å›žæ»šå¤±è´¥: {result.stderr}")
                return False
                
        except Exception as e:
            print(f"âŒ [{self.service_name}] Git å›žæ»šå¼‚å¸¸: {e}")
            return False
    
    def get_current_servicer(self) -> Optional[Any]:
        """èŽ·å–å½“å‰ Servicer å®žä¾‹ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
        with self._servicer_lock:
            return self._current_servicer
    
    def set_servicer(self, servicer: Any):
        """è®¾ç½® Servicer å®žä¾‹"""
        with self._servicer_lock:
            self._current_servicer = servicer
    
    def get_status(self) -> Dict:
        """èŽ·å–çƒ­æ›´æ–°çŠ¶æ€"""
        return {
            'service_name': self.service_name,
            'running': self._running,
            'current_version': self._current_version,
            'check_interval': self.check_interval,
            'watched_files': len(self._file_states),
            'version_history_count': len(self._version_history),
            'watch_directories': self.watch_directories,
        }
    
    def force_reload(self) -> bool:
        """å¼ºåˆ¶é‡æ–°åŠ è½½"""
        print(f"ðŸ”„ [{self.service_name}] å¼ºåˆ¶é‡æ–°åŠ è½½...")
        return self._reload_servicer()


class DynamicServicer:
    """
    åŠ¨æ€ Servicer åŒ…è£…å™¨
    
    ç”¨äºŽåŒ…è£…å®žé™…çš„ Servicerï¼Œæ”¯æŒçƒ­æ›¿æ¢
    æ‰€æœ‰ gRPC è°ƒç”¨éƒ½ä¼šè½¬å‘åˆ°å½“å‰çš„ Servicer å®žä¾‹
    """
    
    def __init__(self, reloader: MicroserviceReloader):
        """
        åˆå§‹åŒ–åŠ¨æ€ Servicer
        
        Args:
            reloader: å¾®æœåŠ¡çƒ­æ›´æ–°å™¨å®žä¾‹
        """
        self._reloader = reloader
        # ç¼“å­˜æ–¹æ³•å¼•ç”¨ï¼ˆå¯é€‰ä¼˜åŒ–ï¼‰
        self._method_cache: Dict[str, Any] = {}
        self._cache_lock = threading.RLock()
    
    def __getattribute__(self, name: str):
        """
        åŠ¨æ€è½¬å‘æ–¹æ³•è°ƒç”¨åˆ°å½“å‰ Servicer
        
        ä½¿ç”¨ __getattribute__ ç¡®ä¿æ‰€æœ‰å±žæ€§è®¿é—®éƒ½ç»è¿‡è¿™é‡Œ
        ä½†éœ€è¦å°å¿ƒå¤„ç†å†…éƒ¨å±žæ€§ï¼Œé¿å…æ— é™é€’å½’
        """
        # å¤„ç†å†…éƒ¨å±žæ€§ï¼ˆé¿å…æ— é™é€’å½’ï¼‰
        if name.startswith('_'):
            return object.__getattribute__(self, name)
        
        # èŽ·å– reloaderï¼ˆä½¿ç”¨ object.__getattribute__ é¿å…é€’å½’ï¼‰
        reloader = object.__getattribute__(self, '_reloader')
        method_cache = object.__getattribute__(self, '_method_cache')
        cache_lock = object.__getattribute__(self, '_cache_lock')
        
        # èŽ·å–å½“å‰ Servicer
        servicer = reloader.get_current_servicer()
        if servicer is None:
            raise RuntimeError(f"Servicer æœªåˆå§‹åŒ–")
        
        # å°è¯•ä»Žç¼“å­˜èŽ·å–
        with cache_lock:
            if name in method_cache:
                cached_method = method_cache[name]
                # éªŒè¯ç¼“å­˜çš„æ–¹æ³•æ˜¯å¦ä»ç„¶æœ‰æ•ˆï¼ˆæ£€æŸ¥ Servicer æ˜¯å¦æ”¹å˜ï¼‰
                if hasattr(cached_method, '__self__') and cached_method.__self__ is servicer:
                    return cached_method
        
        # ä»Ž Servicer èŽ·å–å±žæ€§/æ–¹æ³•
        try:
            attr = getattr(servicer, name)
            
            # å¦‚æžœæ˜¯å¯è°ƒç”¨å¯¹è±¡ï¼ˆæ–¹æ³•ï¼‰ï¼Œç¼“å­˜å®ƒ
            if callable(attr):
                # ä½¿ç”¨ types.MethodType åˆ›å»ºç»‘å®šæ–¹æ³•ï¼Œç¡®ä¿æ¯æ¬¡è°ƒç”¨éƒ½ä½¿ç”¨æœ€æ–°çš„ Servicer
                import types
                if isinstance(attr, types.MethodType):
                    # é‡æ–°ç»‘å®šåˆ°å½“å‰ Servicer
                    bound_method = types.MethodType(attr.__func__, servicer)
                    with cache_lock:
                        method_cache[name] = bound_method
                    return bound_method
                else:
                    # å…¶ä»–å¯è°ƒç”¨å¯¹è±¡ï¼ˆå¦‚å‡½æ•°ï¼‰
                    with cache_lock:
                        method_cache[name] = attr
                    return attr
            else:
                # éžå¯è°ƒç”¨å±žæ€§
                return attr
                
        except AttributeError:
            # å¦‚æžœ Servicer æ²¡æœ‰è¯¥å±žæ€§ï¼ŒæŠ›å‡º AttributeError
            raise AttributeError(f"'{type(servicer).__name__}' object has no attribute '{name}'")
    
    def __getattr__(self, name: str):
        """
        å¤‡ç”¨æ–¹æ³•ï¼ˆå½“ __getattribute__ æ²¡æœ‰æ‰¾åˆ°æ—¶è°ƒç”¨ï¼‰
        
        è¿™é€šå¸¸ä¸åº”è¯¥è¢«è°ƒç”¨ï¼Œå› ä¸º __getattribute__ åº”è¯¥å¤„ç†æ‰€æœ‰æƒ…å†µ
        ä½†ä¿ç•™å®ƒä½œä¸ºå®‰å…¨ç½‘
        """
        reloader = object.__getattribute__(self, '_reloader')
        servicer = reloader.get_current_servicer()
        if servicer is None:
            raise RuntimeError(f"Servicer æœªåˆå§‹åŒ–")
        return getattr(servicer, name)
    
    def clear_cache(self):
        """æ¸…é™¤æ–¹æ³•ç¼“å­˜ï¼ˆåœ¨çƒ­æ›´æ–°åŽè°ƒç”¨ï¼‰"""
        with self._cache_lock:
            self._method_cache.clear()


def create_hot_reload_server(
    service_name: str,
    module_path: str,
    servicer_class_name: str,
    add_servicer_to_server_func: Callable,
    port: int,
    server_options: List = None,
    max_workers: int = 20,
    check_interval: int = 30,
    listen_addr: str = None
):
    """
    åˆ›å»ºæ”¯æŒçƒ­æ›´æ–°çš„ gRPC æœåŠ¡å™¨
    
    Args:
        service_name: æœåŠ¡åç§°
        module_path: æ¨¡å—è·¯å¾„
        servicer_class_name: Servicer ç±»å
        add_servicer_to_server_func: gRPC æ³¨å†Œå‡½æ•°
        port: ç«¯å£å·
        server_options: gRPC æœåŠ¡å™¨é€‰é¡¹
        max_workers: çº¿ç¨‹æ± å¤§å°
        check_interval: çƒ­æ›´æ–°æ£€æŸ¥é—´éš”
        listen_addr: ç›‘å¬åœ°å€ï¼ˆé»˜è®¤: [::]:portï¼Œå¯è‡ªå®šä¹‰å¦‚ localhost:portï¼‰
    
    Returns:
        tuple: (server, reloader)
    """
    import grpc
    from concurrent import futures
    
    # é»˜è®¤æœåŠ¡å™¨é€‰é¡¹
    if server_options is None:
        server_options = [
            ('grpc.keepalive_time_ms', 300000),
            ('grpc.keepalive_timeout_ms', 20000),
            ('grpc.keepalive_permit_without_calls', False),
            ('grpc.http2.max_pings_without_data', 2),
            ('grpc.http2.min_time_between_pings_ms', 60000),
            ('grpc.http2.min_ping_interval_without_data_ms', 300000),
        ]
    
    # åˆ›å»ºçƒ­æ›´æ–°å™¨
    reloader = MicroserviceReloader(
        service_name=service_name,
        module_path=module_path,
        servicer_class_name=servicer_class_name,
        check_interval=check_interval
    )
    
    # åŠ è½½åˆå§‹ Servicer
    module = importlib.import_module(module_path)
    servicer_class = getattr(module, servicer_class_name)
    initial_servicer = servicer_class()
    reloader.set_servicer(initial_servicer)
    
    # åˆ›å»ºåŠ¨æ€ Servicer
    dynamic_servicer = DynamicServicer(reloader)
    
    # åˆ›å»º gRPC æœåŠ¡å™¨
    server = grpc.server(
        futures.ThreadPoolExecutor(max_workers=max_workers),
        options=server_options
    )
    
    # æ³¨å†ŒåŠ¨æ€ Servicer
    add_servicer_to_server_func(dynamic_servicer, server)
    
    # ç»‘å®šç«¯å£ï¼ˆå¦‚æžœæ²¡æœ‰æŒ‡å®šåœ°å€ï¼Œä½¿ç”¨é»˜è®¤çš„ [::]:portï¼‰
    if listen_addr is None:
        listen_addr = f"[::]:{port}"
    server.add_insecure_port(listen_addr)
    
    return server, reloader


# å…¨å±€å¾®æœåŠ¡çƒ­æ›´æ–°å™¨æ³¨å†Œè¡¨
_microservice_reloaders: Dict[str, MicroserviceReloader] = {}

# ä¾èµ–å…³ç³»æ˜ å°„ï¼ˆå…±äº«æ¨¡å— -> ä¾èµ–å®ƒçš„å¾®æœåŠ¡åˆ—è¡¨ï¼‰
DEPENDENCY_MAP: Dict[str, List[str]] = {
    'src': ['bazi_core', 'bazi_fortune', 'bazi_analyzer', 'bazi_rule', 'fortune_analysis', 'fortune_rule'],
    'server': ['bazi_core', 'bazi_fortune', 'bazi_analyzer', 'bazi_rule', 'fortune_analysis', 'fortune_rule', 'intent_service'],
    'services.fortune_analysis': ['fortune_analysis'],
    'services.fortune_rule': ['fortune_rule'],
    'services.intent_service': ['intent_service'],
    'services.prompt_optimizer': ['prompt_optimizer'],
    'services.desk_fengshui': ['desk_fengshui'],
    'services.payment_service': ['payment_service'],
}


def register_microservice_reloader(service_name: str, reloader: MicroserviceReloader):
    """æ³¨å†Œå¾®æœåŠ¡çƒ­æ›´æ–°å™¨"""
    _microservice_reloaders[service_name] = reloader


def get_microservice_reloader(service_name: str) -> Optional[MicroserviceReloader]:
    """èŽ·å–å¾®æœåŠ¡çƒ­æ›´æ–°å™¨"""
    return _microservice_reloaders.get(service_name)


def get_all_microservice_reloaders() -> Dict[str, MicroserviceReloader]:
    """èŽ·å–æ‰€æœ‰å¾®æœåŠ¡çƒ­æ›´æ–°å™¨"""
    return _microservice_reloaders.copy()


def reload_all_microservices() -> Dict[str, bool]:
    """é‡æ–°åŠ è½½æ‰€æœ‰å¾®æœåŠ¡"""
    results = {}
    for service_name, reloader in _microservice_reloaders.items():
        results[service_name] = reloader.force_reload()
    return results


def get_all_microservice_status() -> Dict[str, Dict]:
    """èŽ·å–æ‰€æœ‰å¾®æœåŠ¡çƒ­æ›´æ–°çŠ¶æ€"""
    return {
        service_name: reloader.get_status()
        for service_name, reloader in _microservice_reloaders.items()
    }


def get_dependent_services(changed_file: str) -> List[str]:
    """
    èŽ·å–ä¾èµ–æŒ‡å®šæ–‡ä»¶çš„å¾®æœåŠ¡åˆ—è¡¨
    
    Args:
        changed_file: å˜åŒ–çš„æ–‡ä»¶è·¯å¾„ï¼ˆç›¸å¯¹äºŽé¡¹ç›®æ ¹ç›®å½•ï¼‰
    
    Returns:
        ä¾èµ–è¯¥æ–‡ä»¶çš„å¾®æœåŠ¡åç§°åˆ—è¡¨
    """
    dependent_services = set()
    
    # æ£€æŸ¥æ–‡ä»¶è·¯å¾„ï¼Œç¡®å®šä¾èµ–å…³ç³»
    for module_pattern, services in DEPENDENCY_MAP.items():
        if module_pattern in changed_file or changed_file.startswith(module_pattern):
            dependent_services.update(services)
    
    # å¦‚æžœæ–‡ä»¶åœ¨ src/ ç›®å½•ä¸‹ï¼Œæ‰€æœ‰å¾®æœåŠ¡éƒ½å¯èƒ½ä¾èµ–
    if changed_file.startswith('src/'):
        dependent_services.update(['bazi_core', 'bazi_fortune', 'bazi_analyzer', 'bazi_rule', 
                                   'fortune_analysis', 'fortune_rule', 'intent_service'])
    
    return list(dependent_services)


def trigger_dependent_services(changed_file: str) -> bool:
    """
    è§¦å‘ä¾èµ–æŒ‡å®šæ–‡ä»¶çš„å¾®æœåŠ¡çƒ­æ›´æ–°
    
    Args:
        changed_file: å˜åŒ–çš„æ–‡ä»¶è·¯å¾„
    
    Returns:
        æ˜¯å¦æˆåŠŸè§¦å‘
    """
    dependent_services = get_dependent_services(changed_file)
    
    if not dependent_services:
        return False
    
    print(f"ðŸ”„ æ£€æµ‹åˆ°å…±äº«æ–‡ä»¶å˜åŒ–: {changed_file}")
    print(f"   â†’ è§¦å‘ä¾èµ–æœåŠ¡çƒ­æ›´æ–°: {', '.join(dependent_services)}")
    
    success_count = 0
    for service_name in dependent_services:
        if service_name in _microservice_reloaders:
            reloader = _microservice_reloaders[service_name]
            try:
                # å¼ºåˆ¶æ£€æŸ¥å¹¶é‡æ–°åŠ è½½
                if reloader._check_and_reload():
                    success_count += 1
                    print(f"   âœ“ {service_name} çƒ­æ›´æ–°æˆåŠŸ")
                else:
                    print(f"   âš  {service_name} æ— éœ€æ›´æ–°")
            except Exception as e:
                print(f"   âŒ {service_name} çƒ­æ›´æ–°å¤±è´¥: {e}")
        else:
            print(f"   âš  {service_name} æœªæ³¨å†Œ")
    
    print(f"ðŸ“Š ä¾èµ–æœåŠ¡çƒ­æ›´æ–°å®Œæˆ: {success_count}/{len(dependent_services)} æˆåŠŸ")
    return success_count > 0

