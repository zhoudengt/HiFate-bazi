#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
çƒ­æ›´æ–°é‡è½½å™¨ - å„ç§æ¨¡å—çš„é‡è½½å™¨

æ”¯æŒçš„æ¨¡å—ç±»åž‹ï¼š
- rules: è§„åˆ™é…ç½®
- content: è§„åˆ™å†…å®¹
- config: ç³»ç»Ÿé…ç½®
- cache: ç¼“å­˜æ•°æ®
- source: Pythonæºä»£ç 
- microservice: gRPCå¾®æœåŠ¡ä»£ç 
- singleton: å•ä¾‹å®žä¾‹é‡ç½®
"""

import sys
import os
import logging
from typing import Dict, Any, Optional, List

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
# ä»Ž server/hot_reload/reloaders.py åˆ°é¡¹ç›®æ ¹ç›®å½•ï¼šä¸Šç§»3çº§
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.insert(0, project_root)

logger = logging.getLogger(__name__)

# ============================================================
# å…¨å±€é‡è½½ä¿æŠ¤æ ‡å¿—
# åœ¨ reload_all_modules() æ‰§è¡ŒæœŸé—´ä¸º True
# æ”¯ä»˜ç­‰å…³é”®ç«¯ç‚¹æ£€æŸ¥æ­¤æ ‡å¿—ï¼Œåœ¨é‡è½½çª—å£æœŸè¿”å›ž 503 è€ŒéžæŠ¥é”™
# ============================================================
_reload_in_progress = False

# é‡è½½äº‹ä»¶åŽ†å²è®°å½•ï¼ˆå†…å­˜ä¸­ä¿å­˜æœ€è¿‘ 20 æ¡ï¼‰
_reload_history: list = []
_RELOAD_HISTORY_MAX = 20


def is_reload_in_progress() -> bool:
    """æ£€æŸ¥å½“å‰æ˜¯å¦æ­£åœ¨æ‰§è¡Œçƒ­æ›´æ–°é‡è½½"""
    return _reload_in_progress


def get_reload_history() -> list:
    """èŽ·å–é‡è½½äº‹ä»¶åŽ†å²ï¼ˆæœ€æ–°åœ¨å‰ï¼‰"""
    return list(reversed(_reload_history))


class RuleReloader:
    """è§„åˆ™é‡è½½å™¨"""
    
    @staticmethod
    def reload() -> bool:
        """
        é‡æ–°åŠ è½½è§„åˆ™
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        try:
            from server.services.rule_service import RuleService
            RuleService.reload_rules()
            logger.info("âœ“ è§„åˆ™å·²é‡æ–°åŠ è½½")
            return True
        except Exception as e:
            logger.warning(f"âš  è§„åˆ™é‡è½½å¤±è´¥: {e}")
            return False


class ContentReloader:
    """å†…å®¹é‡è½½å™¨"""
    
    @staticmethod
    def reload() -> bool:
        """
        é‡æ–°åŠ è½½å†…å®¹ï¼ˆæ¸…ç©ºç¼“å­˜ï¼‰
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        try:
            from server.engines.query_adapters import QueryAdapterRegistry
            # æ¸…ç©ºå†…å®¹ç¼“å­˜
            QueryAdapterRegistry._content_cache.clear()
            logger.info("âœ“ å†…å®¹ç¼“å­˜å·²æ¸…ç©º")
            return True
        except Exception as e:
            logger.warning(f"âš  å†…å®¹é‡è½½å¤±è´¥: {e}")
            return False


class ConfigReloader:
    """é…ç½®é‡è½½å™¨"""
    
    @staticmethod
    def reload() -> bool:
        """
        é‡æ–°åŠ è½½é…ç½®
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        try:
            # è¿™é‡Œå¯ä»¥æ·»åŠ å…¶ä»–é…ç½®çš„é‡è½½é€»è¾‘
            # ä¾‹å¦‚ï¼šRedisé…ç½®ã€MySQLé…ç½®ç­‰
            logger.info("âœ“ é…ç½®å·²é‡æ–°åŠ è½½")
            return True
        except Exception as e:
            logger.warning(f"âš  é…ç½®é‡è½½å¤±è´¥: {e}")
            return False


class CacheReloader:
    """ç¼“å­˜é‡è½½å™¨"""
    
    @staticmethod
    def reload() -> bool:
        """
        æ¸…ç©ºç¼“å­˜ï¼ˆåŒ…æ‹¬ Redis ç¼“å­˜å’ŒæœåŠ¡ç±»ç¼“å­˜ï¼‰
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        success = True
        
        # 1. æ¸…ç† Redis ç¼“å­˜ï¼ˆL1å†…å­˜ + L2 Redisï¼‰
        try:
            from server.utils.cache_multi_level import get_multi_cache
            cache = get_multi_cache()
            # æ¸…ç† L1 å†…å­˜ç¼“å­˜
            cache.clear()
            
            # æ¸…ç† L2 Redis ç¼“å­˜ä¸­çš„ç‰¹å®šæ¨¡å¼ï¼ˆbazi_detail å’Œ special_liuniansï¼‰
            try:
                from shared.config.redis import get_redis_client
                redis_client = get_redis_client()
                if redis_client:
                    # æ¸…ç† bazi_detail:* æ¨¡å¼çš„é”®
                    cursor = 0
                    deleted_count = 0
                    while True:
                        cursor, keys = redis_client.scan(cursor, match='bazi_detail:*', count=100)
                        if keys:
                            redis_client.delete(*keys)
                            deleted_count += len(keys)
                        if cursor == 0:
                            break
                    if deleted_count > 0:
                        logger.info(f"   âœ“ æ¸…ç†äº† {deleted_count} ä¸ª bazi_detail ç¼“å­˜é”®")
                    
                    # æ¸…ç† special_liunians:* æ¨¡å¼çš„é”®
                    cursor = 0
                    deleted_count = 0
                    while True:
                        cursor, keys = redis_client.scan(cursor, match='special_liunians:*', count=100)
                        if keys:
                            redis_client.delete(*keys)
                            deleted_count += len(keys)
                        if cursor == 0:
                            break
                    if deleted_count > 0:
                        logger.info(f"   âœ“ æ¸…ç†äº† {deleted_count} ä¸ª special_liunians ç¼“å­˜é”®")
            except Exception as e:
                logger.warning(f"   âš  Redis ç‰¹å®šç¼“å­˜æ¸…ç†å¤±è´¥: {e}")
                # ä¸è®¾ç½® success = Falseï¼Œå› ä¸ºè¿™æ˜¯å¯é€‰çš„
            
            logger.info("   âœ“ ç¼“å­˜å·²æ¸…ç©ºï¼ˆL1å†…å­˜ + L2 Redisï¼‰")
        except Exception as e:
            logger.warning(f"   âš  ç¼“å­˜æ¸…ç†å¤±è´¥: {e}")
            success = False
        
        # 2. æ¸…ç† IndustryService ç¼“å­˜
        try:
            from server.services.industry_service import IndustryService
            IndustryService.clear_cache()
            logger.info("   âœ“ IndustryService ç¼“å­˜å·²æ¸…ç†")
        except Exception as e:
            logger.warning(f"   âš  IndustryService ç¼“å­˜æ¸…ç†å¤±è´¥: {e}")
            # ä¸è®¾ç½® success = Falseï¼Œå› ä¸ºè¿™æ˜¯å¯é€‰çš„
        
        # 3. æ¸…ç† ConfigService ç¼“å­˜ï¼ˆå¦‚æžœå­˜åœ¨ï¼‰
        try:
            from server.services.config_service import ConfigService
            # ConfigService ä½¿ç”¨ç±»çº§åˆ«ç¼“å­˜ï¼Œç›´æŽ¥è®¾ç½®ä¸º None
            ConfigService._element_cache = None
            ConfigService._mingge_cache = None
            logger.info("   âœ“ ConfigService ç¼“å­˜å·²æ¸…ç†")
        except Exception as e:
            logger.warning(f"   âš  ConfigService ç¼“å­˜æ¸…ç†å¤±è´¥: {e}")
            # ä¸è®¾ç½® success = Falseï¼Œå› ä¸ºè¿™æ˜¯å¯é€‰çš„
        
        # 4. æ¸…ç†æ”¯ä»˜å®¢æˆ·ç«¯å®žä¾‹ç¼“å­˜ï¼ˆä½¿é…ç½®ä¿®æ”¹ç”Ÿæ•ˆï¼‰
        try:
            from services.payment_service.client_factory import payment_client_factory
            payment_client_factory.clear_cache()
            logger.info("   âœ“ æ”¯ä»˜å®¢æˆ·ç«¯å®žä¾‹ç¼“å­˜å·²æ¸…ç†")
        except (ImportError, AttributeError) as e:
            logger.debug(f"   âš  æ”¯ä»˜å®¢æˆ·ç«¯æ¨¡å—æœªåŠ è½½ï¼ˆå¯å¿½ç•¥ï¼‰: {e}")
        except Exception as e:
            logger.warning(f"   âš  æ”¯ä»˜å®¢æˆ·ç«¯ç¼“å­˜æ¸…ç†å¤±è´¥: {e}")
            # ä¸è®¾ç½® success = Falseï¼Œå› ä¸ºè¿™æ˜¯å¯é€‰çš„
        
        if success:
            logger.info("âœ“ ç¼“å­˜é‡è½½å®Œæˆ")
        else:
            logger.warning("âš  ç¼“å­˜é‡è½½éƒ¨åˆ†å¤±è´¥")
        
        return success


class SourceCodeReloader:
    """æºä»£ç é‡è½½å™¨ - æ”¯æŒPythonæºä»£ç çƒ­æ›´æ–°"""
    
    _SEARCH_DIRECTORIES = ("core", "src", "server", "services")  # åŒ…å« core å’Œ services ç›®å½•
    _EXCLUDE_DIRS = {"__pycache__", ".mypy_cache", ".pytest_cache"}
    
    @classmethod
    def _discover_source_modules(cls) -> Dict[str, Dict[str, str]]:
        """
        åŠ¨æ€æ‰«æé¡¹ç›®ä¸­çš„ Python æ–‡ä»¶ï¼Œç”Ÿæˆç›‘æŽ§åˆ—è¡¨
        Returns:
            Dict[str, Dict[str, str]]: æ¨¡å—åç§° -> æ–‡ä»¶ä¿¡æ¯
        """
        modules: Dict[str, Dict[str, str]] = {}
        for directory in cls._SEARCH_DIRECTORIES:
            base_dir = os.path.join(project_root, directory)
            if not os.path.exists(base_dir):
                continue
            for root, dirs, files in os.walk(base_dir):
                dirs[:] = [d for d in dirs if d not in cls._EXCLUDE_DIRS]
                for filename in files:
                    if not filename.endswith(".py"):
                        continue
                    full_path = os.path.join(root, filename)
                    rel_path = os.path.relpath(full_path, project_root)
                    module_name = rel_path[:-3].replace(os.sep, ".")
                    modules[module_name] = {
                        "file": rel_path,
                        "description": f"è‡ªåŠ¨ç›‘æŽ§æºæ–‡ä»¶: {rel_path}"
                    }
        return modules
    
    MONITORED_MODULES: Dict[str, Dict[str, str]] = {}
    
    @staticmethod
    def reload() -> bool:
        """
        é‡æ–°åŠ è½½æºä»£ç æ¨¡å—
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        import importlib
        from datetime import datetime
        
        monitored_modules = SourceCodeReloader._discover_source_modules()
        SourceCodeReloader.MONITORED_MODULES = monitored_modules
        
        reloaded_modules = []
        failed_modules = []
        
        logger.info("\n" + "="*60)
        logger.info(f"ðŸ”„ æºä»£ç çƒ­æ›´æ–°å¼€å§‹ - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        logger.info("="*60)
        
        try:
            for module_name, module_info in monitored_modules.items():
                file_path = module_info['file']
                description = module_info['description']
                
                try:
                    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                    full_path = os.path.join(project_root, file_path)
                    if not os.path.exists(full_path):
                        logger.warning(f"  âš  æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                        continue
                    
                    # èŽ·å–æ–‡ä»¶ä¿®æ”¹æ—¶é—´
                    mtime = os.path.getmtime(full_path)
                    mtime_str = datetime.fromtimestamp(mtime).strftime('%Y-%m-%d %H:%M:%S')
                    
                    # ä»Žsys.modulesä¸­èŽ·å–æ¨¡å—ï¼Œå¦‚æžœæœªåŠ è½½åˆ™å°è¯•å¯¼å…¥
                    if module_name in sys.modules:
                        module = sys.modules[module_name]
                    else:
                        # â­ å¦‚æžœæ¨¡å—æœªåŠ è½½ï¼Œå°è¯•å¯¼å…¥ï¼ˆå»¶è¿ŸåŠ è½½çš„æ¨¡å—ï¼‰
                        try:
                            import importlib
                            module = importlib.import_module(module_name)
                            logger.info(f"     ðŸ”„ æ¨¡å—æœªåŠ è½½ï¼Œå·²å¯¼å…¥: {module_name}")
                        except ImportError as e:
                            logger.warning(f"     âš  æ¨¡å—æœªåŠ è½½ä¸”æ— æ³•å¯¼å…¥: {module_name} ({e})")
                            continue
                    
                    # æ‰“å°æ¨¡å—ä¿¡æ¯ï¼ˆæ— è®ºæ˜¯å¦å·²åŠ è½½ï¼‰
                    logger.info(f"\n  ðŸ“¦ æ¨¡å—: {module_name}")
                    logger.info(f"     ðŸ“„ æ–‡ä»¶: {file_path}")
                    logger.info(f"     ðŸ“ åŠŸèƒ½: {description}")
                    logger.info(f"     ðŸ•’ ä¿®æ”¹æ—¶é—´: {mtime_str}")
                    
                    # â­ ç‰¹æ®Šå¤„ç†ï¼šå¦‚æžœæ˜¯ grpc_gateway æ¨¡å—ï¼Œéœ€è¦å…ˆå¤„ç†ç«¯ç‚¹æ³¨å†Œ
                    if module_name == 'server.api.grpc_gateway':
                        try:
                            from server.api.grpc_gateway import SUPPORTED_ENDPOINTS
                            old_count = len(SUPPORTED_ENDPOINTS)
                            logger.info(f"     ðŸ”„ é‡æ–°æ³¨å†Œå‰ç«¯ç‚¹æ•°é‡: {old_count}")
                            
                            # ðŸ”´ å¤‡ä»½å½“å‰ç«¯ç‚¹ï¼ˆå¦‚æžœ reload å¤±è´¥å¯ä»¥æ¢å¤ï¼‰
                            endpoints_backup = dict(SUPPORTED_ENDPOINTS)
                            
                            # æ¸…ç©ºç«¯ç‚¹å­—å…¸ï¼ˆé¿å…æ®‹ç•™æ—§ç«¯ç‚¹ï¼‰
                            SUPPORTED_ENDPOINTS.clear()
                            
                            # é‡æ–°åŠ è½½æ¨¡å—ï¼ˆè§¦å‘è£…é¥°å™¨ @_register é‡æ–°æ‰§è¡Œï¼‰
                            try:
                                importlib.reload(module)
                            except Exception as reload_err:
                                # ðŸ”´ reload å¤±è´¥æ—¶æ¢å¤å¤‡ä»½ï¼Œé¿å…ç«¯ç‚¹å…¨éƒ¨ä¸¢å¤±
                                logger.error(f"     âŒ grpc_gateway reload å¤±è´¥ï¼Œæ¢å¤ {old_count} ä¸ªç«¯ç‚¹: {reload_err}")
                                SUPPORTED_ENDPOINTS.update(endpoints_backup)
                                raise
                            
                            # é‡æ–°èŽ·å–ç«¯ç‚¹å­—å…¸ï¼ˆè£…é¥°å™¨å·²æ‰§è¡Œï¼‰
                            from server.api.grpc_gateway import SUPPORTED_ENDPOINTS as NEW_ENDPOINTS
                            new_count = len(NEW_ENDPOINTS)
                            logger.info(f"     ðŸ”„ é‡æ–°åŠ è½½åŽç«¯ç‚¹æ•°é‡: {new_count}")
                            
                            # å¦‚æžœç«¯ç‚¹ä»æœªæ³¨å†Œï¼Œç›´æŽ¥è°ƒç”¨ _ensure_endpoints_registered æ‰‹åŠ¨æ³¨å†Œ
                            if new_count == 0:
                                logger.warning(f"     âš ï¸  è£…é¥°å™¨æœªæ³¨å†Œç«¯ç‚¹ï¼Œæ‰‹åŠ¨æ³¨å†Œ + æ¢å¤å¤‡ä»½...")
                                try:
                                    from server.api.grpc_gateway import _ensure_endpoints_registered
                                    _ensure_endpoints_registered()
                                    from server.api.grpc_gateway import SUPPORTED_ENDPOINTS as FINAL_ENDPOINTS
                                    final_count = len(FINAL_ENDPOINTS)
                                    if final_count == 0:
                                        # æ‰‹åŠ¨æ³¨å†Œä¹Ÿå¤±è´¥ï¼Œæ¢å¤å¤‡ä»½
                                        logger.warning(f"     âš ï¸  æ‰‹åŠ¨æ³¨å†Œä¹Ÿä¸ºç©ºï¼Œæ¢å¤å¤‡ä»½çš„ {old_count} ä¸ªç«¯ç‚¹")
                                        SUPPORTED_ENDPOINTS.update(endpoints_backup)
                                    else:
                                        logger.info(f"     âœ… æ‰‹åŠ¨æ³¨å†ŒæˆåŠŸï¼ˆç«¯ç‚¹æ•°é‡: {final_count}ï¼‰")
                                except Exception as e:
                                    logger.error(f"     âŒ æ‰‹åŠ¨æ³¨å†Œå¤±è´¥ï¼Œæ¢å¤å¤‡ä»½: {e}")
                                    SUPPORTED_ENDPOINTS.update(endpoints_backup)
                            else:
                                logger.info(f"     âœ… gRPC ç«¯ç‚¹å·²é‡æ–°æ³¨å†Œï¼ˆç«¯ç‚¹æ•°é‡: {new_count}ï¼‰")
                            
                            # éªŒè¯å…³é”®ç«¯ç‚¹æ˜¯å¦å·²æ³¨å†Œ
                            from server.api.grpc_gateway import SUPPORTED_ENDPOINTS as FINAL_CHECK
                            key_endpoints = ['/bazi/interface', '/bazi/shengong-minggong', '/bazi/rizhu-liujiazi', '/daily-fortune-calendar/query']
                            missing_endpoints = [ep for ep in key_endpoints if ep not in FINAL_CHECK]
                            if missing_endpoints:
                                logger.warning(f"     âš ï¸  å…³é”®ç«¯ç‚¹æœªæ³¨å†Œ: {missing_endpoints}ï¼Œä»Žå¤‡ä»½æ¢å¤ç¼ºå¤±ç«¯ç‚¹...")
                                # ä»…æ¢å¤ç¼ºå¤±çš„ç«¯ç‚¹ï¼Œä¸è¦†ç›–å·²æ›´æ–°çš„
                                for ep in missing_endpoints:
                                    if ep in endpoints_backup:
                                        SUPPORTED_ENDPOINTS[ep] = endpoints_backup[ep]
                                        logger.info(f"     ðŸ”„ ä»Žå¤‡ä»½æ¢å¤ç«¯ç‚¹: {ep}")
                                # å†æ¬¡å°è¯• _ensure_endpoints_registered
                                try:
                                    from server.api.grpc_gateway import _ensure_endpoints_registered
                                    _ensure_endpoints_registered()
                                except Exception:
                                    pass
                                # æœ€ç»ˆéªŒè¯
                                from server.api.grpc_gateway import SUPPORTED_ENDPOINTS as FINAL_CHECK2
                                still_missing = [ep for ep in key_endpoints if ep not in FINAL_CHECK2]
                                if still_missing:
                                    logger.error(f"     âŒ å…³é”®ç«¯ç‚¹ä»ç„¶ç¼ºå¤±: {still_missing}")
                                else:
                                    logger.info(f"     âœ… å…³é”®ç«¯ç‚¹éªŒè¯é€šè¿‡ï¼ˆç«¯ç‚¹æ•°é‡: {len(FINAL_CHECK2)}ï¼‰")
                            else:
                                logger.info(f"     âœ… å…³é”®ç«¯ç‚¹éªŒè¯é€šè¿‡")
                                
                        except Exception as e:
                            logger.error(f"     âŒ gRPC ç«¯ç‚¹é‡æ–°æ³¨å†Œå¤±è´¥: {e}")
                            import traceback
                            traceback.print_exc()
                    else:
                        # æ™®é€šæ¨¡å—ï¼šç›´æŽ¥é‡æ–°åŠ è½½
                        importlib.reload(module)
                    
                    # â­ ç‰¹æ®Šå¤„ç†ï¼šå¦‚æžœæ˜¯ server.main æ¨¡å—ï¼Œéœ€è¦é‡æ–°æ³¨å†Œè·¯ç”±
                    if module_name == 'server.main':
                        try:
                            logger.info(f"     ðŸ”„ æ£€æµ‹åˆ° server.main æ¨¡å—æ›´æ–°ï¼Œé‡æ–°æ³¨å†Œè·¯ç”±...")
                            # ç­‰å¾…æ¨¡å—é‡æ–°åŠ è½½å®Œæˆ
                            import time
                            time.sleep(0.1)  # çŸ­æš‚å»¶è¿Ÿï¼Œç¡®ä¿æ¨¡å—é‡æ–°åŠ è½½å®Œæˆ
                            
                            from server.utils.router_manager import RouterManager
                            router_manager = RouterManager.get_instance()
                            if router_manager:
                                # å°è¯•é‡æ–°æ³¨å†Œè·¯ç”±ä¿¡æ¯ï¼ˆå¦‚æžœ server.main å·²é‡æ–°åŠ è½½ï¼Œ_register_all_routers_to_manager ä¼šè¢«é‡æ–°æ‰§è¡Œï¼‰
                                # ä½†æ˜¯ä¸ºäº†ç¡®ä¿è·¯ç”±ä¿¡æ¯æ˜¯æœ€æ–°çš„ï¼Œæˆ‘ä»¬éœ€è¦ç¡®ä¿å®ƒå·²æ‰§è¡Œ
                                try:
                                    # å°è¯•è°ƒç”¨ _register_all_routers_to_managerï¼ˆå¦‚æžœå­˜åœ¨ï¼‰
                                    if 'server.main' in sys.modules:
                                        main_module = sys.modules['server.main']
                                        if hasattr(main_module, '_register_all_routers_to_manager'):
                                            main_module._register_all_routers_to_manager()
                                            logger.info(f"     âœ… è·¯ç”±ä¿¡æ¯å·²é‡æ–°æ³¨å†Œåˆ°ç®¡ç†å™¨")
                                except Exception as e2:
                                    logger.warning(f"     âš ï¸  é‡æ–°æ³¨å†Œè·¯ç”±ä¿¡æ¯åˆ°ç®¡ç†å™¨å¤±è´¥: {e2}")
                                
                                # æ¸…é™¤æ³¨å†ŒçŠ¶æ€ï¼Œå¼ºåˆ¶é‡æ–°æ³¨å†Œåˆ° FastAPI åº”ç”¨
                                router_manager.clear_registered_state()
                                # é‡æ–°æ³¨å†Œæ‰€æœ‰è·¯ç”±åˆ° FastAPI åº”ç”¨
                                results = router_manager.register_all_routers(force=True)
                                success_count = sum(1 for v in results.values() if v)
                                failed_count = sum(1 for v in results.values() if not v)
                                logger.info(f"     âœ… è·¯ç”±é‡æ–°æ³¨å†Œåˆ° FastAPI åº”ç”¨å®Œæˆ: {success_count} æˆåŠŸ, {failed_count} å¤±è´¥")
                            else:
                                logger.warning(f"     âš ï¸  è·¯ç”±ç®¡ç†å™¨æœªåˆå§‹åŒ–ï¼Œè·³è¿‡è·¯ç”±é‡æ–°æ³¨å†Œ")
                        except Exception as e:
                            logger.warning(f"     âš ï¸  è·¯ç”±é‡æ–°æ³¨å†Œå¤±è´¥ï¼ˆä¸å½±å“æ¨¡å—é‡è½½ï¼‰: {e}")
                            import traceback
                            traceback.print_exc()
                    
                    reloaded_modules.append({
                        'module': module_name,
                        'file': file_path,
                        'description': description,
                        'mtime': mtime_str
                    })
                    logger.info(f"     âœ… é‡è½½æˆåŠŸ")
                        
                except Exception as e:
                    error_msg = str(e)
                    failed_modules.append({
                        'module': module_name,
                        'file': file_path,
                        'error': error_msg
                    })
                    logger.error(f"  âŒ é‡è½½æ¨¡å— {module_name} å¤±è´¥: {error_msg}")
            
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # ðŸ”´ æœ€ç»ˆæ­¥éª¤ï¼šæ‰€æœ‰æ¨¡å—é‡è½½å®ŒæˆåŽï¼Œé‡æ–°æ³¨å†Œè·¯ç”±
            # åŽŸå› ï¼šos.walk éåŽ†æ—¶ server/main.py åœ¨ server/hot_reload/api.py ä¹‹å‰ï¼Œ
            # å¯¼è‡´ server.main é‡è½½æ—¶çœ‹åˆ°çš„æ˜¯æ—§çš„ hot_reload routerã€‚
            # è¿™é‡Œç¡®ä¿åœ¨æ‰€æœ‰æ¨¡å—éƒ½å·²æ›´æ–°åŽï¼Œç”¨æœ€æ–°çš„ router å¯¹è±¡é‡æ–°æ³¨å†Œã€‚
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            try:
                from server.utils.router_manager import RouterManager
                router_manager = RouterManager.get_instance()
                if router_manager and 'server.main' in sys.modules:
                    main_module = sys.modules['server.main']
                    
                    # 1. é‡æ–°ç»‘å®š server.main ä¸­çš„ router å˜é‡åˆ°æœ€æ–°çš„æ¨¡å—å¯¹è±¡
                    router_bindings = {
                        'server.hot_reload.api': 'hot_reload_router',
                    }
                    for src_module, var_name in router_bindings.items():
                        if src_module in sys.modules:
                            new_router = getattr(sys.modules[src_module], 'router', None)
                            if new_router and hasattr(main_module, var_name):
                                setattr(main_module, var_name, new_router)
                    
                    # 2. é‡æ–°æ³¨å†Œè·¯ç”±ä¿¡æ¯åˆ°ç®¡ç†å™¨
                    if hasattr(main_module, '_register_all_routers_to_manager'):
                        main_module._register_all_routers_to_manager()
                    
                    # 3. å¼ºåˆ¶é‡æ–°æ³¨å†Œåˆ° FastAPI åº”ç”¨
                    router_manager.clear_registered_state()
                    results = router_manager.register_all_routers(force=True)
                    success_count_r = sum(1 for v in results.values() if v)
                    logger.info(f"  ðŸ”„ æœ€ç»ˆè·¯ç”±é‡æ–°æ³¨å†Œ: {success_count_r} ä¸ªè·¯ç”±å·²æŒ‚è½½")
            except Exception as e:
                logger.warning(f"  âš ï¸  æœ€ç»ˆè·¯ç”±é‡æ–°æ³¨å†Œå¤±è´¥ï¼ˆä¸å½±å“æ¨¡å—é‡è½½ï¼‰: {e}")
            
            # æ‰“å°æ€»ç»“
            logger.info("\n" + "-"*60)
            if reloaded_modules:
                logger.info(f"âœ… æºä»£ç çƒ­æ›´æ–°å®Œæˆ - æˆåŠŸé‡è½½ {len(reloaded_modules)} ä¸ªæ¨¡å—:")
                for info in reloaded_modules:
                    logger.info(f"   â€¢ {info['module']}")
                    logger.info(f"     æ–‡ä»¶: {info['file']}")
                    logger.info(f"     åŠŸèƒ½: {info['description']}")
                    logger.info(f"     ä¿®æ”¹æ—¶é—´: {info['mtime']}")
            
            if failed_modules:
                logger.warning(f"\nâš ï¸  å¤±è´¥ {len(failed_modules)} ä¸ªæ¨¡å—:")
                for info in failed_modules:
                    logger.error(f"   â€¢ {info['module']}: {info['error']}")
            
            logger.info("="*60 + "\n")
            
            return len(reloaded_modules) > 0
            
        except Exception as e:
            logger.error(f"âŒ æºä»£ç çƒ­æ›´æ–°å¤±è´¥: {e}", exc_info=True)
            logger.error("="*60 + "\n")
            return False


# åˆå§‹åŒ–æºä»£ç ç›‘æŽ§åˆ—è¡¨
SourceCodeReloader.MONITORED_MODULES = SourceCodeReloader._discover_source_modules()


class MicroserviceReloaderProxy:
    """å¾®æœåŠ¡é‡è½½å™¨ä»£ç† - è§¦å‘æ‰€æœ‰å¾®æœåŠ¡çš„çƒ­æ›´æ–°"""
    
    @staticmethod
    def reload() -> bool:
        """
        é‡æ–°åŠ è½½æ‰€æœ‰å¾®æœåŠ¡
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        try:
            from .microservice_reloader import get_all_microservice_reloaders, reload_all_microservices
            
            reloaders = get_all_microservice_reloaders()
            if not reloaders:
                logger.warning("âš  æ²¡æœ‰æ³¨å†Œçš„å¾®æœåŠ¡çƒ­æ›´æ–°å™¨")
                return True
            
            logger.info(f"\nðŸ”„ å¼€å§‹é‡è½½ {len(reloaders)} ä¸ªå¾®æœåŠ¡...")
            results = reload_all_microservices()
            
            success_count = sum(1 for v in results.values() if v)
            failed_count = len(results) - success_count
            
            if failed_count > 0:
                logger.warning(f"âš  å¾®æœåŠ¡é‡è½½: {success_count} æˆåŠŸ, {failed_count} å¤±è´¥")
                for service_name, success in results.items():
                    if not success:
                        logger.error(f"   âŒ {service_name}")
                return False
            
            logger.info(f"âœ“ æ‰€æœ‰å¾®æœåŠ¡é‡è½½æˆåŠŸ ({success_count} ä¸ª)")
            return True
            
        except ImportError:
            logger.warning("âš  å¾®æœåŠ¡çƒ­æ›´æ–°æ¨¡å—æœªåŠ è½½")
            return True
        except Exception as e:
            logger.error(f"âš  å¾®æœåŠ¡é‡è½½å¤±è´¥: {e}", exc_info=True)
            return False


class SingletonReloader:
    """å•ä¾‹é‡ç½®å™¨ - é‡ç½®æ‰€æœ‰æ³¨å†Œçš„å•ä¾‹å®žä¾‹"""
    
    # éœ€è¦é‡ç½®çš„å•ä¾‹åˆ—è¡¨ï¼ˆå®Œæ•´æ¸…å•ï¼ŒåŒ…å«æ‰€æœ‰å·²çŸ¥å•ä¾‹ï¼‰
    SINGLETON_CLASSES = [
        ('server.services.rule_service', 'RuleService', ['_engine', '_cache', '_cached_content_version', '_cached_rule_version']),
        ('server.observability.metrics_collector', 'MetricsCollector', ['_instance']),
        ('server.observability.alert_manager', 'AlertManager', ['_instance']),
        ('server.observability.tracer', 'Tracer', ['_instance']),
        # ä»¥ä¸‹ä¸ºæ–°å¢žçš„é—æ¼å•ä¾‹
        ('server.config.config_loader', 'ConfigService', ['_instance']),
        ('server.config.env_config', 'EnvConfig', ['_instance']),
        ('server.config.input_format_loader', 'InputFormatLoader', ['_instance']),
        ('server.config.app_config', 'AppConfig', ['_instance']),
        ('server.utils.cache_version_manager', 'CacheVersionManager', ['_instance']),
        ('server.utils.secret_manager', 'SecretManager', ['_instance']),
        ('server.utils.unified_logger', 'UnifiedLogger', ['_instance']),
        ('server.core.service_registry', 'ServiceRegistry', ['_instance']),
        ('server.services.shensha_sort_service', 'ShenshaSortService', ['_instance']),
        ('server.services.user_interaction_logger', 'UserInteractionLogger', ['_instance']),
    ]
    
    @staticmethod
    def reload() -> bool:
        """
        é‡ç½®æ‰€æœ‰å•ä¾‹å®žä¾‹
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        logger.info("\nðŸ”„ å¼€å§‹é‡ç½®å•ä¾‹å®žä¾‹...")
        success_count = 0
        failed_count = 0
        
        for module_path, class_name, attrs in SingletonReloader.SINGLETON_CLASSES:
            try:
                if module_path in sys.modules:
                    module = sys.modules[module_path]
                    cls = getattr(module, class_name, None)
                    
                    if cls is not None:
                        for attr in attrs:
                            if hasattr(cls, attr):
                                setattr(cls, attr, None)
                        logger.info(f"   âœ“ é‡ç½® {class_name}")
                        success_count += 1
                    else:
                        logger.warning(f"   âš  ç±»æœªæ‰¾åˆ°: {class_name}")
                else:
                    logger.warning(f"   âš  æ¨¡å—æœªåŠ è½½: {module_path}")
                    
            except Exception as e:
                logger.error(f"   âŒ é‡ç½®å¤±è´¥ {class_name}: {e}")
                failed_count += 1
        
        if failed_count > 0:
            logger.warning(f"âš  å•ä¾‹é‡ç½®: {success_count} æˆåŠŸ, {failed_count} å¤±è´¥")
            return False
        
        logger.info(f"âœ“ å•ä¾‹é‡ç½®å®Œæˆ ({success_count} ä¸ª)")
        return True
    
    @staticmethod
    def register_singleton(module_path: str, class_name: str, attrs: List[str]):
        """
        æ³¨å†Œéœ€è¦é‡ç½®çš„å•ä¾‹
        
        Args:
            module_path: æ¨¡å—è·¯å¾„
            class_name: ç±»å
            attrs: éœ€è¦é‡ç½®çš„å±žæ€§åˆ—è¡¨
        """
        SingletonReloader.SINGLETON_CLASSES.append((module_path, class_name, attrs))


class ConfigReloaderEnhanced:
    """å¢žå¼ºçš„é…ç½®é‡è½½å™¨ - æ”¯æŒçŽ¯å¢ƒå˜é‡å’Œ Redis é…ç½®çƒ­åŠ è½½"""
    
    @staticmethod
    def reload() -> bool:
        """
        é‡æ–°åŠ è½½é…ç½®
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        try:
            logger.info("\nðŸ”„ å¼€å§‹é‡è½½é…ç½®...")
            
            # 1. é‡æ–°åŠ è½½çŽ¯å¢ƒå˜é‡
            from dotenv import load_dotenv
            load_dotenv(override=True)
            logger.info("   âœ“ çŽ¯å¢ƒå˜é‡å·²é‡æ–°åŠ è½½")
            
            # 2. é‡ç½®é…ç½®å•ä¾‹
            try:
                from server.config.app_config import AppConfig
                if hasattr(AppConfig, '_instance'):
                    AppConfig._instance = None
                    logger.info("   âœ“ AppConfig å·²é‡ç½®")
            except ImportError:
                pass
            
            # 3. é‡æ–°åŠ è½½æ•°æ®åº“è¿žæŽ¥æ± é…ç½®
            try:
                from shared.config.database import refresh_connection_pool
                refresh_connection_pool()
                logger.info("   âœ“ MySQL è¿žæŽ¥æ± å·²åˆ·æ–°")
            except (ImportError, AttributeError) as e:
                logger.debug(f"   âš  MySQL è¿žæŽ¥æ± æ¨¡å—æœªåŠ è½½ï¼ˆå¯å¿½ç•¥ï¼‰: {e}")
            except Exception as e:
                logger.warning(f"   âš  MySQL è¿žæŽ¥æ± åˆ·æ–°å¤±è´¥: {e}")
            
            # 4. é‡æ–°åŠ è½½ Redis é…ç½®
            try:
                from shared.config.redis import refresh_redis_connection
                refresh_redis_connection()
                logger.info("   âœ“ Redis è¿žæŽ¥å·²åˆ·æ–°")
            except (ImportError, AttributeError) as e:
                logger.debug(f"   âš  Redis è¿žæŽ¥æ¨¡å—æœªåŠ è½½ï¼ˆå¯å¿½ç•¥ï¼‰: {e}")
            except Exception as e:
                logger.warning(f"   âš  Redis è¿žæŽ¥åˆ·æ–°å¤±è´¥: {e}")
            
            # 5. é‡æ–°åŠ è½½æ”¯ä»˜é…ç½®ç¼“å­˜ï¼ˆä»Žæ•°æ®åº“é‡æ–°è¯»å–ï¼‰
            try:
                from services.payment_service.payment_config_loader import reload_payment_config
                reload_payment_config()  # æ¸…é™¤æ‰€æœ‰æ”¯ä»˜é…ç½®ç¼“å­˜
                logger.info("   âœ“ æ”¯ä»˜é…ç½®ç¼“å­˜å·²æ¸…é™¤")
            except (ImportError, AttributeError) as e:
                logger.debug(f"   âš  æ”¯ä»˜é…ç½®æ¨¡å—æœªåŠ è½½ï¼ˆå¯å¿½ç•¥ï¼‰: {e}")
            except Exception as e:
                logger.warning(f"   âš  æ”¯ä»˜é…ç½®ç¼“å­˜æ¸…é™¤å¤±è´¥: {e}")
            
            logger.info("âœ“ é…ç½®é‡è½½å®Œæˆ")
            return True
            
        except Exception as e:
            logger.warning(f"âš  é…ç½®é‡è½½å¤±è´¥: {e}")
            return False


# é‡è½½å™¨æ³¨å†Œè¡¨
RELOADERS = {
    'rules': RuleReloader,
    'content': ContentReloader,
    'config': ConfigReloaderEnhanced,  # ä½¿ç”¨å¢žå¼ºç‰ˆé…ç½®é‡è½½å™¨
    'cache': CacheReloader,
    'source': SourceCodeReloader,  # æºä»£ç é‡è½½å™¨
    'microservice': MicroserviceReloaderProxy,  # å¾®æœåŠ¡é‡è½½å™¨
    'singleton': SingletonReloader,  # å•ä¾‹é‡ç½®å™¨
}

# é‡è½½é¡ºåºï¼ˆæŒ‰ä¾èµ–å…³ç³»ï¼‰
# ðŸ”´ é‡è¦ï¼šsingleton å¿…é¡»åœ¨ source ä¹‹åŽï¼
# åŽŸå› ï¼šsource é‡è½½ä¼šè§¦å‘ __init__.py é‡æ–°æ³¨å†Œæ”¯ä»˜å®¢æˆ·ç«¯ç­‰ç»„ä»¶ã€‚
# å¦‚æžœ singleton å…ˆæ‰§è¡Œï¼ˆé‡ç½® _clients=Noneï¼‰ï¼Œåˆ™ source é‡è½½å‰çš„çª—å£æœŸ
# å†…ä»»ä½•æ”¯ä»˜è¯·æ±‚éƒ½ä¼šå¤±è´¥ã€‚æ­£ç¡®é¡ºåºï¼šå…ˆåŠ è½½æ–°ä»£ç  â†’ å†æ¸…ç†æ—§çŠ¶æ€ã€‚
RELOAD_ORDER = [
    'config',       # 1. å…ˆæ›´æ–°é…ç½®ï¼ˆçŽ¯å¢ƒå˜é‡ã€æ•°æ®åº“è¿žæŽ¥ç­‰ï¼‰
    'rules',        # 2. æ›´æ–°è§„åˆ™
    'content',      # 3. æ›´æ–°å†…å®¹
    'source',       # 4. æ›´æ–°æºä»£ç ï¼ˆè§¦å‘æ¨¡å—é‡æ–°å¯¼å…¥å’Œæ³¨å†Œï¼‰
    'singleton',    # 5. é‡ç½®å•ä¾‹ï¼ˆæ¸…ç†æ—§å®žä¾‹ï¼Œå¼ºåˆ¶ç”¨æ–°ä»£ç é‡å»ºï¼‰
    'microservice', # 6. æ›´æ–°å¾®æœåŠ¡
    'cache',        # 7. æœ€åŽæ¸…ç†ç¼“å­˜
]


def get_reloader(module_name: str) -> Optional[Any]:
    """èŽ·å–é‡è½½å™¨"""
    return RELOADERS.get(module_name)


def reload_all_modules() -> Dict[str, bool]:
    """æŒ‰é¡ºåºé‡è½½æ‰€æœ‰æ¨¡å—ï¼ˆå¸¦ä¿æŠ¤æ ‡å¿—ï¼‰"""
    global _reload_in_progress
    from datetime import datetime
    import time as _time
    
    logger.info("\n" + "="*60)
    logger.info(f"ðŸ”„ å…¨é‡çƒ­æ›´æ–°å¼€å§‹ - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info("="*60)
    
    # ðŸ”´ è®¾ç½®ä¿æŠ¤æ ‡å¿—ï¼šé‡è½½æœŸé—´é˜»æ­¢å…³é”®ç«¯ç‚¹å¤„ç†è¯·æ±‚
    _reload_in_progress = True
    _t_start = _time.perf_counter()
    
    results = {}
    try:
        for module_name in RELOAD_ORDER:
            reloader = RELOADERS.get(module_name)
            if reloader:
                try:
                    results[module_name] = reloader.reload()
                except Exception as e:
                    logger.error(f"âŒ {module_name} é‡è½½å¤±è´¥: {e}")
                    results[module_name] = False
    finally:
        # ðŸ”´ æ— è®ºæˆåŠŸå¤±è´¥ï¼Œå¿…é¡»æ¸…é™¤ä¿æŠ¤æ ‡å¿—
        _reload_in_progress = False
        _elapsed_ms = int((_time.perf_counter() - _t_start) * 1000)
    
    success_count = sum(1 for v in results.values() if v)
    failed_count = len(results) - success_count
    
    logger.info("\n" + "-"*60)
    if failed_count > 0:
        logger.warning(f"âš  å…¨é‡çƒ­æ›´æ–°å®Œæˆ: {success_count} æˆåŠŸ, {failed_count} å¤±è´¥ (è€—æ—¶: {_elapsed_ms}ms)")
    else:
        logger.info(f"âœ… å…¨é‡çƒ­æ›´æ–°å®Œæˆ: æ‰€æœ‰ {success_count} ä¸ªæ¨¡å—æ›´æ–°æˆåŠŸ (è€—æ—¶: {_elapsed_ms}ms)")
    logger.info("="*60 + "\n")
    
    # ðŸ”´ è®°å½•é‡è½½äº‹ä»¶åˆ°åŽ†å²
    event = {
        "timestamp": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        "worker_pid": os.getpid(),
        "elapsed_ms": _elapsed_ms,
        "success_count": success_count,
        "failed_count": failed_count,
        "results": {k: v for k, v in results.items()},
        "all_success": failed_count == 0
    }
    _reload_history.append(event)
    if len(_reload_history) > _RELOAD_HISTORY_MAX:
        _reload_history.pop(0)
    
    return results



