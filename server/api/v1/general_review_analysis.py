#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å…«å­—å‘½ç†-æ€»è¯„åˆ†æAPI
åŸºäºç”¨æˆ·ç”Ÿè¾°æ•°æ®ï¼Œä½¿ç”¨ Coze Bot æµå¼ç”Ÿæˆæ€»è¯„åˆ†æ
"""

import logging
import os
import sys
import time
from typing import Dict, Any, Optional, List, Tuple
from fastapi import APIRouter
from pydantic import BaseModel, Field
from fastapi.responses import StreamingResponse
import json
import asyncio
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
sys.path.insert(0, project_root)

from server.services.bazi_service import BaziService
from server.services.wangshuai_service import WangShuaiService
from server.services.bazi_detail_service import BaziDetailService
from server.services.rule_service import RuleService
from server.services.health_analysis_service import HealthAnalysisService
from server.services.rizhu_liujiazi_service import RizhuLiujiaziService
from core.analyzers.fortune_relation_analyzer import FortuneRelationAnalyzer
from server.utils.data_validator import validate_bazi_data
from server.api.v1.xishen_jishen import get_xishen_jishen, XishenJishenRequest
from server.utils.bazi_input_processor import BaziInputProcessor

# å¯¼å…¥é…ç½®åŠ è½½å™¨ï¼ˆä»æ•°æ®åº“è¯»å–é…ç½®ï¼‰
try:
    from server.config.config_loader import get_config_from_db_only
except ImportError:
    # å¦‚æœå¯¼å…¥å¤±è´¥ï¼ŒæŠ›å‡ºé”™è¯¯ï¼ˆä¸å…è®¸é™çº§ï¼‰
    def get_config_from_db_only(key: str) -> Optional[str]:
        raise ImportError("æ— æ³•å¯¼å…¥é…ç½®åŠ è½½å™¨ï¼Œè¯·ç¡®ä¿ server.config.config_loader æ¨¡å—å¯ç”¨")
from core.analyzers.rizhu_gender_analyzer import RizhuGenderAnalyzer
from core.analyzers.fortune_relation_analyzer import FortuneRelationAnalyzer
from core.analyzers.wuxing_balance_analyzer import WuxingBalanceAnalyzer
from server.orchestrators.bazi_data_orchestrator import BaziDataOrchestrator
from server.services.industry_service import IndustryService
from server.api.v1.models.bazi_base_models import BaziBaseRequest
from server.utils.dayun_liunian_helper import (
    calculate_user_age,
    get_current_dayun,
    build_enhanced_dayun_structure
)

from server.config.input_format_loader import build_input_data_from_result
from server.utils.prompt_builders import (
    format_general_review_input_data_for_coze as format_input_data_for_coze,
    format_general_review_for_llm,
    _simplify_dayun
)
from server.services.user_interaction_logger import get_user_interaction_logger

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

# åˆ›å»ºè·¯ç”±
router = APIRouter()


class GeneralReviewRequest(BaziBaseRequest):
    """æ€»è¯„åˆ†æè¯·æ±‚æ¨¡å‹ï¼ˆç»§æ‰¿ BaziBaseRequestï¼ŒåŒ…å«7ä¸ªæ ‡å‡†å‚æ•°ï¼‰"""
    bot_id: Optional[str] = Field(None, description="Coze Bot IDï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨ç¯å¢ƒå˜é‡é…ç½®ï¼‰")


@router.post("/general-review/test", summary="æµ‹è¯•æ¥å£ï¼šè¿”å›æ ¼å¼åŒ–åçš„æ•°æ®ï¼ˆç”¨äº Coze Botï¼‰")
async def general_review_analysis_test(request: GeneralReviewRequest):
    """
    æµ‹è¯•æ¥å£ï¼šè¿”å›æ ¼å¼åŒ–åçš„æ•°æ®ï¼ˆç”¨äº Coze Bot çš„ {{input}} å ä½ç¬¦ï¼‰
    
    âš ï¸ æ–¹æ¡ˆ2ï¼šä½¿ç”¨å ä½ç¬¦æ¨¡æ¿ï¼Œæ•°æ®ä¸é‡å¤ï¼ŒèŠ‚çœ Token
    æç¤ºè¯æ¨¡æ¿å·²é…ç½®åœ¨ Coze Bot çš„ System Prompt ä¸­ï¼Œä»£ç åªå‘é€æ•°æ®
    
    Args:
        request: æ€»è¯„åˆ†æè¯·æ±‚å‚æ•°
        
    Returns:
        dict: åŒ…å«æ ¼å¼åŒ–åçš„æ•°æ®
    """
    try:
        # å¤„ç†è¾“å…¥ï¼ˆå†œå†è½¬æ¢ç­‰ï¼‰
        final_solar_date, final_solar_time, _ = BaziInputProcessor.process_input(
            request.solar_date, request.solar_time, request.calendar_type or "solar", 
            request.location, request.latitude, request.longitude
        )
        
        # ä½¿ç”¨ç»Ÿä¸€æ¥å£è·å–åŸºç¡€æ•°æ®ï¼ˆä¸æµå¼æ¥å£ä¿æŒä¸€è‡´çš„ modules é…ç½®ï¼‰
        modules = {
            'bazi': True,
            'wangshuai': True,
            'xishen_jishen': True,
            'detail': True,
            'dayun': {
                'mode': 'count',
                'count': 13  # è·å–æ‰€æœ‰å¤§è¿ï¼ˆåŒ…å«å°è¿ï¼‰
            },
            'liunian': True,
            'special_liunians': {
                'dayun_config': {
                    'mode': 'count',
                    'count': 8
                },
                'count': 100
            },
            'personality': True,
            'rizhu': True,
            'health': True,
            'rules': {
                'types': ['rizhu_gender', 'character', 'summary']
            }
        }
        
        unified_data = await BaziDataOrchestrator.fetch_data(
            solar_date=final_solar_date,
            solar_time=final_solar_time,
            gender=request.gender,
            modules=modules,
            use_cache=True,
            parallel=True,
            calendar_type=request.calendar_type,
            location=request.location,
            latitude=request.latitude,
            longitude=request.longitude,
            preprocessed=True
        )
        
        # ä»ç»Ÿä¸€æ¥å£ç»“æœä¸­æå–æ•°æ®
        bazi_module_data = unified_data.get('bazi', {})
        if isinstance(bazi_module_data, dict) and 'bazi' in bazi_module_data:
            bazi_data = bazi_module_data.get('bazi', {})
            rizhu_from_bazi = bazi_module_data.get('rizhu', {})
        else:
            bazi_data = bazi_module_data
            rizhu_from_bazi = {}
        
        wangshuai_result = unified_data.get('wangshuai', {})
        detail_result = unified_data.get('detail', {})
        personality_result = unified_data.get('personality', {})
        rizhu_result = unified_data.get('rizhu', {}) or rizhu_from_bazi
        health_result = unified_data.get('health', {})
        
        # æå–å’ŒéªŒè¯æ•°æ®
        bazi_data = validate_bazi_data(bazi_data)
        
        # âœ… ä½¿ç”¨ç»Ÿä¸€æ•°æ®æœåŠ¡è·å–å¤§è¿æµå¹´ã€ç‰¹æ®Šæµå¹´æ•°æ®ï¼ˆä¸æµå¼æ¥å£ä¿æŒä¸€è‡´ï¼‰
        from server.orchestrators.bazi_data_service import BaziDataService
        
        fortune_data = await BaziDataService.get_fortune_data(
            solar_date=final_solar_date,
            solar_time=final_solar_time,
            gender=request.gender,
            calendar_type=request.calendar_type or "solar",
            location=request.location,
            latitude=request.latitude,
            longitude=request.longitude,
            include_dayun=True,
            include_liunian=True,
            include_special_liunian=True,
            dayun_mode=BaziDataService.DEFAULT_DAYUN_MODE,
            target_years=BaziDataService.DEFAULT_TARGET_YEARS,
            current_time=None
        )
        
        # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼ï¼ˆä¸æµå¼æ¥å£ä¿æŒä¸€è‡´ï¼‰
        dayun_sequence = []
        liunian_sequence = []
        special_liunians = []
        
        for dayun in fortune_data.dayun_sequence:
            dayun_sequence.append({
                'step': dayun.step,
                'stem': dayun.stem,
                'branch': dayun.branch,
                'year_start': dayun.year_start,
                'year_end': dayun.year_end,
                'age_range': dayun.age_range,
                'age_display': dayun.age_display,
                'nayin': dayun.nayin,
                'main_star': dayun.main_star,
                'hidden_stems': dayun.hidden_stems or [],
                'hidden_stars': dayun.hidden_stars or [],
                'star_fortune': dayun.star_fortune,
                'self_sitting': dayun.self_sitting,
                'kongwang': dayun.kongwang,
                'deities': dayun.deities or [],
                'details': dayun.details or {}
            })
        
        for liunian in fortune_data.liunian_sequence:
            liunian_sequence.append({
                'year': liunian.year,
                'stem': liunian.stem,
                'branch': liunian.branch,
                'ganzhi': liunian.ganzhi,
                'age': liunian.age,
                'age_display': liunian.age_display,
                'nayin': liunian.nayin,
                'main_star': liunian.main_star,
                'hidden_stems': liunian.hidden_stems or [],
                'hidden_stars': liunian.hidden_stars or [],
                'star_fortune': liunian.star_fortune,
                'self_sitting': liunian.self_sitting,
                'kongwang': liunian.kongwang,
                'deities': liunian.deities or [],
                'details': liunian.details or {}
            })
        
        for special_liunian in fortune_data.special_liunians:
            special_liunians.append({
                'year': special_liunian.year,
                'stem': special_liunian.stem,
                'branch': special_liunian.branch,
                'ganzhi': special_liunian.ganzhi,
                'age': special_liunian.age,
                'age_display': special_liunian.age_display,
                'nayin': special_liunian.nayin,
                'main_star': special_liunian.main_star,
                'hidden_stems': special_liunian.hidden_stems or [],
                'hidden_stars': special_liunian.hidden_stars or [],
                'star_fortune': special_liunian.star_fortune,
                'self_sitting': special_liunian.self_sitting,
                'kongwang': special_liunian.kongwang,
                'deities': special_liunian.deities or [],
                'relations': special_liunian.relations or [],
                'dayun_step': special_liunian.dayun_step,
                'dayun_ganzhi': special_liunian.dayun_ganzhi,
                'details': special_liunian.details or {}
            })
        
        logger.info(f"[General Review Test] âœ… ç»Ÿä¸€æ•°æ®æœåŠ¡è·å–å®Œæˆ - dayun: {len(dayun_sequence)}, liunian: {len(liunian_sequence)}, special: {len(special_liunians)}")
        
        # è·å–å–œå¿Œæ•°æ®ï¼ˆä» unified_data è·å–ï¼Œä¸æµå¼æ¥å£ä¸€è‡´ï¼‰
        xishen_jishen_result = unified_data.get('xishen_jishen', {})
        if xishen_jishen_result and hasattr(xishen_jishen_result, 'model_dump'):
            xishen_jishen_result = xishen_jishen_result.model_dump()
        elif xishen_jishen_result and hasattr(xishen_jishen_result, 'dict'):
            xishen_jishen_result = xishen_jishen_result.dict()
        
        # æ„å»ºinput_dataï¼ˆä¸æµå¼æ¥å£ä¿æŒä¸€è‡´ï¼‰
        input_data = build_general_review_input_data(
            bazi_data,
            wangshuai_result,
            detail_result,
            dayun_sequence,
            request.gender,
            final_solar_date,
            final_solar_time,
            personality_result,
            rizhu_result,
            health_result,
            liunian_sequence,  # ä½¿ç”¨ä» fortune_data è·å–çš„æµå¹´åºåˆ—
            special_liunians,
            xishen_jishen_result
        )
        logger.info("âœ… [General Review Test] ä½¿ç”¨ä¸æµå¼æ¥å£ä¸€è‡´çš„æ•°æ®æ„å»º input_data")
        
        # æ ¼å¼åŒ–æ•°æ®
        formatted_data = format_input_data_for_coze(input_data)
        
        return {
            "success": True,
            "formatted_data": formatted_data,
            "formatted_data_length": len(formatted_data),
            "data_summary": {
                "bazi_pillars": input_data.get('mingpan_hexin_geju', {}).get('bazi_pillars', {}),
                "dayun_count": len(input_data.get('guanjian_dayun', {}).get('key_dayuns', [])),
                "current_dayun_liunians_count": len(input_data.get('guanjian_dayun', {}).get('current_dayun', {}).get('liunians', []) if input_data.get('guanjian_dayun', {}).get('current_dayun') else []),
                "key_dayuns_count": len(input_data.get('guanjian_dayun', {}).get('key_dayuns', [])),
                "xishen": input_data.get('zhongsheng_tidian', {}).get('xishen', {}),
                "jishen": input_data.get('zhongsheng_tidian', {}).get('jishen', {})
            },
            "usage": {
                "description": "æ­¤æ¥å£è¿”å›çš„æ•°æ®å¯ä»¥ç›´æ¥ç”¨äº Coze Bot çš„ {{input}} å ä½ç¬¦",
                "coze_bot_setup": "1. ç™»å½• Coze å¹³å°\n2. æ‰¾åˆ°'å…«å­—å‘½ç†æ€»è¯„åˆ†æ' Bot\n3. è¿›å…¥ Bot è®¾ç½® â†’ System Prompt\n4. é…ç½®æç¤ºè¯å¹¶ä¿å­˜",
                "test_command": f'curl -X POST "http://localhost:8001/api/v1/general-review/test" -H "Content-Type: application/json" -d \'{{"solar_date": "{request.solar_date}", "solar_time": "{request.solar_time}", "gender": "{request.gender}", "calendar_type": "{request.calendar_type or "solar"}"}}\''
            }
        }
    except Exception as e:
        import traceback
        logger.error(f"æµ‹è¯•æ¥å£å¼‚å¸¸: {e}\n{traceback.format_exc()}")
        return {
            "success": False,
            "error": str(e),
            "traceback": traceback.format_exc()
        }


@router.post("/general-review/stream", summary="æµå¼ç”Ÿæˆæ€»è¯„åˆ†æ")
async def general_review_analysis_stream(request: GeneralReviewRequest):
    """
    æµå¼ç”Ÿæˆæ€»è¯„åˆ†æ
    
    Args:
        request: æ€»è¯„åˆ†æè¯·æ±‚å‚æ•°
        
    Returns:
        StreamingResponse: SSE æµå¼å“åº”
    """
    logger.info(f"[General Review API] æ”¶åˆ°è¯·æ±‚: solar_date={request.solar_date}, solar_time={request.solar_time}")
    
    return StreamingResponse(
        general_review_analysis_stream_generator(
            request.solar_date,
            request.solar_time,
            request.gender,
            request.calendar_type,
            request.location,
            request.latitude,
            request.longitude,
            request.bot_id
        ),
        media_type="text/event-stream"
    )


@router.post("/general-review/debug", summary="è°ƒè¯•ï¼šæŸ¥çœ‹æ€»è¯„åˆ†ææ•°æ®")
async def general_review_analysis_debug(request: GeneralReviewRequest):
    """
    è°ƒè¯•æ¥å£ï¼šæŸ¥çœ‹æå–çš„æ•°æ®å’Œæ„å»ºçš„ Prompt
    
    Args:
        request: æ€»è¯„åˆ†æè¯·æ±‚å‚æ•°
        
    Returns:
        dict: åŒ…å«æ•°æ®å’Œ Prompt çš„è°ƒè¯•ä¿¡æ¯
    """
    logger.debug(f"[DEBUG general_review_analysis_debug] å‡½æ•°è¢«è°ƒç”¨ï¼Œå‚æ•°: solar_date={request.solar_date}, solar_time={request.solar_time}, gender={request.gender}")
    logger.info(f"[General Review Debug] ========== å‡½æ•°å¼€å§‹æ‰§è¡Œ ==========")
    logger.info(f"[General Review Debug] å‡½æ•°è¢«è°ƒç”¨ï¼Œå‚æ•°: solar_date={request.solar_date}, solar_time={request.solar_time}, gender={request.gender}")
    try:
        # å¤„ç†è¾“å…¥ï¼ˆå†œå†è½¬æ¢ç­‰ï¼‰
        final_solar_date, final_solar_time, _ = BaziInputProcessor.process_input(
            request.solar_date, request.solar_time, "solar", None, None, None
        )
        
        # ä½¿ç”¨ç»Ÿä¸€æ¥å£è·å–æ•°æ®
        try:
            # æ„å»ºç»Ÿä¸€æ¥å£çš„ modules é…ç½®
            modules = {
                'bazi': True,
                'wangshuai': True,
                'xishen_jishen': True,
                'detail': True,
                'dayun': {
                    'mode': 'count',
                    'count': 13  # è·å–æ‰€æœ‰å¤§è¿ï¼ˆåŒ…å«å°è¿ï¼‰
                },
                'liunian': True,
                'special_liunians': {
                    'dayun_config': {
                        'mode': 'count',
                        'count': 8
                    },
                    'count': 100
                },
                'personality': True,
                'rizhu': True,
                'health': True,
                'rules': {
                    'types': ['rizhu_gender', 'character', 'summary']
                }
            }
            
            logger.info(f"[General Review Debug] å¼€å§‹è°ƒç”¨ç»Ÿä¸€æ¥å£è·å–æ•°æ®")
            unified_data = await BaziDataOrchestrator.fetch_data(
                solar_date=final_solar_date,
                solar_time=final_solar_time,
                gender=request.gender,
                modules=modules,
                use_cache=True,
                parallel=True,
                calendar_type=request.calendar_type,
                location=request.location,
                latitude=request.latitude,
                longitude=request.longitude
            )
            logger.info(f"[General Review Debug] âœ… ç»Ÿä¸€æ¥å£æ•°æ®è·å–å®Œæˆ")
            
        except Exception as e:
            import traceback
            error_msg = traceback.format_exc()
            logger.error(f"[General Review Debug] âŒ ç»Ÿä¸€æ¥å£è°ƒç”¨å¤±è´¥: {e}\n{error_msg}")
            return {
                "success": False,
                "error": f"æ•°æ®è·å–å¤±è´¥: {str(e)}",
                "error_trace": error_msg
            }
        
        # ä»ç»Ÿä¸€æ¥å£è¿”å›çš„æ•°æ®ä¸­æå–æ‰€éœ€å­—æ®µ
        # æ³¨æ„ï¼šBaziService.calculate_bazi_full è¿”å›çš„ç»“æ„æ˜¯ {bazi: {...}, rizhu: {...}, matched_rules: [...]}
        # æ‰€ä»¥å®é™…å…«å­—æ•°æ®åœ¨ unified_data['bazi']['bazi'] ä¸­
        bazi_module_data = unified_data.get('bazi', {})
        if isinstance(bazi_module_data, dict) and 'bazi' in bazi_module_data:
            # åµŒå¥—ç»“æ„ï¼š{bazi: {...å®é™…æ•°æ®...}, rizhu: {...}, matched_rules: [...]}
            bazi_data = bazi_module_data.get('bazi', {})
            # åŒæ—¶å¯ä»¥ä»è¿™é‡Œæå– rizhu å’Œ matched_rules
            rizhu_from_bazi = bazi_module_data.get('rizhu', {})
            matched_rules_from_bazi = bazi_module_data.get('matched_rules', [])
        else:
            # æ‰å¹³ç»“æ„æˆ–ç©ºæ•°æ®
            bazi_data = bazi_module_data
            rizhu_from_bazi = {}
            matched_rules_from_bazi = []
        
        # âš ï¸ ä¿®å¤ï¼šwangshuai_result ä¹Ÿæ˜¯åµŒå¥—ç»“æ„ {success: true, data: {...}}
        wangshuai_module_data = unified_data.get('wangshuai', {})
        if isinstance(wangshuai_module_data, dict) and 'data' in wangshuai_module_data:
            wangshuai_result = wangshuai_module_data.get('data', {})
        else:
            wangshuai_result = wangshuai_module_data
        xishen_jishen_result = unified_data.get('xishen_jishen', {})
        detail_data = unified_data.get('detail', {})
        personality_result = unified_data.get('personality', {})
        # ä¼˜å…ˆä½¿ç”¨ personality æ¨¡å—çš„ rizhuï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨ bazi æ¨¡å—è¿”å›çš„
        rizhu_result = unified_data.get('rizhu', {}) or rizhu_from_bazi
        health_result = unified_data.get('health', {})
        rules_data = unified_data.get('rules', [])
        
        # å¤„ç† xishen_jishen_resultï¼ˆå¯èƒ½æ˜¯ Pydantic æ¨¡å‹ï¼Œéœ€è¦è½¬æ¢ä¸ºå­—å…¸ï¼‰
        if xishen_jishen_result and hasattr(xishen_jishen_result, 'model_dump'):
            xishen_jishen_result = xishen_jishen_result.model_dump()
        elif xishen_jishen_result and hasattr(xishen_jishen_result, 'dict'):
            xishen_jishen_result = xishen_jishen_result.dict()
        
        # éªŒè¯å…«å­—æ•°æ®
        bazi_data = validate_bazi_data(bazi_data)
        
        # æå–å¤§è¿åºåˆ—å’Œæµå¹´åºåˆ—
        # ä¼˜å…ˆä» detail æ¨¡å—ä¸­æå–ï¼ˆä¸åŸæœ‰é€»è¾‘ä¸€è‡´ï¼‰
        if detail_data:
            details = detail_data.get('details', detail_data)
            dayun_sequence = details.get('dayun_sequence', [])
            liunian_sequence = details.get('liunian_sequence', [])
        else:
            # é™çº§æ–¹æ¡ˆï¼šä» dayun å’Œ liunian æ¨¡å—ä¸­æå–
            dayun_sequence = unified_data.get('dayun', [])
            liunian_sequence = unified_data.get('liunian', [])
        
        logger.info(f"[General Review Debug] è·å–åˆ° dayun_sequence æ•°é‡: {len(dayun_sequence)}, liunian_sequence æ•°é‡: {len(liunian_sequence)}")
        
        # æå–ç‰¹æ®Šæµå¹´ï¼ˆç»Ÿä¸€æ¥å£è¿”å›çš„æ˜¯å­—å…¸æ ¼å¼ï¼ŒåŒ…å« 'list', 'by_dayun', 'formatted'ï¼‰
        special_liunians_data = unified_data.get('special_liunians', {})
        if isinstance(special_liunians_data, dict):
            special_liunians = special_liunians_data.get('list', [])
        elif isinstance(special_liunians_data, list):
            special_liunians = special_liunians_data
        else:
            special_liunians = []
        
        logger.info(f"[General Review Debug] è·å–åˆ°ç‰¹æ®Šæµå¹´æ•°é‡: {len(special_liunians)}")
        
        # æå–è§„åˆ™åŒ¹é…ç»“æœï¼ˆç»Ÿä¸€æ¥å£è¿”å›çš„æ˜¯åˆ—è¡¨æ ¼å¼ï¼‰
        rizhu_rules = []
        if isinstance(rules_data, list):
            rizhu_rules = rules_data
        elif isinstance(rules_data, dict):
            # å¦‚æœè¿”å›çš„æ˜¯å­—å…¸æ ¼å¼ï¼Œåˆå¹¶æ‰€æœ‰è§„åˆ™ç±»å‹
            rizhu_rules = rules_data.get('rizhu_gender', []) + \
                         rules_data.get('character', []) + \
                         rules_data.get('summary', [])
        
        # æ„å»º detail_resultï¼ˆç”¨äº build_general_review_input_dataï¼‰
        # ä¿æŒä¸åŸæœ‰æ ¼å¼ä¸€è‡´
        detail_result = detail_data if detail_data else {
            'details': {
                'dayun_sequence': dayun_sequence,
                'liunian_sequence': liunian_sequence
            }
        }
        
        # è·å–äº”è¡Œç»Ÿè®¡
        element_counts = bazi_data.get('element_counts', {})
        
        # æ„å»ºinput_dataï¼ˆä¼˜å…ˆä½¿ç”¨æ•°æ®åº“æ ¼å¼å®šä¹‰ï¼‰
        # æ„å»ºinput_dataï¼ˆç›´æ¥ä½¿ç”¨ç¡¬ç¼–ç å‡½æ•°ï¼Œç¡®ä¿æ•°æ®å®Œæ•´æ€§ï¼‰
        input_data = build_general_review_input_data(
            bazi_data=bazi_data,
            wangshuai_result=wangshuai_result,
            detail_result=detail_result,
            dayun_sequence=dayun_sequence,
            gender=request.gender,
            solar_date=final_solar_date,
            solar_time=final_solar_time,
            personality_result=personality_result,
            rizhu_result=rizhu_result,
            health_result=health_result,
            liunian_sequence=liunian_sequence,
            special_liunians=special_liunians,
            xishen_jishen_result=xishen_jishen_result
        )
        logger.info("âœ… ä½¿ç”¨ç¡¬ç¼–ç å‡½æ•°æ„å»º input_data: general_review_analysis")
        
        # âš ï¸ DEBUG: è°ƒç”¨åæ£€æŸ¥å˜é‡
        logger.debug(f"[DEBUG] build_general_review_input_data è°ƒç”¨åï¼Œdayun_sequence æ•°é‡: {len(dayun_sequence)}, special_liunians æ•°é‡: {len(special_liunians)}")
        logger.info(f"[General Review Debug] build_general_review_input_data è°ƒç”¨åï¼Œdayun_sequence æ•°é‡: {len(dayun_sequence)}, special_liunians æ•°é‡: {len(special_liunians)}")
        
        # æ·»åŠ æ—¥æŸ±è§„åˆ™
        input_data['rizhu_rules'] = {
            'matched_rules': rizhu_rules,
            'rules_count': len(rizhu_rules),
            'rule_judgments': [
                rule.get('content', {}).get('text', '') 
                for rule in rizhu_rules 
                if isinstance(rule.get('content'), dict) and rule.get('content', {}).get('text')
            ]
        }
        
        # éªŒè¯æ•°æ®å®Œæ•´æ€§
        is_valid, validation_error = validate_general_review_input_data(input_data)
        if not is_valid:
            return {
                "success": False,
                "error": f"æ•°æ®å®Œæ•´æ€§éªŒè¯å¤±è´¥: {validation_error}"
            }
        
        # âœ… åªè¿”å› input_dataï¼Œè¯„æµ‹è„šæœ¬ä½¿ç”¨ç›¸åŒçš„å‡½æ•°æ„å»º formatted_data
        return {
            "success": True,
            "input_data": input_data,
            "summary": {
                "bazi_pillars": input_data.get('mingpan_hexin_geju', {}).get('bazi_pillars', {}),
                "dayun_count": len(input_data.get('guanjian_dayun', {}).get('key_dayuns', [])),
                "current_dayun_liunians_count": len(input_data.get('guanjian_dayun', {}).get('current_dayun', {}).get('liunians', []) if input_data.get('guanjian_dayun', {}).get('current_dayun') else []),
                "key_dayuns_count": len(input_data.get('guanjian_dayun', {}).get('key_dayuns', [])),
                "xishen": input_data.get('zhongsheng_tidian', {}).get('xishen', {}),
                "jishen": input_data.get('zhongsheng_tidian', {}).get('jishen', {})
            }
        }
    except Exception as e:
        import traceback
        error_trace = traceback.format_exc()
        logger.error(f"è°ƒè¯•æ¥å£å¤±è´¥: {e}\n{error_trace}")
        
        return {
            "success": False,
            "error": str(e)
        }


async def general_review_analysis_stream_generator(
    solar_date: str,
    solar_time: str,
    gender: str,
    calendar_type: Optional[str] = "solar",
    location: Optional[str] = None,
    latitude: Optional[float] = None,
    longitude: Optional[float] = None,
    bot_id: Optional[str] = None
):
    """
    æµå¼ç”Ÿæˆæ€»è¯„åˆ†æçš„ç”Ÿæˆå™¨
    
    Args:
        solar_date: é˜³å†æ—¥æœŸæˆ–å†œå†æ—¥æœŸ
        solar_time: å‡ºç”Ÿæ—¶é—´
        gender: æ€§åˆ«
        calendar_type: å†æ³•ç±»å‹ï¼ˆsolar/lunarï¼‰ï¼Œé»˜è®¤solar
        location: å‡ºç”Ÿåœ°ç‚¹ï¼ˆç”¨äºæ—¶åŒºè½¬æ¢ï¼Œä¼˜å…ˆçº§1ï¼‰
        latitude: çº¬åº¦ï¼ˆç”¨äºæ—¶åŒºè½¬æ¢ï¼Œä¼˜å…ˆçº§2ï¼‰
        longitude: ç»åº¦ï¼ˆç”¨äºæ—¶åŒºè½¬æ¢å’ŒçœŸå¤ªé˜³æ—¶è®¡ç®—ï¼Œä¼˜å…ˆçº§2ï¼‰
        bot_id: Coze Bot IDï¼ˆå¯é€‰ï¼‰
    """
    # è®°å½•å¼€å§‹æ—¶é—´å’Œå‰ç«¯è¾“å…¥
    api_start_time = time.time()
    frontend_input = {
        'solar_date': solar_date,
        'solar_time': solar_time,
        'gender': gender,
        'calendar_type': calendar_type,
        'location': location,
        'latitude': latitude,
        'longitude': longitude
    }
    llm_first_token_time = None
    llm_output_chunks = []
    
    # è°ƒè¯•ï¼šç¡®è®¤ç”Ÿæˆå™¨è¢«è°ƒç”¨
    logger.debug(f"[General Review Stream DEBUG] ç”Ÿæˆå™¨å¼€å§‹æ‰§è¡Œ: solar_date={solar_date}")
    
    try:
        # âœ… æ€§èƒ½ä¼˜åŒ–ï¼šç«‹å³è¿”å›é¦–æ¡æ¶ˆæ¯ï¼Œè®©ç”¨æˆ·æ„ŸçŸ¥åˆ°è¿æ¥å·²å»ºç«‹
        # è¿™ä¸ªä¼˜åŒ–å°†é¦–æ¬¡å“åº”æ—¶é—´ä» 24ç§’ é™ä½åˆ° <1ç§’
        # âœ… æ¶æ„ä¼˜åŒ–ï¼šç§»é™¤æ— æ„ä¹‰çš„è¿›åº¦æ¶ˆæ¯ï¼Œç›´æ¥å¼€å§‹æ•°æ®å¤„ç†
        # è¯¦è§ï¼šstandards/08_æ•°æ®ç¼–æ’æ¶æ„è§„èŒƒ.md
        
        # 1. ç¡®å®šä½¿ç”¨çš„ bot_idï¼ˆä¼˜å…ˆçº§ï¼šå‚æ•° > æ•°æ®åº“é…ç½® > ç¯å¢ƒå˜é‡ï¼‰
        used_bot_id = bot_id
        if not used_bot_id:
            # åªä»æ•°æ®åº“è¯»å–ï¼Œä¸é™çº§åˆ°ç¯å¢ƒå˜é‡
            used_bot_id = get_config_from_db_only("GENERAL_REVIEW_BOT_ID") or get_config_from_db_only("COZE_BOT_ID")
            if not used_bot_id:
                error_msg = {
                    'type': 'error',
                    'content': "æ•°æ®åº“é…ç½®ç¼ºå¤±: GENERAL_REVIEW_BOT_ID æˆ– COZE_BOT_IDï¼Œè¯·åœ¨ service_configs è¡¨ä¸­é…ç½®ã€‚"
                }
                yield f"data: {json.dumps(error_msg, ensure_ascii=False)}\n\n"
                return
        
        logger.info(f"æ€»è¯„åˆ†æè¯·æ±‚: solar_date={solar_date}, solar_time={solar_time}, gender={gender}, bot_id={used_bot_id}")
        
        # 2. å¤„ç†è¾“å…¥ï¼ˆå†œå†è½¬æ¢ç­‰ï¼Œæ”¯æŒ7ä¸ªæ ‡å‡†å‚æ•°ï¼‰
        final_solar_date, final_solar_time, _ = BaziInputProcessor.process_input(
            solar_date, solar_time, calendar_type or "solar", location, latitude, longitude
        )
        
        # 3. ä½¿ç”¨ç»Ÿä¸€æ¥å£è·å–æ•°æ®ï¼ˆé˜¶æ®µ2ï¼šæ•°æ®è·å–ä¸å¹¶è¡Œä¼˜åŒ–ï¼‰
        # âœ… æ€§èƒ½ä¼˜åŒ–ï¼šåœ¨æ•°æ®è·å–å¼€å§‹æ—¶å°± yieldï¼Œå‡å°‘å®¢æˆ·ç«¯ç­‰å¾…æ—¶é—´
        try:
            # æ„å»ºç»Ÿä¸€æ¥å£çš„ modules é…ç½®
            modules = {
                'bazi': True,
                'wangshuai': True,
                'xishen_jishen': True,
                'detail': True,
                'dayun': {
                    'mode': 'count',
                    'count': 13  # è·å–æ‰€æœ‰å¤§è¿ï¼ˆåŒ…å«å°è¿ï¼‰
                },
                'liunian': True,
                'special_liunians': {
                    'dayun_config': {
                        'mode': 'count',
                        'count': 8
                    },
                    'count': 100
                },
                'personality': True,
                'rizhu': True,  # âš ï¸ å¯ç”¨ rizhu æ¨¡å—ï¼ˆè°ƒç”¨ RizhuLiujiaziService è¿”å›å®Œæ•´åˆ†æï¼‰
                'health': True,
                'rules': {
                    'types': ['rizhu_gender', 'character', 'summary']
                }
            }
            
            logger.info(f"[General Review Stream] å¼€å§‹è°ƒç”¨ç»Ÿä¸€æ¥å£è·å–æ•°æ®")
            
            unified_data = await BaziDataOrchestrator.fetch_data(
                solar_date=final_solar_date,
                solar_time=final_solar_time,
                gender=gender,
                modules=modules,
                use_cache=True,
                parallel=True
            )
            logger.info(f"[General Review Stream] âœ… ç»Ÿä¸€æ¥å£æ•°æ®è·å–å®Œæˆ")
            
        except Exception as e:
            import traceback
            error_msg = traceback.format_exc()
            logger.error(f"[General Review Stream] âŒ ç»Ÿä¸€æ¥å£è°ƒç”¨å¤±è´¥: {e}\n{error_msg}")
            error_response = {
                'type': 'error',
                'content': f"æ•°æ®è·å–å¤±è´¥: {str(e)}ã€‚è¯·ç¨åé‡è¯•ã€‚"
            }
            yield f"data: {json.dumps(error_response, ensure_ascii=False)}\n\n"
            return
        
        # 4. ä»ç»Ÿä¸€æ¥å£è¿”å›çš„æ•°æ®ä¸­æå–æ‰€éœ€å­—æ®µ
        # æ³¨æ„ï¼šBaziService.calculate_bazi_full è¿”å›çš„ç»“æ„æ˜¯ {bazi: {...}, rizhu: {...}, matched_rules: [...]}
        # æ‰€ä»¥å®é™…å…«å­—æ•°æ®åœ¨ unified_data['bazi']['bazi'] ä¸­
        bazi_module_data = unified_data.get('bazi', {})
        if isinstance(bazi_module_data, dict) and 'bazi' in bazi_module_data:
            # åµŒå¥—ç»“æ„ï¼š{bazi: {...å®é™…æ•°æ®...}, rizhu: {...}, matched_rules: [...]}
            bazi_data = bazi_module_data.get('bazi', {})
            # åŒæ—¶å¯ä»¥ä»è¿™é‡Œæå– rizhu å’Œ matched_rules
            rizhu_from_bazi = bazi_module_data.get('rizhu', {})
            matched_rules_from_bazi = bazi_module_data.get('matched_rules', [])
        else:
            # æ‰å¹³ç»“æ„æˆ–ç©ºæ•°æ®
            bazi_data = bazi_module_data
            rizhu_from_bazi = {}
            matched_rules_from_bazi = []
        
        wangshuai_result = unified_data.get('wangshuai', {})
        xishen_jishen_result = unified_data.get('xishen_jishen', {})
        detail_data = unified_data.get('detail', {})
        personality_result = unified_data.get('personality', {})
        # ä¼˜å…ˆä½¿ç”¨ personality æ¨¡å—çš„ rizhuï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨ bazi æ¨¡å—è¿”å›çš„
        rizhu_result = unified_data.get('rizhu', {}) or rizhu_from_bazi
        health_result = unified_data.get('health', {})
        rules_data = unified_data.get('rules', [])
        
        # å¤„ç† xishen_jishen_resultï¼ˆå¯èƒ½æ˜¯ Pydantic æ¨¡å‹ï¼Œéœ€è¦è½¬æ¢ä¸ºå­—å…¸ï¼‰
        if xishen_jishen_result and hasattr(xishen_jishen_result, 'model_dump'):
            xishen_jishen_result = xishen_jishen_result.model_dump()
        elif xishen_jishen_result and hasattr(xishen_jishen_result, 'dict'):
            xishen_jishen_result = xishen_jishen_result.dict()
        
        # éªŒè¯å…«å­—æ•°æ®
        bazi_data = validate_bazi_data(bazi_data)
        
        # âœ… ä½¿ç”¨ç»Ÿä¸€æ•°æ®æœåŠ¡è·å–å¤§è¿æµå¹´ã€ç‰¹æ®Šæµå¹´æ•°æ®ï¼ˆç¡®ä¿æ•°æ®ä¸€è‡´æ€§ï¼‰
        # âœ… æ€§èƒ½ä¼˜åŒ–ï¼šå¤ç”¨ unified_data ä¸­å·²è·å–çš„ detail_dataï¼Œé¿å…é‡å¤è®¡ç®—
        from server.orchestrators.bazi_data_service import BaziDataService
        
        # è·å–å®Œæ•´è¿åŠ¿æ•°æ®ï¼ˆåŒ…å«å¤§è¿åºåˆ—ã€æµå¹´åºåˆ—ã€ç‰¹æ®Šæµå¹´ï¼‰
        # æ€§èƒ½ä¼˜åŒ–ï¼šä¼ å…¥å·²è·å–çš„ detail_dataï¼Œé¿å…é‡å¤è°ƒç”¨ calculate_detail_full
        fortune_data = await BaziDataService.get_fortune_data(
            solar_date=final_solar_date,
            solar_time=final_solar_time,
            gender=gender,
            calendar_type=calendar_type or "solar",
            location=location,
            latitude=latitude,
            longitude=longitude,
            include_dayun=True,
            include_liunian=True,
            include_special_liunian=True,
            dayun_mode=BaziDataService.DEFAULT_DAYUN_MODE,  # ç»Ÿä¸€çš„å¤§è¿æ¨¡å¼
            target_years=BaziDataService.DEFAULT_TARGET_YEARS,  # ç»Ÿä¸€çš„å¹´ä»½èŒƒå›´
            current_time=None,
            detail_result=detail_data  # âœ… æ€§èƒ½ä¼˜åŒ–ï¼šå¤ç”¨å·²è·å–çš„ detail_data
        )
        
        # âœ… æ€§èƒ½ä¼˜åŒ–ï¼šä½¿ç”¨åˆ—è¡¨æ¨å¯¼å¼æ‰¹é‡è½¬æ¢ï¼Œå‡å°‘å¾ªç¯å¼€é”€
        # ä»ç»Ÿä¸€æ•°æ®æœåŠ¡è·å–å¤§è¿åºåˆ—å’Œç‰¹æ®Šæµå¹´
        # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼ï¼ˆå…¼å®¹ç°æœ‰ä»£ç ï¼‰- ä½¿ç”¨åˆ—è¡¨æ¨å¯¼å¼ä¼˜åŒ–æ€§èƒ½
        dayun_sequence = [
            {
                'step': dayun.step,
                'stem': dayun.stem,
                'branch': dayun.branch,
                'year_start': dayun.year_start,
                'year_end': dayun.year_end,
                'age_range': dayun.age_range,
                'age_display': dayun.age_display,
                'nayin': dayun.nayin,
                'main_star': dayun.main_star,
                'hidden_stems': dayun.hidden_stems or [],
                'hidden_stars': dayun.hidden_stars or [],
                'star_fortune': dayun.star_fortune,
                'self_sitting': dayun.self_sitting,
                'kongwang': dayun.kongwang,
                'deities': dayun.deities or [],
                'details': dayun.details or {}
            }
            for dayun in fortune_data.dayun_sequence
        ]
        
        # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼ï¼ˆå…¼å®¹ç°æœ‰ä»£ç ï¼‰- ä½¿ç”¨åˆ—è¡¨æ¨å¯¼å¼ä¼˜åŒ–æ€§èƒ½
        liunian_sequence = [
            {
                'year': liunian.year,
                'stem': liunian.stem,
                'branch': liunian.branch,
                'ganzhi': liunian.ganzhi,
                'age': liunian.age,
                'age_display': liunian.age_display,
                'nayin': liunian.nayin,
                'main_star': liunian.main_star,
                'hidden_stems': liunian.hidden_stems or [],
                'hidden_stars': liunian.hidden_stars or [],
                'star_fortune': liunian.star_fortune,
                'self_sitting': liunian.self_sitting,
                'kongwang': liunian.kongwang,
                'deities': liunian.deities or [],
                'details': liunian.details or {}
            }
            for liunian in fortune_data.liunian_sequence
        ]
        
        # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼ï¼ˆå…¼å®¹ç°æœ‰ä»£ç ï¼‰- ä½¿ç”¨åˆ—è¡¨æ¨å¯¼å¼ä¼˜åŒ–æ€§èƒ½
        special_liunians = [
            {
                'year': special_liunian.year,
                'stem': special_liunian.stem,
                'branch': special_liunian.branch,
                'ganzhi': special_liunian.ganzhi,
                'age': special_liunian.age,
                'age_display': special_liunian.age_display,
                'nayin': special_liunian.nayin,
                'main_star': special_liunian.main_star,
                'hidden_stems': special_liunian.hidden_stems or [],
                'hidden_stars': special_liunian.hidden_stars or [],
                'star_fortune': special_liunian.star_fortune,
                'self_sitting': special_liunian.self_sitting,
                'kongwang': special_liunian.kongwang,
                'deities': special_liunian.deities or [],
                'relations': special_liunian.relations or [],
                'dayun_step': special_liunian.dayun_step,
                'dayun_ganzhi': special_liunian.dayun_ganzhi,
                'details': special_liunian.details or {}
            }
            for special_liunian in fortune_data.special_liunians
        ]
        
        logger.info(f"[General Review Stream] âœ… ç»Ÿä¸€æ•°æ®æœåŠ¡è·å–å®Œæˆ - dayun_sequence æ•°é‡: {len(dayun_sequence)}, liunian_sequence æ•°é‡: {len(liunian_sequence)}, ç‰¹æ®Šæµå¹´æ•°é‡: {len(special_liunians)}")
        
        # æå–è§„åˆ™åŒ¹é…ç»“æœï¼ˆç»Ÿä¸€æ¥å£è¿”å›çš„æ˜¯åˆ—è¡¨æ ¼å¼ï¼‰
        rizhu_rules = []
        if isinstance(rules_data, list):
            rizhu_rules = rules_data
        elif isinstance(rules_data, dict):
            # å¦‚æœè¿”å›çš„æ˜¯å­—å…¸æ ¼å¼ï¼Œåˆå¹¶æ‰€æœ‰è§„åˆ™ç±»å‹
            rizhu_rules = rules_data.get('rizhu_gender', []) + \
                         rules_data.get('character', []) + \
                         rules_data.get('summary', [])
        
        # æ„å»º detail_resultï¼ˆç”¨äº build_general_review_input_dataï¼‰
        # ä¿æŒä¸åŸæœ‰æ ¼å¼ä¸€è‡´
        detail_result = detail_data if detail_data else {
            'details': {
                'dayun_sequence': dayun_sequence,
                'liunian_sequence': liunian_sequence
            }
        }
        
        # è·å–äº”è¡Œç»Ÿè®¡
        element_counts = bazi_data.get('element_counts', {})
        
        # ========== é˜¶æ®µ5ï¼šæ„å»º input_dataï¼ˆç›´æ¥ä½¿ç”¨ç¡¬ç¼–ç å‡½æ•°ï¼Œç¡®ä¿æ•°æ®å®Œæ•´æ€§ï¼‰ ==========
        logger.info(f"[é˜¶æ®µ5-DEBUG] å‡†å¤‡æ„å»º input_dataï¼Œspecial_liunians æ•°é‡: {len(special_liunians)}")
        if special_liunians:
            special_liunian_strs = [f"{l.get('year', '')}å¹´{l.get('ganzhi', '')}" for l in special_liunians[:3]]
            logger.info(f"[é˜¶æ®µ5-DEBUG] special_liunians å†…å®¹: {special_liunian_strs}")
        
        input_data = build_general_review_input_data(
            bazi_data=bazi_data,
            wangshuai_result=wangshuai_result,
            detail_result=detail_result,
            dayun_sequence=dayun_sequence,
            gender=gender,
            solar_date=final_solar_date,
            solar_time=final_solar_time,
            personality_result=personality_result,
            rizhu_result=rizhu_result,
            health_result=health_result,
            liunian_sequence=liunian_sequence,
            special_liunians=special_liunians,
            xishen_jishen_result=xishen_jishen_result
        )
        logger.info("âœ… ä½¿ç”¨ç¡¬ç¼–ç å‡½æ•°æ„å»º input_data: general_review_analysis")
        
        # 8. æ·»åŠ æ—¥æŸ±è§„åˆ™ï¼ˆNEWï¼‰
        input_data['rizhu_rules'] = {
            'matched_rules': rizhu_rules,
            'rules_count': len(rizhu_rules),
            'rule_judgments': [
                rule.get('content', {}).get('text', '') 
                for rule in rizhu_rules 
                if isinstance(rule.get('content'), dict) and rule.get('content', {}).get('text')
            ]
        }
        
        # 7. éªŒè¯æ•°æ®å®Œæ•´æ€§ï¼ˆé˜¶æ®µ3ï¼šæ•°æ®éªŒè¯ä¸å®Œæ•´æ€§æ£€æŸ¥ï¼‰
        is_valid, validation_error = validate_general_review_input_data(input_data)
        if not is_valid:
            logger.error(f"æ•°æ®å®Œæ•´æ€§éªŒè¯å¤±è´¥: {validation_error}")
            error_msg = {
                'type': 'error',
                'content': f"æ•°æ®è®¡ç®—ä¸å®Œæ•´: {validation_error}ã€‚è¯·æ£€æŸ¥ç”Ÿè¾°æ•°æ®æ˜¯å¦æ­£ç¡®ã€‚"
            }
            yield f"data: {json.dumps(error_msg, ensure_ascii=False)}\n\n"
            return
        
        # 8. âš ï¸ ä¼˜åŒ–ï¼šä½¿ç”¨ç²¾ç®€ä¸­æ–‡æ–‡æœ¬æ ¼å¼ï¼ˆToken å‡å°‘ 86%ï¼‰
        formatted_data = format_general_review_for_llm(input_data)
        logger.info(f"[General Review Stream] æ ¼å¼åŒ–æ•°æ®é•¿åº¦: {len(formatted_data)} å­—ç¬¦ï¼ˆä¼˜åŒ–åï¼‰")
        logger.debug(f"[General Review Stream] æ ¼å¼åŒ–æ•°æ®:\n{formatted_data}")
        
        # 8.1 ä¿å­˜å‚æ•°åˆ°æ–‡ä»¶ï¼ˆç”¨äºæ•°æ®å‡æåˆ†æï¼‰
        try:
            # åˆ›å»ºä¿å­˜ç›®å½•
            save_dir = os.path.join(project_root, "logs", "general_review_params")
            os.makedirs(save_dir, exist_ok=True)
            
            # ç”Ÿæˆæ–‡ä»¶åï¼ˆä½¿ç”¨æ—¶é—´æˆ³é¿å…å†²çªï¼‰
            timestamp_str = datetime.now().strftime("%Y%m%d-%H%M%S")
            safe_date = final_solar_date.replace("-", "")
            safe_time = final_solar_time.replace(":", "-")
            filename = f"general_review_{safe_date}_{safe_time}_{gender}_{timestamp_str}.json"
            filepath = os.path.join(save_dir, filename)
            
            # è®¡ç®—æ•°æ®ç»Ÿè®¡
            def calculate_module_size(module_data):
                """è®¡ç®—æ¨¡å—æ•°æ®å¤§å°ï¼ˆJSONåºåˆ—åŒ–åçš„å­—èŠ‚æ•°ï¼‰"""
                try:
                    return len(json.dumps(module_data, ensure_ascii=False))
                except:
                    return 0
            
            modules_size = {}
            for key, value in input_data.items():
                if key != '_debug':  # è·³è¿‡è°ƒè¯•ä¿¡æ¯
                    modules_size[key] = calculate_module_size(value)
            
            # æ„å»ºä¿å­˜æ•°æ®
            save_data = {
                "request_params": {
                    "solar_date": final_solar_date,
                    "solar_time": final_solar_time,
                    "gender": gender,
                    "calendar_type": calendar_type,
                    "location": location,
                    "latitude": latitude,
                    "longitude": longitude
                },
                "formatted_data": formatted_data,
                "statistics": {
                    "formatted_data_length": len(formatted_data),
                    "formatted_data_size_kb": round(len(formatted_data) / 1024, 2),
                    "input_data_keys": list(input_data.keys()),
                    "modules_size": modules_size,
                    "modules_size_total_kb": round(sum(modules_size.values()) / 1024, 2),
                    "dayun_count": len(dayun_sequence),
                    "liunian_count": len(liunian_sequence),
                    "special_liunian_count": len(special_liunians)
                },
                "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            }
            
            # ä¿å­˜åˆ°æ–‡ä»¶
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(save_data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"[General Review Stream] âœ… å‚æ•°å·²ä¿å­˜åˆ°: {filepath}")
            logger.info(f"[General Review Stream] æ•°æ®ç»Ÿè®¡: æ€»å¤§å° {save_data['statistics']['formatted_data_size_kb']} KB, "
                       f"æ¨¡å—æ€»å¤§å° {save_data['statistics']['modules_size_total_kb']} KB")
        except Exception as e:
            # ä¿å­˜å¤±è´¥ä¸å½±å“ä¸»æµç¨‹
            logger.warning(f"[General Review Stream] ä¿å­˜å‚æ•°æ–‡ä»¶å¤±è´¥: {e}", exc_info=True)
        
        # 9. è°ƒç”¨ LLM APIï¼ˆé˜¶æ®µ5ï¼šLLM APIè°ƒç”¨ï¼Œæ”¯æŒ Coze å’Œç™¾ç‚¼å¹³å°ï¼‰
        logger.info(f"ğŸ” [æ­¥éª¤5-LLMè°ƒç”¨] å¼€å§‹è°ƒç”¨ LLM APIï¼ŒBot ID: {used_bot_id}")
        from server.services.llm_service_factory import LLMServiceFactory
        llm_service = LLMServiceFactory.get_service(scene="general_review", bot_id=used_bot_id)

        # 10. æµå¼å¤„ç†ï¼ˆé˜¶æ®µ6ï¼šæµå¼å¤„ç†ï¼‰
        llm_start_time = time.time()
        chunk_count = 0
        total_content_length = 0
        has_content = False
        
        async for chunk in llm_service.stream_analysis(formatted_data, bot_id=used_bot_id):
            chunk_type = chunk.get('type', 'unknown')
            
            # è®°å½•ç¬¬ä¸€ä¸ªtokenæ—¶é—´
            if llm_first_token_time is None and chunk_type == 'progress':
                llm_first_token_time = time.time()
            
            if chunk_type == 'progress':
                chunk_count += 1
                content = chunk.get('content', '')
                llm_output_chunks.append(content)  # æ”¶é›†è¾“å‡ºå†…å®¹
                total_content_length += len(content)
                has_content = True
                if chunk_count == 1:
                    logger.info(f"âœ… [æ­¥éª¤5-Cozeè°ƒç”¨] æ”¶åˆ°ç¬¬ä¸€ä¸ªå“åº”å—ï¼Œç±»å‹: {chunk_type}")
            elif chunk_type == 'complete':
                complete_content = chunk.get('content', '')
                llm_output_chunks.append(complete_content)  # æ”¶é›†å®Œæ•´å†…å®¹
                logger.info(f"âœ… [æ­¥éª¤5-Cozeè°ƒç”¨] æ”¶åˆ°å®Œæˆå“åº”ï¼Œæ€»å—æ•°: {chunk_count}, æ€»å†…å®¹é•¿åº¦: {total_content_length}")
                has_content = True
            elif chunk_type == 'error':
                logger.error(f"âŒ [æ­¥éª¤5-Cozeè°ƒç”¨] æ”¶åˆ°é”™è¯¯å“åº”: {chunk.get('content', '')}")
            
            yield f"data: {json.dumps(chunk, ensure_ascii=False)}\n\n"
            if chunk_type in ['complete', 'error']:
                break
        
        # è®°å½•äº¤äº’æ•°æ®ï¼ˆå¼‚æ­¥ï¼Œä¸é˜»å¡ï¼‰
        api_end_time = time.time()
        api_response_time_ms = int((api_end_time - api_start_time) * 1000)
        llm_total_time_ms = int((api_end_time - llm_start_time) * 1000) if llm_start_time else None
        llm_output = ''.join(llm_output_chunks)
        
        logger_instance = get_user_interaction_logger()
        logger_instance.log_function_usage_async(
            function_type='general',
            function_name='å…«å­—å‘½ç†-æ€»è¯„åˆ†æ',
            frontend_api='/api/v1/bazi/general-review/stream',
            frontend_input=frontend_input,
            input_data=input_data if 'input_data' in locals() else {},
            llm_output=llm_output,
            llm_api='coze_api',
            api_response_time_ms=api_response_time_ms,
            llm_first_token_time_ms=int((llm_first_token_time - llm_start_time) * 1000) if llm_first_token_time and llm_start_time else None,
            llm_total_time_ms=llm_total_time_ms,
            round_number=1,
            bot_id=used_bot_id,
            status='success' if has_content else 'failed',
            streaming=True
        )
                
    except ValueError as e:
        # é…ç½®é”™è¯¯
        logger.error(f"Coze API é…ç½®é”™è¯¯: {e}")
        error_msg = {
            'type': 'error',
            'content': f"Coze API é…ç½®ç¼ºå¤±: {str(e)}"
        }
        yield f"data: {json.dumps(error_msg, ensure_ascii=False)}\n\n"
        
        # è®°å½•é”™è¯¯
        api_end_time = time.time()
        api_response_time_ms = int((api_end_time - api_start_time) * 1000)
        logger_instance = get_user_interaction_logger()
        logger_instance.log_function_usage_async(
            function_type='general',
            function_name='å…«å­—å‘½ç†-æ€»è¯„åˆ†æ',
            frontend_api='/api/v1/bazi/general-review/stream',
            frontend_input=frontend_input,
            input_data={},
            llm_output='',
            llm_api='coze_api',
            api_response_time_ms=api_response_time_ms,
            llm_first_token_time_ms=None,
            llm_total_time_ms=None,
            round_number=1,
            status='failed',
            error_message=str(e),
            streaming=True
        )
    except Exception as e:
        # å…¶ä»–é”™è¯¯ï¼ˆé˜¶æ®µ7ï¼šé”™è¯¯å¤„ç†ï¼‰
        import traceback
        logger.error(f"æ€»è¯„åˆ†æå¤±è´¥: {e}\n{traceback.format_exc()}")
        error_msg = {
            'type': 'error',
            'content': f"åˆ†æå¤„ç†å¤±è´¥: {str(e)}"
        }
        yield f"data: {json.dumps(error_msg, ensure_ascii=False)}\n\n"
        
        # è®°å½•é”™è¯¯
        api_end_time = time.time()
        api_response_time_ms = int((api_end_time - api_start_time) * 1000)
        logger_instance = get_user_interaction_logger()
        logger_instance.log_function_usage_async(
            function_type='general',
            function_name='å…«å­—å‘½ç†-æ€»è¯„åˆ†æ',
            frontend_api='/api/v1/bazi/general-review/stream',
            frontend_input=frontend_input,
            input_data={},
            llm_output='',
            llm_api='coze_api',
            api_response_time_ms=api_response_time_ms,
            llm_first_token_time_ms=None,
            llm_total_time_ms=None,
            round_number=1,
            status='failed',
            error_message=str(e),
            streaming=True
        )


def classify_special_liunians(special_liunians: List[Dict[str, Any]]) -> Dict[str, List[Dict[str, Any]]]:
    """
    æŒ‰å…³ç³»ç±»å‹åˆ†ç±»ç‰¹æ®Šæµå¹´ï¼ˆä¼˜å…ˆçº§æ’åºï¼‰
    
    ä¼˜å…ˆçº§ï¼šå¤©å…‹åœ°å†² > å¤©åˆåœ°åˆ > å²è¿å¹¶ä¸´ > å…¶ä»–
    
    Args:
        special_liunians: ç‰¹æ®Šæµå¹´åˆ—è¡¨
        
    Returns:
        dict: åˆ†ç±»åçš„ç‰¹æ®Šæµå¹´
            - tiankedi_chong: å¤©å…‹åœ°å†²çš„æµå¹´
            - tianhedi_he: å¤©åˆåœ°åˆçš„æµå¹´
            - suiyun_binglin: å²è¿å¹¶ä¸´çš„æµå¹´
            - other: å…¶ä»–å…³ç³»çš„æµå¹´
    """
    classified = {
        'tiankedi_chong': [],
        'tianhedi_he': [],
        'suiyun_binglin': [],
        'other': []
    }
    
    for liunian in special_liunians:
        relations = liunian.get('relations', [])
        relation_types = [r.get('type', '') for r in relations]
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«ä¼˜å…ˆå…³ç³»ï¼ˆæŒ‰ä¼˜å…ˆçº§é¡ºåºï¼‰
        has_tiankedi = any('å¤©å…‹åœ°å†²' in rt for rt in relation_types)
        has_tianhedi = any('å¤©åˆåœ°åˆ' in rt for rt in relation_types)
        has_suiyun = any('å²è¿å¹¶ä¸´' in rt for rt in relation_types)
        
        # ä¼˜å…ˆçº§ï¼šå¤©å…‹åœ°å†² > å¤©åˆåœ°åˆ > å²è¿å¹¶ä¸´ > å…¶ä»–
        if has_tiankedi:
            classified['tiankedi_chong'].append(liunian)
        elif has_tianhedi:
            classified['tianhedi_he'].append(liunian)
        elif has_suiyun:
            classified['suiyun_binglin'].append(liunian)
        else:
            classified['other'].append(liunian)
    
    return classified


def organize_special_liunians_by_dayun(
    special_liunians: List[Dict[str, Any]], 
    dayun_sequence: List[Dict[str, Any]]
) -> Dict[int, Dict[str, Any]]:
    """
    å°†ç‰¹æ®Šæµå¹´æŒ‰å¤§è¿åˆ†ç»„ï¼Œæ¯ä¸ªå¤§è¿ä¸‹çš„æµå¹´æŒ‰ä¼˜å…ˆçº§åˆ†ç±»
    
    ä¼˜å…ˆçº§ï¼šå¤©å…‹åœ°å†² > å¤©åˆåœ°åˆ > å²è¿å¹¶ä¸´ > å…¶ä»–
    
    Args:
        special_liunians: ç‰¹æ®Šæµå¹´åˆ—è¡¨ï¼ˆåŒ…å« dayun_step å­—æ®µï¼‰
        dayun_sequence: å¤§è¿åºåˆ—ï¼ˆç”¨äºè·å–å¤§è¿ä¿¡æ¯ï¼‰
    
    Returns:
        dict: {
            dayun_step: {
                'dayun_info': {...},  # å¤§è¿ä¿¡æ¯ï¼ˆstep, stem, branch, age_display, year_start, year_endï¼‰
                'tiankedi_chong': [...],  # å¤©å…‹åœ°å†²
                'tianhedi_he': [...],     # å¤©åˆåœ°åˆ
                'suiyun_binglin': [...],  # å²è¿å¹¶ä¸´
                'other': [...]            # å…¶ä»–
            }
        }
    """
    # 1. å…ˆæŒ‰å…³ç³»ç±»å‹åˆ†ç±»ï¼ˆä¼˜å…ˆçº§æ’åºï¼‰
    classified = classify_special_liunians(special_liunians)
    
    # 2. åˆ›å»ºå¤§è¿æ˜ å°„
    dayun_map = {}
    for dayun in dayun_sequence:
        step = dayun.get('step')
        if step is not None:
            dayun_map[step] = {
                'step': dayun.get('step'),
                'stem': dayun.get('stem', ''),
                'branch': dayun.get('branch', ''),
                'age_display': dayun.get('age_display', ''),
                'year_start': dayun.get('year_start', 0),
                'year_end': dayun.get('year_end', 0)
            }
    
    # 3. æŒ‰å¤§è¿åˆ†ç»„
    result = {}
    
    # å¤„ç†å¤©å…‹åœ°å†²
    for liunian in classified['tiankedi_chong']:
        step = liunian.get('dayun_step')
        if step is not None:
            if step not in result:
                result[step] = {
                    'dayun_info': dayun_map.get(step, {}),
                    'tiankedi_chong': [],
                    'tianhedi_he': [],
                    'suiyun_binglin': [],
                    'other': []
                }
            result[step]['tiankedi_chong'].append(liunian)
    
    # å¤„ç†å¤©åˆåœ°åˆ
    for liunian in classified['tianhedi_he']:
        step = liunian.get('dayun_step')
        if step is not None:
            if step not in result:
                result[step] = {
                    'dayun_info': dayun_map.get(step, {}),
                    'tiankedi_chong': [],
                    'tianhedi_he': [],
                    'suiyun_binglin': [],
                    'other': []
                }
            result[step]['tianhedi_he'].append(liunian)
    
    # å¤„ç†å²è¿å¹¶ä¸´
    for liunian in classified['suiyun_binglin']:
        step = liunian.get('dayun_step')
        if step is not None:
            if step not in result:
                result[step] = {
                    'dayun_info': dayun_map.get(step, {}),
                    'tiankedi_chong': [],
                    'tianhedi_he': [],
                    'suiyun_binglin': [],
                    'other': []
                }
            result[step]['suiyun_binglin'].append(liunian)
    
    # å¤„ç†å…¶ä»–
    for liunian in classified['other']:
        step = liunian.get('dayun_step')
        if step is not None:
            if step not in result:
                result[step] = {
                    'dayun_info': dayun_map.get(step, {}),
                    'tiankedi_chong': [],
                    'tianhedi_he': [],
                    'suiyun_binglin': [],
                    'other': []
                }
            result[step]['other'].append(liunian)
    
    return result


def _build_rizhu_xinming_node(
    day_pillar: Dict[str, Any],
    gender: str,
    personality_result: Optional[Dict[str, Any]]
) -> Dict[str, Any]:
    """
    æ„å»ºæ—¥æŸ±æ€§å‘½è§£æèŠ‚ç‚¹
    
    åŒ…å«å®Œæ•´çš„æ—¥æŸ±æ€§æ ¼ä¸å‘½è¿åˆ†ææ•°æ®ï¼ˆ31æ¡æˆ–æ›´å¤šï¼‰ï¼Œä¸çœç•¥ä»»ä½•å†…å®¹ã€‚
    æ•°æ®æ¥æºï¼šsrc/bazi_config/rizhu_gender_config.py -> RIZHU_GENDER_CONFIG
    
    Args:
        day_pillar: æ—¥æŸ±æ•°æ®ï¼ŒåŒ…å« stemï¼ˆå¤©å¹²ï¼‰å’Œ branchï¼ˆåœ°æ”¯ï¼‰
        gender: æ€§åˆ«ï¼ˆmale/femaleï¼‰
        personality_result: æ—¥ä¸»æ€§æ ¼åˆ†æç»“æœï¼ŒåŒ…å« descriptions åˆ—è¡¨
    
    Returns:
        dict: æ—¥æŸ±æ€§å‘½è§£æèŠ‚ç‚¹
            {
                'rizhu': 'ç”²å­',              # æ—¥æŸ±ï¼ˆå¤©å¹²+åœ°æ”¯ï¼‰
                'gender': 'female',           # æ€§åˆ«
                'gender_display': 'å¥³',       # æ€§åˆ«æ˜¾ç¤º
                'descriptions': [...],        # å®Œæ•´çš„æ€§æ ¼å‘½è¿æè¿°åˆ—è¡¨
                'descriptions_count': 31,     # æè¿°æ¡ç›®æ•°é‡
                'summary': 'æ—¥æŸ±ç”²å­å¥³å‘½åˆ†æ'  # æ‘˜è¦æ ‡é¢˜
            }
    """
    # æå–æ—¥æŸ±
    day_stem = day_pillar.get('stem', '') if day_pillar else ''
    day_branch = day_pillar.get('branch', '') if day_pillar else ''
    rizhu = f"{day_stem}{day_branch}"
    
    # è½¬æ¢æ€§åˆ«æ˜¾ç¤º
    gender_display = 'ç”·' if gender == 'male' else 'å¥³'
    
    # æå–å®Œæ•´çš„ descriptions åˆ—è¡¨
    descriptions = []
    if personality_result and isinstance(personality_result, dict):
        descriptions = personality_result.get('descriptions', [])
    
    # æ„å»ºæ‘˜è¦
    summary = f"æ—¥æŸ±{rizhu}{gender_display}å‘½åˆ†æ" if rizhu else f"{gender_display}å‘½åˆ†æ"
    
    # è®°å½•æ—¥å¿—
    logger.info(f"[rizhu_xinming_jiexi] æ„å»ºæ—¥æŸ±èŠ‚ç‚¹: rizhu={rizhu}, gender={gender}, descriptions_count={len(descriptions)}")
    
    return {
        'rizhu': rizhu,
        'gender': gender,
        'gender_display': gender_display,
        'descriptions': descriptions,  # å®Œæ•´çš„31æ¡ï¼ˆæˆ–æ›´å¤šï¼‰æ•°æ®
        'descriptions_count': len(descriptions),
        'summary': summary
    }


def build_general_review_input_data(
    bazi_data: Dict[str, Any],
    wangshuai_result: Dict[str, Any],
    detail_result: Dict[str, Any],
    dayun_sequence: List[Dict[str, Any]],
    gender: str,
    solar_date: str = None,  # âš ï¸ æ–°å¢ï¼šåŸå§‹é˜³å†æ—¥æœŸ
    solar_time: str = None,  # âš ï¸ æ–°å¢ï¼šåŸå§‹é˜³å†æ—¶é—´
    personality_result: Dict[str, Any] = None,
    rizhu_result: Dict[str, Any] = None,
    health_result: Dict[str, Any] = None,
    liunian_sequence: List[Dict[str, Any]] = None,
    special_liunians: List[Dict[str, Any]] = None,  # âš ï¸ æ–°å¢ï¼šç‰¹æ®Šæµå¹´ï¼ˆå·²ç­›é€‰ï¼‰
    xishen_jishen_result: Any = None  # âš ï¸ å–œå¿Œæ•°æ®ç»“æœï¼ˆXishenJishenResponseï¼‰
) -> Dict[str, Any]:
    """
    æ„å»ºæ€»è¯„åˆ†æçš„è¾“å…¥æ•°æ®
    
    Args:
        bazi_data: å…«å­—åŸºç¡€æ•°æ®
        wangshuai_result: æ—ºè¡°åˆ†æç»“æœ
        detail_result: è¯¦ç»†è®¡ç®—ç»“æœ
        dayun_sequence: å¤§è¿åºåˆ—
        gender: æ€§åˆ«ï¼ˆmale/femaleï¼‰
        solar_date: åŸå§‹é˜³å†æ—¥æœŸ
        solar_time: åŸå§‹é˜³å†æ—¶é—´
        personality_result: æ—¥ä¸»æ€§æ ¼åˆ†æç»“æœ
        rizhu_result: æ—¥æŸ±ç®—æ³•ç»“æœ
        health_result: å¥åº·åˆ†æç»“æœ
        liunian_sequence: æµå¹´åºåˆ—
        
    Returns:
        dict: æ€»è¯„åˆ†æçš„input_data
    """
    # âš ï¸ DEBUG: è®°å½•å‚æ•°ä¿¡æ¯åˆ°æ—¥å¿—
    logger.info(f"[DEBUG build_general_review_input_data] solar_date={solar_date}, solar_time={solar_time}, gender={gender}")
    logger.info(f"[DEBUG build_general_review_input_data] dayun_sequence length={len(dayun_sequence)}")
    logger.info(f"[DEBUG build_general_review_input_data] bazi_data keys={list(bazi_data.keys())}")
    logger.info(f"[DEBUG build_general_review_input_data] bazi_data type={type(bazi_data)}")
    
    # æå–åŸºç¡€æ•°æ®
    bazi_pillars = bazi_data.get('bazi_pillars', {})
    logger.info(f"[DEBUG] bazi_pillars={bazi_pillars}")
    day_pillar = bazi_pillars.get('day', {})
    element_counts = bazi_data.get('element_counts', {})
    logger.info(f"[DEBUG] element_counts={element_counts}")
    ten_gods_data = bazi_data.get('ten_gods_stats', {})
    ten_gods_full = bazi_data.get('ten_gods', {})
    
    # æå–æœˆä»¤
    month_pillar = bazi_pillars.get('month', {})
    month_branch = month_pillar.get('branch', '')
    yue_ling = f"{month_branch}æœˆ" if month_branch else ''
    
    # åˆ¤æ–­æ ¼å±€ç±»å‹ï¼ˆåŸºäºæœˆä»¤å’Œåç¥é…ç½®ï¼‰
    geju_type = determine_geju_type(month_branch, ten_gods_full, wangshuai_result)
    
    # åˆ†æäº”è¡Œæµé€šæƒ…å†µ
    wuxing_liutong = analyze_wuxing_liutong(element_counts, bazi_pillars)
    
    # æå–äº‹ä¸šæ˜Ÿå’Œè´¢å¯Œæ˜Ÿ
    shiye_xing = extract_career_star(ten_gods_data)
    caifu_xing = extract_wealth_star(ten_gods_data)
    
    # åˆ†æå¤§è¿å¯¹äº‹ä¸šè´¢è¿çš„å½±å“
    dayun_effect = analyze_dayun_effect(dayun_sequence, shiye_xing, caifu_xing, ten_gods_data)
    
    # âš ï¸ æ•°æ®æå–è¾…åŠ©å‡½æ•°ï¼šä» wangshuai_result ä¸­æå–æ—ºè¡°æ•°æ®
    def extract_wangshuai_data(wangshuai_result: Dict[str, Any]) -> Dict[str, Any]:
        """ä» wangshuai_result ä¸­æå–æ—ºè¡°æ•°æ®"""
        if isinstance(wangshuai_result, dict):
            if wangshuai_result.get('success') and 'data' in wangshuai_result:
                return wangshuai_result.get('data', {})
            if 'wangshuai' in wangshuai_result or 'xi_shen' in wangshuai_result:
                return wangshuai_result
        return {}
    
    # âš ï¸ æ•°æ®æå–è¾…åŠ©å‡½æ•°ï¼šä» detail_result æˆ– bazi_data ä¸­æå–åç¥æ•°æ®
    def extract_ten_gods_data(detail_result: Dict[str, Any], bazi_data: Dict[str, Any]) -> Dict[str, Any]:
        """ä» detail_result æˆ– bazi_data ä¸­æå–åç¥æ•°æ®"""
        # 1. å…ˆå°è¯•ä» detail_result çš„é¡¶å±‚è·å–
        ten_gods = detail_result.get('ten_gods', {})
        if ten_gods and isinstance(ten_gods, dict) and len(ten_gods) > 0:
            return ten_gods
        
        # 2. å°è¯•ä» detail_result çš„ details å­—æ®µä¸­æå–
        details = detail_result.get('details', {})
        if details and isinstance(details, dict):
            ten_gods_from_details = {}
            for pillar_name in ['year', 'month', 'day', 'hour']:
                pillar_detail = details.get(pillar_name, {})
                if isinstance(pillar_detail, dict):
                    ten_gods_from_details[pillar_name] = {
                        'main_star': pillar_detail.get('main_star', ''),
                        'hidden_stars': pillar_detail.get('hidden_stars', [])
                    }
            if any(ten_gods_from_details.values()):
                return ten_gods_from_details
        
        # 3. å°è¯•ä» bazi_data çš„ details å­—æ®µä¸­æå–
        bazi_details = bazi_data.get('details', {})
        if bazi_details and isinstance(bazi_details, dict):
            ten_gods_from_bazi = {}
            for pillar_name in ['year', 'month', 'day', 'hour']:
                pillar_detail = bazi_details.get(pillar_name, {})
                if isinstance(pillar_detail, dict):
                    ten_gods_from_bazi[pillar_name] = {
                        'main_star': pillar_detail.get('main_star', ''),
                        'hidden_stars': pillar_detail.get('hidden_stars', [])
                    }
            if any(ten_gods_from_bazi.values()):
                return ten_gods_from_bazi
        
        return {}
    
    # âš ï¸ ä¿®å¤ï¼šä» wangshuai_result ä¸­æ­£ç¡®æå–æ—ºè¡°æ•°æ®
    wangshuai_data = extract_wangshuai_data(wangshuai_result)
    wangshuai_str = wangshuai_data.get('wangshuai', '') if isinstance(wangshuai_data, dict) else str(wangshuai_data) if wangshuai_data else ''
    wangshuai_detail_str = wangshuai_data.get('wangshuai_detail', wangshuai_data.get('detail', '')) if isinstance(wangshuai_data, dict) else ''
    
    # âš ï¸ ä¿®å¤ï¼šä» detail_result æˆ– bazi_data ä¸­æå–åç¥æ•°æ®
    ten_gods_extracted = extract_ten_gods_data(detail_result, bazi_data)
    # å¦‚æœæå–çš„åç¥æ•°æ®ä¸ºç©ºï¼Œä½¿ç”¨åŸæœ‰çš„ ten_gods_full
    if not ten_gods_extracted:
        ten_gods_extracted = ten_gods_full
    
    # âš ï¸ ä¼˜åŒ–ï¼šä½¿ç”¨å·¥å…·å‡½æ•°è®¡ç®—å¹´é¾„å’Œå½“å‰å¤§è¿ï¼ˆä¸æ’ç›˜ç³»ç»Ÿä¸€è‡´ï¼‰
    birth_date = bazi_data.get('basic_info', {}).get('solar_date', '') or solar_date
    current_age = 0
    birth_year = None
    if birth_date:
        current_age = calculate_user_age(birth_date)
        try:
            birth_year = int(birth_date.split('-')[0])
        except:
            pass
    
    # è·å–å½“å‰å¤§è¿ï¼ˆä¸æ’ç›˜ç³»ç»Ÿä¸€è‡´ï¼‰
    current_dayun_info = get_current_dayun(dayun_sequence, current_age)
    
    # âš ï¸ ä¼˜åŒ–ï¼šä½¿ç”¨å·¥å…·å‡½æ•°æ„å»ºå¢å¼ºçš„å¤§è¿æµå¹´ç»“æ„ï¼ˆåŒ…å«ä¼˜å…ˆçº§ã€æè¿°ã€å¤‡æ³¨ç­‰ï¼‰
    if special_liunians is None:
        special_liunians = []
    
    enhanced_dayun_structure = build_enhanced_dayun_structure(
        dayun_sequence=dayun_sequence,
        special_liunians=special_liunians,
        current_age=current_age,
        current_dayun=current_dayun_info,
        birth_year=birth_year
    )
    
    # âš ï¸ ä¼˜åŒ–ï¼šæ·»åŠ åå¤„ç†å‡½æ•°ï¼ˆæ¸…ç†æµæœˆæµæ—¥å­—æ®µï¼Œé™åˆ¶æµå¹´æ•°é‡ï¼‰
    def clean_liunian_data(liunian: Dict[str, Any]) -> Dict[str, Any]:
        """æ¸…ç†æµå¹´æ•°æ®ï¼šç§»é™¤æµæœˆæµæ—¥å­—æ®µï¼Œä¿ç•™ relations å’Œ dayun_step å­—æ®µ"""
        cleaned = liunian.copy()
        fields_to_remove = ['liuyue_sequence', 'liuri_sequence', 'liushi_sequence']
        for field in fields_to_remove:
            cleaned.pop(field, None)
        # âš ï¸ å…³é”®ï¼šç¡®ä¿ relations å’Œ dayun_step å­—æ®µè¢«ä¿ç•™
        if 'relations' not in cleaned:
            cleaned['relations'] = liunian.get('relations', [])
        if 'dayun_step' not in cleaned:
            cleaned['dayun_step'] = liunian.get('dayun_step')
        if 'dayun_ganzhi' not in cleaned:
            cleaned['dayun_ganzhi'] = liunian.get('dayun_ganzhi', '')
        return cleaned
    
    # âš ï¸ ä¿®æ”¹ï¼šä¸å†é™åˆ¶æµå¹´æ•°é‡ï¼Œä¼˜å…ˆçº§åªç”¨äºæ’åºï¼Œæ‰€æœ‰ç‰¹æ®Šæµå¹´éƒ½è¦æ˜¾ç¤º
    # æå–å½“å‰å¤§è¿æ•°æ®ï¼ˆä¼˜å…ˆçº§1ï¼‰
    current_dayun_enhanced = enhanced_dayun_structure.get('current_dayun')
    current_dayun_data = None
    if current_dayun_enhanced:
        raw_liunians = current_dayun_enhanced.get('liunians', [])
        cleaned_liunians = [clean_liunian_data(liunian) for liunian in raw_liunians]
        # âš ï¸ ä¸å†é™åˆ¶æ•°é‡ï¼Œæ‰€æœ‰æµå¹´éƒ½æ˜¾ç¤ºï¼ŒæŒ‰ä¼˜å…ˆçº§æ’åº
        all_liunians = sorted(cleaned_liunians, key=lambda x: x.get('priority', 999999))
        
        current_dayun_data = {
            'step': str(current_dayun_enhanced.get('step', '')),
            'stem': current_dayun_enhanced.get('gan', current_dayun_enhanced.get('stem', '')),
            'branch': current_dayun_enhanced.get('zhi', current_dayun_enhanced.get('branch', '')),
            'age_display': current_dayun_enhanced.get('age_display', current_dayun_enhanced.get('age_range', '')),
            'main_star': current_dayun_enhanced.get('main_star', ''),
            'priority': current_dayun_enhanced.get('priority', 1),
            'life_stage': current_dayun_enhanced.get('life_stage', ''),
            'description': current_dayun_enhanced.get('description', ''),
            'note': current_dayun_enhanced.get('note', ''),
            'liunians': all_liunians  # âš ï¸ ä½¿ç”¨å…¨éƒ¨æµå¹´ï¼Œä¸é™åˆ¶æ•°é‡
        }
    
    # æå–å…³é”®å¤§è¿æ•°æ®ï¼ˆä¼˜å…ˆçº§2-10ï¼‰
    key_dayuns_enhanced = enhanced_dayun_structure.get('key_dayuns', [])
    key_dayuns_data = []
    for key_dayun in key_dayuns_enhanced:
        raw_liunians = key_dayun.get('liunians', [])
        cleaned_liunians = [clean_liunian_data(liunian) for liunian in raw_liunians]
        # âš ï¸ ä¸å†é™åˆ¶æ•°é‡ï¼Œæ‰€æœ‰æµå¹´éƒ½æ˜¾ç¤ºï¼ŒæŒ‰ä¼˜å…ˆçº§æ’åº
        all_liunians_for_dayun = sorted(cleaned_liunians, key=lambda x: x.get('priority', 999999))
        
        key_dayuns_data.append({
            'step': str(key_dayun.get('step', '')),
            'stem': key_dayun.get('gan', key_dayun.get('stem', '')),
            'branch': key_dayun.get('zhi', key_dayun.get('branch', '')),
            'age_display': key_dayun.get('age_display', key_dayun.get('age_range', '')),
            'main_star': key_dayun.get('main_star', ''),
            'priority': key_dayun.get('priority', 999),
            'life_stage': key_dayun.get('life_stage', ''),
            'description': key_dayun.get('description', ''),
            'note': key_dayun.get('note', ''),
            'liunians': all_liunians_for_dayun  # âš ï¸ ä½¿ç”¨å…¨éƒ¨æµå¹´ï¼Œä¸é™åˆ¶æ•°é‡
        })
    
    # åˆ†æå¤§è¿æµå¹´å†²åˆåˆ‘å®³
    chonghe_xinghai = analyze_chonghe_xinghai(bazi_pillars, dayun_sequence, detail_result)
    
    # âš ï¸ ä½¿ç”¨ä¼ å…¥çš„ç‰¹æ®Šæµå¹´ï¼ˆå·²åœ¨å¤–éƒ¨é€šè¿‡ BaziDisplayService.get_fortune_display è·å–å¹¶ç­›é€‰ï¼‰
    if special_liunians is None:
        special_liunians = []
    
    # ========== é˜¶æ®µ5ï¼šæ£€æŸ¥ special_liunians æ˜¯å¦æ­£ç¡®ä¼ é€’åˆ° build_general_review_input_data ==========
    logger.info(f"[é˜¶æ®µ5] âœ… build_general_review_input_data æ¥æ”¶åˆ°çš„ special_liunians æ•°é‡: {len(special_liunians)}")
    logger.info(f"[é˜¶æ®µ5] æ¥æ”¶åˆ°çš„ç‰¹æ®Šæµå¹´æ•°é‡: {len(special_liunians)}")
    if special_liunians:
        special_liunian_strs = [f"{l.get('year', '')}å¹´{l.get('ganzhi', '')}" for l in special_liunians[:5]]
        logger.info(f"[é˜¶æ®µ5] special_liunians å†…å®¹: {special_liunian_strs}")
    else:
        logger.info(f"[é˜¶æ®µ5] âš ï¸ special_liunians ä¸ºç©º")
    
    # æå–åç¥å¯¹æ€§æ ¼çš„å½±å“
    ten_gods_effect = analyze_ten_gods_effect(ten_gods_data, ten_gods_full)
    
    # æå–å¥åº·ç›¸å…³æ•°æ®
    wuxing_balance = health_result.get('wuxing_balance', {}) if health_result else {}
    zangfu_duiying = health_result.get('body_algorithm', {}) if health_result else {}
    jiankang_ruodian = health_result.get('pathology_tendency', {}) if health_result else {}
    
    # âš ï¸ æå–å–œå¿Œæ•°æ®ï¼ˆä¼˜å…ˆä½¿ç”¨ xishen_jishen_resultï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨ wangshuai_result ä½œä¸ºé™çº§ï¼‰
    xi_ji_data = extract_xi_ji_data(xishen_jishen_result, wangshuai_result)
    
    # æ„å»ºæ–¹ä½é€‰æ‹©ã€è¡Œä¸šé€‰æ‹©ç­‰å»ºè®®
    # âš ï¸ ä½¿ç”¨æ–°çš„å–œå¿Œç»“æ„
    xishen_wuxing = xi_ji_data.get('xishen_wuxing', [])
    jishen_wuxing = xi_ji_data.get('jishen_wuxing', [])
    fangwei_xuanze = get_directions_from_elements(xishen_wuxing, jishen_wuxing)
    hangye_xuanze = get_industries_from_elements(xishen_wuxing, jishen_wuxing)
    
    # å»æ‰è°ƒå€™ä¿¡æ¯ï¼ˆtiaohouï¼‰- ä¸ä¿®æ”¹åº•å±‚å‡½æ•°ï¼Œåªåœ¨è¿™é‡Œå»æ‰
    xi_ji_xishen = xi_ji_data.get('xishen', {})
    xi_ji_jishen = xi_ji_data.get('jishen', {})
    xishen_without_tiaohou = {k: v for k, v in xi_ji_xishen.items() if k != 'tiaohou'}
    jishen_without_tiaohou = {k: v for k, v in xi_ji_jishen.items() if k != 'tiaohou'}
    
    # æ„å»ºå®Œæ•´çš„input_data
    input_data = {
        # 1. å‘½ç›˜æ ¸å¿ƒæ ¼å±€
        'mingpan_hexin_geju': {
            'day_master': day_pillar,
            'bazi_pillars': bazi_pillars,
            'ten_gods': ten_gods_extracted,  # âš ï¸ ä½¿ç”¨æå–çš„åç¥æ•°æ®
            'wangshuai': wangshuai_str,  # âš ï¸ ä½¿ç”¨æå–çš„æ—ºè¡°æ•°æ®
            'wangshuai_detail': wangshuai_detail_str,  # âš ï¸ ä½¿ç”¨æå–çš„æ—ºè¡°è¯¦ç»†æ•°æ®
            'yue_ling': yue_ling,
            'geju_type': geju_type,
            'wuxing_liutong': wuxing_liutong
        },
        
        # 2. æ€§æ ¼ç‰¹è´¨
        'xingge_tezhi': {
            'day_master_personality': personality_result.get('descriptions', []) if personality_result else [],
            'rizhu_algorithm': rizhu_result.get('analysis', '') if rizhu_result else '',
            'ten_gods_effect': ten_gods_effect
        },
        
        # 3. äº‹ä¸šè´¢è¿è½¨è¿¹
        'shiye_caiyun': {
            'shiye_xing': shiye_xing,
            'caifu_xing': caifu_xing,
            'dayun_effect': dayun_effect
        },
        
        # 4. å®¶åº­å…­äº²å…³ç³»
        'jiating_liuqin': {
            'year_pillar': bazi_pillars.get('year', {}),
            'month_pillar': bazi_pillars.get('month', {}),
            'day_pillar': bazi_pillars.get('day', {}),
            'hour_pillar': bazi_pillars.get('hour', {})
        },
        
        # 5. å¥åº·è¦ç‚¹
        'jiankang_yaodian': {
            'wuxing_balance': wuxing_balance,
            'zangfu_duiying': zangfu_duiying,
            'jiankang_ruodian': jiankang_ruodian
        },
        
        # 6. å…³é”®å¤§è¿ä¸äººç”ŸèŠ‚ç‚¹
        'guanjian_dayun': {
            'current_dayun': current_dayun_data,  # âš ï¸ ä½¿ç”¨å¢å¼ºçš„å½“å‰å¤§è¿æ•°æ®
            'key_dayuns': key_dayuns_data,  # âš ï¸ ä½¿ç”¨å¢å¼ºçš„å…³é”®å¤§è¿æ•°æ®ï¼ˆä¼˜å…ˆçº§2-10ï¼‰
            'dayun_sequence': dayun_sequence,  # âš ï¸ å®Œæ•´çš„å¤§è¿åºåˆ—ï¼ˆä¿ç•™ç”¨äºå…¼å®¹ï¼‰
            'chonghe_xinghai': chonghe_xinghai
        },
        
        # 7. ç»ˆç”Ÿæç‚¹ä¸å»ºè®®
        'zhongsheng_tidian': {
            'xishen': xishen_without_tiaohou,  # å»æ‰ tiaohou
            'jishen': jishen_without_tiaohou,  # å»æ‰ tiaohouï¼ˆé˜²å¾¡æ€§ï¼‰
            'xishen_wuxing': xi_ji_data.get('xishen_wuxing', []),
            'jishen_wuxing': xi_ji_data.get('jishen_wuxing', []),
            'fangwei_xuanze': fangwei_xuanze,
            'hangye_xuanze': hangye_xuanze,
            'xiushen_jianyi': {},  # ä¿®èº«å»ºè®®å¯ä»¥åŸºäºæ ¼å±€å’Œæ€§æ ¼ç”Ÿæˆ
            'fengshui_tiaojie': {}  # é£æ°´è°ƒèŠ‚å¯ä»¥åŸºäºäº”è¡Œå¹³è¡¡ç”Ÿæˆ
        },
        
        # 8. æ—¥æŸ±æ€§å‘½è§£æï¼ˆæ–°å¢ï¼šå®Œæ•´çš„æ—¥æŸ±æ€§æ ¼ä¸å‘½è¿åˆ†ææ•°æ®ï¼‰
        'rizhu_xinming_jiexi': _build_rizhu_xinming_node(day_pillar, gender, personality_result)
    }
    
    # âš ï¸ DEBUG: æ·»åŠ è°ƒè¯•ä¿¡æ¯ï¼ˆç”¨äºæ’æŸ¥ç‰¹æ®Šæµå¹´é—®é¢˜ï¼‰
    input_data['_debug'] = {
        'solar_date': solar_date,
        'solar_time': solar_time,
        'gender': gender,
        'dayun_count': len(dayun_sequence),
        'special_liunian_count': len(special_liunians)
    }
    
    return input_data


def extract_xi_ji_data(xishen_jishen_result: Any, wangshuai_result: Dict[str, Any] = None) -> Dict[str, Any]:
    """
    ä» xishen_jishen_result å’Œ wangshuai_result ä¸­æå–å–œå¿Œæ•°æ®ï¼Œå¹¶è½¬æ¢ä¸ºåˆ†ç¦»çš„æ ‡å‡†æ ¼å¼
    
    âš ï¸ ä¼˜å…ˆä½¿ç”¨ xishen_jishen_resultï¼ˆäº”è¡Œï¼‰å’Œ wangshuai_resultï¼ˆåç¥ï¼‰çš„ç»„åˆ
    
    Args:
        xishen_jishen_result: get_xishen_jishen() çš„è¿”å›ç»“æœï¼ˆå¯èƒ½æ˜¯ XishenJishenResponse æˆ–å­—å…¸ï¼‰
        wangshuai_result: æ—ºè¡°åˆ†æç»“æœï¼ˆç”¨äºè·å–åç¥å–œå¿Œå’Œè°ƒå€™ä¿¡æ¯ï¼‰
    
    Returns:
        dict: åˆ†ç¦»çš„å–œå¿Œæ•°æ®ç»“æ„
            {
                'xishen': {'shishen': [...], 'wuxing': [...], 'tiaohou': {...}},
                'jishen': {'shishen': [...], 'wuxing': [...]},
                'xishen_wuxing': [...],  # ç‹¬ç«‹å­—æ®µ
                'jishen_wuxing': [...]   # ç‹¬ç«‹å­—æ®µ
            }
    """
    # åˆå§‹åŒ–å˜é‡
    xi_shen = []
    ji_shen = []
    xi_shen_elements = []
    ji_shen_elements = []
    tiaohou_info = {}
    
    # 1. å¤„ç† xishen_jishen_resultï¼ˆæå–äº”è¡Œï¼‰
    if xishen_jishen_result:
        # æ”¯æŒå­—å…¸æ ¼å¼ï¼ˆç»Ÿä¸€æ¥å£è¿”å›ï¼‰
        if isinstance(xishen_jishen_result, dict) and 'success' in xishen_jishen_result:
            if xishen_jishen_result.get('success') and xishen_jishen_result.get('data'):
                data = xishen_jishen_result['data']
                
                # æå–äº”è¡Œåˆ—è¡¨ï¼ˆä»å¸¦IDçš„æ ¼å¼è½¬æ¢ä¸ºçº¯åç§°åˆ—è¡¨ï¼‰
                xi_shen_elements = [e['name'] for e in data.get('xi_shen_elements', []) if isinstance(e, dict) and 'name' in e]
                ji_shen_elements = [e['name'] for e in data.get('ji_shen_elements', []) if isinstance(e, dict) and 'name' in e]
                
                logger.info(f"âœ… [å–œå¿Œæ•°æ®] ä» xishen_jishen_result æå–äº”è¡Œ: å–œç¥={xi_shen_elements}, å¿Œç¥={ji_shen_elements}")
        
        # æ”¯æŒ Pydantic å¯¹è±¡æ ¼å¼
        elif hasattr(xishen_jishen_result, 'success') and xishen_jishen_result.success:
            if xishen_jishen_result.data:
                data = xishen_jishen_result.data
                
                # æå–äº”è¡Œåˆ—è¡¨
                xi_shen_elements = [e['name'] for e in data.get('xi_shen_elements', []) if isinstance(e, dict) and 'name' in e]
                ji_shen_elements = [e['name'] for e in data.get('ji_shen_elements', []) if isinstance(e, dict) and 'name' in e]
                
                logger.info(f"âœ… [å–œå¿Œæ•°æ®] ä» xishen_jishen_resultï¼ˆPydanticï¼‰æå–äº”è¡Œ: å–œç¥={xi_shen_elements}, å¿Œç¥={ji_shen_elements}")
    
    # 2. å¤„ç† wangshuai_resultï¼ˆæå–åç¥å’Œè°ƒå€™ä¿¡æ¯ï¼‰
    if wangshuai_result:
        xi_shen = wangshuai_result.get('xi_shen', [])
        ji_shen = wangshuai_result.get('ji_shen', [])
        
        # å¦‚æœäº”è¡Œæ•°æ®ä¸ºç©ºï¼Œä» wangshuai_result è·å–
        if not xi_shen_elements:
            xi_shen_elements = wangshuai_result.get('xi_shen_elements', [])
        if not ji_shen_elements:
            ji_shen_elements = wangshuai_result.get('ji_shen_elements', [])
        
        # æå–è°ƒå€™ä¿¡æ¯
        final_xi_ji = wangshuai_result.get('final_xi_ji', {})
        if final_xi_ji:
            tiaohou_info = {
                'first_xishen': final_xi_ji.get('first_xi_shen', []) or final_xi_ji.get('first_xishen', []),
                'priority': final_xi_ji.get('tiaohou_priority', ''),
                'description': final_xi_ji.get('analysis', '') or final_xi_ji.get('description', ''),
                'recommendations': final_xi_ji.get('recommendations', [])
            }
        
        logger.info(f"âœ… [å–œå¿Œæ•°æ®] ä» wangshuai_result æå–åç¥: å–œç¥={xi_shen}, å¿Œç¥={ji_shen}")
    
    # 3. è¿”å›åˆ†ç¦»çš„å–œå¿Œç»“æ„
    result = {
        'xishen': {
            'shishen': xi_shen,
            'wuxing': xi_shen_elements,
            'tiaohou': tiaohou_info
        },
        'jishen': {
            'shishen': ji_shen,
            'wuxing': ji_shen_elements
        },
        'xishen_wuxing': xi_shen_elements,  # ç‹¬ç«‹å­—æ®µ
        'jishen_wuxing': ji_shen_elements   # ç‹¬ç«‹å­—æ®µ
    }
    
    logger.info(f"âœ… [å–œå¿Œæ•°æ®] è¿”å›åˆ†ç¦»ç»“æ„: xishen.shishen={len(xi_shen)}, xishen.wuxing={len(xi_shen_elements)}, jishen.shishen={len(ji_shen)}, jishen.wuxing={len(ji_shen_elements)}")
    
    return result


def determine_geju_type(month_branch: str, ten_gods_full: dict, wangshuai_result: dict) -> str:
    """
    åˆ¤æ–­æ ¼å±€ç±»å‹
    åŸºäºæœˆä»¤å’Œåç¥é…ç½®åˆ¤æ–­æ ¼å±€ç±»å‹ï¼ˆæ­£å®˜æ ¼ã€ä¸ƒæ€æ ¼ã€æ­£è´¢æ ¼ã€åè´¢æ ¼ã€é£Ÿç¥æ ¼ã€ä¼¤å®˜æ ¼ç­‰ï¼‰
    """
    try:
        # ä»æ—ºè¡°ç»“æœä¸­è·å–æ ¼å±€ç±»å‹
        geju = wangshuai_result.get('geju_type', '')
        if geju:
            return geju
        
        # å¦‚æœæ²¡æœ‰ï¼ŒåŸºäºæœˆä»¤å’Œåç¥åˆ¤æ–­
        month_pillar_ten_gods = ten_gods_full.get('month', {})
        if month_pillar_ten_gods:
            main_star = month_pillar_ten_gods.get('main_star', '')
            if main_star:
                # åŸºäºæœˆæŸ±ä¸»æ˜Ÿåˆ¤æ–­æ ¼å±€
                geju_map = {
                    'æ­£å®˜': 'æ­£å®˜æ ¼',
                    'ä¸ƒæ€': 'ä¸ƒæ€æ ¼',
                    'åå®˜': 'ä¸ƒæ€æ ¼',
                    'æ­£è´¢': 'æ­£è´¢æ ¼',
                    'åè´¢': 'åè´¢æ ¼',
                    'é£Ÿç¥': 'é£Ÿç¥æ ¼',
                    'ä¼¤å®˜': 'ä¼¤å®˜æ ¼',
                    'æ­£å°': 'æ­£å°æ ¼',
                    'åå°': 'åå°æ ¼'
                }
                return geju_map.get(main_star, '')
        
        return ''
    except Exception as e:
        logger.warning(f"åˆ¤æ–­æ ¼å±€ç±»å‹å¤±è´¥: {e}")
        return ''


def analyze_wuxing_liutong(element_counts: dict, bazi_pillars: dict) -> dict:
    """
    åˆ†æäº”è¡Œæµé€šæƒ…å†µ
    åŸºäºäº”è¡Œç»Ÿè®¡å’Œç”Ÿå…‹å…³ç³»åˆ†æäº”è¡Œæµé€š
    """
    try:
        from core.data.constants import STEM_ELEMENTS, BRANCH_ELEMENTS
        
        # äº”è¡Œç”Ÿå…‹å…³ç³»
        ELEMENT_RELATIONS = {
            'æœ¨': {'produces': 'ç«', 'controls': 'åœŸ', 'produced_by': 'æ°´', 'controlled_by': 'é‡‘'},
            'ç«': {'produces': 'åœŸ', 'controls': 'é‡‘', 'produced_by': 'æœ¨', 'controlled_by': 'æ°´'},
            'åœŸ': {'produces': 'é‡‘', 'controls': 'æ°´', 'produced_by': 'ç«', 'controlled_by': 'æœ¨'},
            'é‡‘': {'produces': 'æ°´', 'controls': 'æœ¨', 'produced_by': 'åœŸ', 'controlled_by': 'ç«'},
            'æ°´': {'produces': 'æœ¨', 'controls': 'ç«', 'produced_by': 'é‡‘', 'controlled_by': 'åœŸ'}
        }
        
        # ç»Ÿè®¡äº”è¡Œæ•°é‡
        wuxing_count = {
            'æœ¨': element_counts.get('æœ¨', 0),
            'ç«': element_counts.get('ç«', 0),
            'åœŸ': element_counts.get('åœŸ', 0),
            'é‡‘': element_counts.get('é‡‘', 0),
            'æ°´': element_counts.get('æ°´', 0)
        }
        
        # åˆ†ææµé€šæƒ…å†µ
        circulation_paths = []
        strong_elements = [e for e, count in wuxing_count.items() if count >= 2]
        weak_elements = [e for e, count in wuxing_count.items() if count == 0]
        
        # åˆ†æä¸»è¦æµé€šè·¯å¾„
        for element in ['æœ¨', 'ç«', 'åœŸ', 'é‡‘', 'æ°´']:
            if wuxing_count[element] > 0:
                produces = ELEMENT_RELATIONS[element]['produces']
                if wuxing_count[produces] > 0:
                    circulation_paths.append(f"{element}ç”Ÿ{produces}")
        
        summary = ""
        if strong_elements:
            summary += f"å¼ºæ—ºäº”è¡Œï¼š{'ã€'.join(strong_elements)}ï¼›"
        if weak_elements:
            summary += f"ç¼ºå¤±äº”è¡Œï¼š{'ã€'.join(weak_elements)}ï¼›"
        if circulation_paths:
            summary += f"æµé€šè·¯å¾„ï¼š{'ã€'.join(circulation_paths[:3])}"
        
        return {
            'wuxing_count': wuxing_count,
            'strong_elements': strong_elements,
            'weak_elements': weak_elements,
            'circulation_paths': circulation_paths,
            'summary': summary
        }
    except Exception as e:
        logger.warning(f"åˆ†æäº”è¡Œæµé€šå¤±è´¥: {e}")
        return {}


def extract_career_star(ten_gods_stats: dict) -> dict:
    """
    æå–äº‹ä¸šæ˜Ÿä¿¡æ¯
    äº‹ä¸šæ˜Ÿï¼šæ­£å®˜ã€ä¸ƒæ€ã€æ­£å°ã€åå°
    """
    result = {
        'primary': '',
        'secondary': '',
        'positions': [],
        'strength': '',
        'description': ''
    }
    
    zhengguan = ten_gods_stats.get('æ­£å®˜', 0)
    qisha = ten_gods_stats.get('ä¸ƒæ€', 0) + ten_gods_stats.get('åå®˜', 0)
    zhengyin = ten_gods_stats.get('æ­£å°', 0)
    pianyin = ten_gods_stats.get('åå°', 0)
    
    # ç¡®å®šä¸»è¦äº‹ä¸šæ˜Ÿ
    if zhengguan > 0 or qisha > 0:
        if zhengguan >= qisha:
            result['primary'] = 'æ­£å®˜'
            if qisha > 0:
                result['secondary'] = 'ä¸ƒæ€'
        else:
            result['primary'] = 'ä¸ƒæ€'
            if zhengguan > 0:
                result['secondary'] = 'æ­£å®˜'
    elif zhengyin > 0 or pianyin > 0:
        if zhengyin >= pianyin:
            result['primary'] = 'æ­£å°'
        else:
            result['primary'] = 'åå°'
    
    return result


def extract_wealth_star(ten_gods_stats: dict) -> dict:
    """
    æå–è´¢å¯Œæ˜Ÿä¿¡æ¯
    è´¢å¯Œæ˜Ÿï¼šæ­£è´¢ã€åè´¢
    """
    result = {
        'primary': '',
        'positions': [],
        'strength': '',
        'description': ''
    }
    
    zhengcai = ten_gods_stats.get('æ­£è´¢', 0)
    piancai = ten_gods_stats.get('åè´¢', 0)
    
    if zhengcai > 0 or piancai > 0:
        if zhengcai >= piancai:
            result['primary'] = 'æ­£è´¢'
        else:
            result['primary'] = 'åè´¢'
    
    return result


def analyze_dayun_effect(dayun_sequence: List[dict], shiye_xing: dict, caifu_xing: dict, ten_gods_stats: dict) -> dict:
    """
    åˆ†æå¤§è¿å¯¹äº‹ä¸šè´¢è¿çš„å½±å“
    
    âš ï¸ åŒ…å«æ‰€æœ‰å¤§è¿é˜¶æ®µï¼ˆè‡³å°‘å‰7æ­¥ï¼‰ï¼Œç¡®ä¿ä¸é—æ¼ä»»ä½•å¤§è¿
    """
    try:
        result = {
            'career_effects': [],
            'wealth_effects': [],
            'all_dayuns': [],  # âš ï¸ æ–°å¢ï¼šåŒ…å«æ‰€æœ‰å¤§è¿çš„å®Œæ•´ä¿¡æ¯
            'summary': ''
        }
        
        # âš ï¸ åˆ†ææ‰€æœ‰å¤§è¿ï¼ˆè‡³å°‘å‰7æ­¥ï¼Œç¡®ä¿ä¸é—æ¼ï¼‰
        max_steps = min(7, len(dayun_sequence))
        for idx in range(max_steps):
            if idx < len(dayun_sequence):
                dayun = dayun_sequence[idx]
                main_star = dayun.get('main_star', '')
                step = dayun.get('step', idx + 1)
                age_display = dayun.get('age_display', '')
                stem = dayun.get('stem', '')
                branch = dayun.get('branch', '')
                
                # âš ï¸ æ·»åŠ æ‰€æœ‰å¤§è¿çš„å®Œæ•´ä¿¡æ¯
                dayun_info = {
                    'step': step,
                    'age_display': age_display,
                    'stem': stem,
                    'branch': branch,
                    'ganzhi': f"{stem}{branch}",
                    'main_star': main_star,
                    'year_start': dayun.get('year_start', 0),
                    'year_end': dayun.get('year_end', 0)
                }
                result['all_dayuns'].append(dayun_info)
                
                # åˆ†æäº‹ä¸šå½±å“ï¼ˆæ‰€æœ‰å¤§è¿éƒ½æ£€æŸ¥ï¼Œä¸åªæ˜¯ç¬¬2-4æ­¥ï¼‰
                if main_star in ['æ­£å®˜', 'ä¸ƒæ€', 'åå®˜', 'æ­£å°', 'åå°']:
                    result['career_effects'].append({
                        'step': step,
                        'age_display': age_display,
                        'main_star': main_star,
                        'ganzhi': f"{stem}{branch}",
                        'effect': f"ç¬¬{step}æ­¥å¤§è¿ï¼ˆ{age_display}ï¼‰ä¸»æ˜Ÿä¸º{main_star}ï¼Œå¯¹äº‹ä¸šæœ‰é‡è¦å½±å“"
                    })
                
                # åˆ†æè´¢è¿å½±å“ï¼ˆæ‰€æœ‰å¤§è¿éƒ½æ£€æŸ¥ï¼Œä¸åªæ˜¯ç¬¬2-4æ­¥ï¼‰
                if main_star in ['æ­£è´¢', 'åè´¢', 'é£Ÿç¥', 'ä¼¤å®˜']:
                    result['wealth_effects'].append({
                        'step': step,
                        'age_display': age_display,
                        'main_star': main_star,
                        'ganzhi': f"{stem}{branch}",
                        'effect': f"ç¬¬{step}æ­¥å¤§è¿ï¼ˆ{age_display}ï¼‰ä¸»æ˜Ÿä¸º{main_star}ï¼Œå¯¹è´¢è¿æœ‰é‡è¦å½±å“"
                    })
        
        # ç”Ÿæˆæ‘˜è¦
        if result['career_effects']:
            result['summary'] += f"äº‹ä¸šå…³é”®å¤§è¿ï¼š{len(result['career_effects'])}æ­¥ï¼›"
        if result['wealth_effects']:
            result['summary'] += f"è´¢è¿å…³é”®å¤§è¿ï¼š{len(result['wealth_effects'])}æ­¥"
        
        logger.info(f"[å¤§è¿åˆ†æ] å…±åˆ†æ {len(result['all_dayuns'])} ä¸ªå¤§è¿é˜¶æ®µï¼Œäº‹ä¸šå½±å“ {len(result['career_effects'])} æ­¥ï¼Œè´¢è¿å½±å“ {len(result['wealth_effects'])} æ­¥")
        
        return result
    except Exception as e:
        logger.warning(f"åˆ†æå¤§è¿å¯¹äº‹ä¸šè´¢è¿çš„å½±å“å¤±è´¥: {e}")
        return {}


def analyze_chonghe_xinghai(bazi_pillars: dict, dayun_sequence: List[dict], detail_result: dict) -> dict:
    """
    åˆ†æå¤§è¿æµå¹´å†²åˆåˆ‘å®³
    """
    try:
        result = {
            'bazi_internal_relations': {},
            'dayun_liunian_relations': [],
            'summary': ''
        }
        
        # åˆ†æå…«å­—å†…éƒ¨å†²åˆåˆ‘å®³ï¼ˆä½¿ç”¨é™æ€æ–¹æ³•ï¼‰
        internal_relations = FortuneRelationAnalyzer._analyze_internal_relations(bazi_pillars)
        result['bazi_internal_relations'] = internal_relations
        
        # åˆ†æå¤§è¿ä¸æµå¹´çš„å…³ç³»ï¼ˆéœ€è¦è¿›ä¸€æ­¥å®ç°ï¼‰
        # è¿™é‡Œå¯ä»¥åŸºäºdetail_resultä¸­çš„æµå¹´æ•°æ®è¿›è¡Œåˆ†æ
        
        # ç”Ÿæˆæ‘˜è¦
        if internal_relations.get('chong_details'):
            result['summary'] += f"å†²ï¼š{len(internal_relations['chong_details'])}å¤„ï¼›"
        if internal_relations.get('he_details'):
            result['summary'] += f"åˆï¼š{len(internal_relations['he_details'])}å¤„ï¼›"
        if internal_relations.get('xing_details'):
            result['summary'] += f"åˆ‘ï¼š{len(internal_relations['xing_details'])}å¤„"
        
        return result
    except Exception as e:
        logger.warning(f"åˆ†æå¤§è¿æµå¹´å†²åˆåˆ‘å®³å¤±è´¥: {e}")
        return {}


def analyze_ten_gods_effect(ten_gods_stats: dict, ten_gods_full: dict) -> dict:
    """
    åˆ†æåç¥å¯¹æ€§æ ¼çš„å½±å“
    """
    try:
        result = {
            'effects': [],
            'summary': ''
        }
        
        # åŸºäºåç¥é…ç½®åˆ†ææ€§æ ¼ç‰¹å¾
        dominant_gods = []
        for god, count in ten_gods_stats.items():
            if count >= 2:
                dominant_gods.append(god)
        
        # åç¥æ€§æ ¼ç‰¹å¾æ˜ å°„
        personality_map = {
            'æ­£å®˜': 'ç¨³é‡ã€æœ‰è´£ä»»æ„Ÿã€éµå®ˆè§„åˆ™',
            'ä¸ƒæ€': 'æœæ–­ã€æœ‰é­„åŠ›ã€å‹‡äºæŒ‘æˆ˜',
            'æ­£å°': 'æ¸©å’Œã€æœ‰çˆ±å¿ƒã€ä¹äºåŠ©äºº',
            'åå°': 'ç‹¬ç«‹æ€è€ƒã€æœ‰åˆ›æ„ã€å†…å‘',
            'æ­£è´¢': 'åŠ¡å®ã€èŠ‚ä¿­ã€é‡è§†ç‰©è´¨',
            'åè´¢': 'çµæ´»ã€å–„äºç†è´¢ã€æ•¢äºæŠ•èµ„',
            'é£Ÿç¥': 'æ¸©å’Œã€æœ‰æ‰åã€å–œæ¬¢äº«å—',
            'ä¼¤å®˜': 'èªæ˜ã€æœ‰æ‰åã€ä¸ªæ€§å¼ æ‰¬',
            'æ¯”è‚©': 'ç‹¬ç«‹ã€è‡ªä¿¡ã€æœ‰ä¸»è§',
            'åŠ«è´¢': 'å†²åŠ¨ã€å¥½èƒœã€æœ‰ç«äº‰åŠ›'
        }
        
        effects = []
        for god in dominant_gods:
            if god in personality_map:
                effects.append(f"{god}ï¼š{personality_map[god]}")
        
        result['effects'] = effects
        if effects:
            result['summary'] = 'ã€'.join(effects)
        
        return result
    except Exception as e:
        logger.warning(f"åˆ†æåç¥å¯¹æ€§æ ¼çš„å½±å“å¤±è´¥: {e}")
        return {}


def get_directions_from_elements(xi_elements: List[str], ji_elements: List[str]) -> dict:
    """æ ¹æ®å–œå¿Œäº”è¡Œè·å–æ–¹ä½å»ºè®®"""
    ELEMENT_DIRECTION = {
        'æœ¨': 'ä¸œæ–¹',
        'ç«': 'å—æ–¹',
        'åœŸ': 'ä¸­å¤®',
        'é‡‘': 'è¥¿æ–¹',
        'æ°´': 'åŒ—æ–¹'
    }
    
    result = {
        'best_directions': [],
        'avoid_directions': [],
        'analysis': ''
    }
    
    for element in xi_elements:
        direction = ELEMENT_DIRECTION.get(element)
        if direction and direction not in result['best_directions']:
            result['best_directions'].append(direction)
    
    for element in ji_elements:
        direction = ELEMENT_DIRECTION.get(element)
        if direction and direction not in result['avoid_directions']:
            result['avoid_directions'].append(direction)
    
    return result


def get_industries_from_elements(xi_elements: List[str], ji_elements: List[str]) -> dict:
    """
    æ ¹æ®å–œå¿Œäº”è¡Œè·å–è¡Œä¸šå»ºè®®ï¼ˆä»æ•°æ®åº“è¯»å–ï¼‰
    
    Args:
        xi_elements: å–œç¥äº”è¡Œåˆ—è¡¨ï¼Œå¦‚ ['é‡‘', 'åœŸ']
        ji_elements: å¿Œç¥äº”è¡Œåˆ—è¡¨ï¼Œå¦‚ ['æœ¨', 'ç«']
    
    Returns:
        dict: {
            'best_industries': [...],      # é€‚åˆçš„è¡Œä¸šåˆ—è¡¨
            'secondary_industries': [],    # æ¬¡è¦è¡Œä¸šï¼ˆé¢„ç•™ï¼‰
            'avoid_industries': [...],     # éœ€è¦é¿å…çš„è¡Œä¸šåˆ—è¡¨
            'analysis': ''                 # åˆ†æè¯´æ˜ï¼ˆé¢„ç•™ï¼‰
        }
    """
    # ä½¿ç”¨ IndustryService ä»æ•°æ®åº“æŸ¥è¯¢è¡Œä¸šæ•°æ®
    return IndustryService.get_industries_by_elements(xi_elements, ji_elements)


def validate_general_review_input_data(data: dict) -> Tuple[bool, str]:
    """
    éªŒè¯è¾“å…¥æ•°æ®å®Œæ•´æ€§ï¼ˆé˜¶æ®µ3ï¼šæ•°æ®éªŒè¯ä¸å®Œæ•´æ€§æ£€æŸ¥ï¼‰
    
    Args:
        data: è¾“å…¥æ•°æ®å­—å…¸
        
    Returns:
        (is_valid, error_message): æ˜¯å¦æœ‰æ•ˆï¼Œé”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœæ— æ•ˆï¼‰
    """
    required_fields = {
        'mingpan_hexin_geju': {
            'bazi_pillars': 'å…«å­—æ’ç›˜',
            'day_master': 'æ—¥ä¸»ä¿¡æ¯',
            'ten_gods': 'åç¥é…ç½®',
            'wangshuai': 'æ—ºè¡°åˆ†æ'
        },
        'xingge_tezhi': {
            # æ€§æ ¼ç‰¹è´¨éƒ¨åˆ†å…è®¸éƒ¨åˆ†ä¸ºç©º
        },
        'shiye_caiyun': {
            # äº‹ä¸šè´¢è¿éƒ¨åˆ†å…è®¸éƒ¨åˆ†ä¸ºç©º
        },
        'jiating_liuqin': {
            'year_pillar': 'å¹´æŸ±',
            'month_pillar': 'æœˆæŸ±',
            'day_pillar': 'æ—¥æŸ±',
            'hour_pillar': 'æ—¶æŸ±'
        },
        'jiankang_yaodian': {
            # å¥åº·è¦ç‚¹éƒ¨åˆ†å…è®¸éƒ¨åˆ†ä¸ºç©º
        },
        'guanjian_dayun': {
            'key_dayuns': 'å…³é”®å¤§è¿åˆ—è¡¨'  # âš ï¸ å·²æ”¹ä¸º key_dayunsï¼ˆä¼˜å…ˆçº§2-10ï¼‰
        },
        'zhongsheng_tidian': {
            'xishen': 'å–œç¥æ•°æ®',
            'jishen': 'å¿Œç¥æ•°æ®'
        }
    }
    
    missing_fields = []
    
    for section, fields in required_fields.items():
        if section not in data:
            missing_fields.append(f"{section}ï¼ˆæ•´ä¸ªéƒ¨åˆ†ç¼ºå¤±ï¼‰")
            continue
            
        section_data = data[section]
        if not isinstance(section_data, dict):
            missing_fields.append(f"{section}ï¼ˆæ ¼å¼é”™è¯¯ï¼Œåº”ä¸ºå­—å…¸ï¼‰")
            continue
            
        for field, field_name in fields.items():
            if field not in section_data:
                missing_fields.append(f"{section}.{field}ï¼ˆ{field_name}ï¼‰")
            elif section_data[field] is None:
                missing_fields.append(f"{section}.{field}ï¼ˆ{field_name}ä¸ºNoneï¼‰")
            elif isinstance(section_data[field], (list, dict)) and len(section_data[field]) == 0:
                # ç©ºåˆ—è¡¨/å­—å…¸å¯èƒ½æ˜¯æ­£å¸¸çš„ï¼ˆå¦‚æ— åŒ¹é…è§„åˆ™ï¼‰ï¼Œä¸æŠ¥é”™
                pass
    
    if missing_fields:
        error_msg = f"æ•°æ®ä¸å®Œæ•´ï¼Œç¼ºå¤±å­—æ®µï¼š{', '.join(missing_fields)}"
        return False, error_msg
    
    return True, ""

# âœ… _simplify_dayun å’Œ format_input_data_for_coze å‡½æ•°å·²ç§»è‡³ server/utils/prompt_builders.py
# é€šè¿‡é¡¶éƒ¨ import å¯¼å…¥ï¼Œç¡®ä¿è¯„æµ‹è„šæœ¬å’Œæµå¼æ¥å£ä½¿ç”¨ç›¸åŒçš„å‡½æ•°
