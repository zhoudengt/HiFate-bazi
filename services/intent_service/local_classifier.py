# -*- coding: utf-8 -*-
"""
æœ¬åœ° BERT æ¨¡å‹åˆ†ç±»å™¨ï¼ˆ50-100msï¼‰
ç”¨äºå¤„ç†ç®€å•é—®é¢˜çš„æ„å›¾è¯†åˆ«
"""
import time
import re
from typing import Dict, Any, Optional, List
from datetime import datetime

from services.intent_service.logger import logger
from services.intent_service.config import INTENT_CATEGORIES, INTENT_TO_RULE_TYPE_MAP

# å°è¯•å¯¼å…¥ transformersï¼ˆå¯é€‰ä¾èµ–ï¼‰
try:
    import torch
    from transformers import AutoTokenizer, AutoModelForSequenceClassification
    TRANSFORMERS_AVAILABLE = True
except ImportError:
    TRANSFORMERS_AVAILABLE = False
    logger.warning("transformers æœªå®‰è£…ï¼Œæœ¬åœ°æ¨¡å‹åŠŸèƒ½å°†ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨å…³é”®è¯å›é€€æ–¹æ¡ˆ")


class LocalIntentClassifier:
    """æœ¬åœ°æ„å›¾åˆ†ç±»å™¨ï¼ˆä½¿ç”¨BERTæ¨¡å‹ï¼‰"""
    
    def __init__(self, model_name: str = "hfl/chinese-roberta-wwm-ext"):
        """
        åˆå§‹åŒ–æœ¬åœ°åˆ†ç±»å™¨
        
        Args:
            model_name: é¢„è®­ç»ƒæ¨¡å‹åç§°
        """
        self.model_name = model_name
        self.tokenizer = None
        self.model = None
        self.device = None
        self.intent_labels = list(INTENT_CATEGORIES.keys())
        self.rule_type_map = INTENT_TO_RULE_TYPE_MAP
        self.model_loaded = False
        
        # ğŸ”´ å¼ºåˆ¶è¦æ±‚ï¼šå¿…é¡»å°è¯•åŠ è½½æœ¬åœ°æ¨¡å‹ï¼Œä¸èƒ½ç›´æ¥é€€å›
        # å³ä½¿ TRANSFORMERS_AVAILABLE = Falseï¼Œä¹Ÿè¦å°è¯•åŠ¨æ€å¯¼å…¥
        if TRANSFORMERS_AVAILABLE:
            try:
                self._load_model()
                if self.model_loaded:
                    logger.info(f"[LocalIntentClassifier] âœ… åˆå§‹åŒ–æˆåŠŸï¼Œæ¨¡å‹: {model_name}")
                else:
                    logger.error(f"[LocalIntentClassifier] âŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œä½†ä¼šç»§ç»­å°è¯•ä½¿ç”¨å…³é”®è¯å›é€€ä½œä¸ºä¸´æ—¶æ–¹æ¡ˆ")
            except Exception as e:
                logger.error(f"[LocalIntentClassifier] âŒ åˆå§‹åŒ–å¼‚å¸¸: {e}", exc_info=True)
                logger.error(f"[LocalIntentClassifier] âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥ï¼Œä½†ä¼šç»§ç»­å°è¯•ä½¿ç”¨å…³é”®è¯å›é€€ä½œä¸ºä¸´æ—¶æ–¹æ¡ˆ")
                self.model_loaded = False
        else:
            # ğŸ”´ å³ä½¿ transformers æœªå®‰è£…ï¼Œä¹Ÿè¦å°è¯•åŠ¨æ€å¯¼å…¥ï¼ˆå¯èƒ½åœ¨ä¸åŒç¯å¢ƒä¸­ï¼‰
            logger.warning(f"[LocalIntentClassifier] âš ï¸ transformersåº“åœ¨å¯¼å…¥æ—¶ä¸å¯ç”¨ï¼Œå°è¯•åŠ¨æ€å¯¼å…¥...")
            try:
                import torch
                from transformers import AutoTokenizer, AutoModelForSequenceClassification
                logger.info(f"[LocalIntentClassifier] âœ… åŠ¨æ€å¯¼å…¥æˆåŠŸï¼Œå¼€å§‹åŠ è½½æ¨¡å‹...")
                self._load_model()
                if self.model_loaded:
                    logger.info(f"[LocalIntentClassifier] âœ… åŠ¨æ€å¯¼å…¥åæ¨¡å‹åŠ è½½æˆåŠŸï¼Œæ¨¡å‹: {model_name}")
                else:
                    logger.error(f"[LocalIntentClassifier] âŒ åŠ¨æ€å¯¼å…¥åæ¨¡å‹åŠ è½½å¤±è´¥ï¼Œå°†ä½¿ç”¨å…³é”®è¯å›é€€ä½œä¸ºä¸´æ—¶æ–¹æ¡ˆ")
            except ImportError as e:
                logger.error(f"[LocalIntentClassifier] âŒ åŠ¨æ€å¯¼å…¥ä¹Ÿå¤±è´¥: {e}")
                logger.error(f"[LocalIntentClassifier] âŒ æ— æ³•ä½¿ç”¨æœ¬åœ°æ¨¡å‹ï¼Œå°†ä½¿ç”¨å…³é”®è¯å›é€€ä½œä¸ºä¸´æ—¶æ–¹æ¡ˆ")
                self.model_loaded = False
            except Exception as e:
                logger.error(f"[LocalIntentClassifier] âŒ åŠ¨æ€å¯¼å…¥ååŠ è½½æ¨¡å‹å¤±è´¥: {e}", exc_info=True)
                self.model_loaded = False
    
    def _load_model(self):
        """åŠ è½½é¢„è®­ç»ƒæ¨¡å‹"""
        try:
            # ä½¿ç”¨CPUï¼ˆæ›´å¿«å¯åŠ¨ï¼Œé€‚åˆå°æ¨¡å‹ï¼‰
            self.device = torch.device("cpu")
            logger.info(f"[LocalIntentClassifier] å¼€å§‹åŠ è½½æ¨¡å‹: {self.model_name}")
            
            # åŠ è½½tokenizer
            logger.info(f"[LocalIntentClassifier] åŠ è½½tokenizer...")
            try:
                self.tokenizer = AutoTokenizer.from_pretrained(
                    self.model_name,
                    cache_dir="./models_cache"
                )
                logger.info(f"[LocalIntentClassifier] âœ… TokenizeråŠ è½½æˆåŠŸ")
            except Exception as e:
                logger.error(f"[LocalIntentClassifier] âŒ TokenizeråŠ è½½å¤±è´¥: {e}", exc_info=True)
                self.model_loaded = False
                return
            
            # ğŸ”´ ä½¿ç”¨åŸºç¡€æ¨¡å‹è¿›è¡Œæ„å›¾åˆ†ç±»ï¼ˆä¸ä¾èµ–å¾®è°ƒï¼‰
            # åŸºç¡€æ¨¡å‹å¯ä»¥ç›´æ¥ç”¨äºæ¨ç†ï¼Œæ— éœ€å¾®è°ƒ
            logger.info(f"[LocalIntentClassifier] åŠ è½½æ¨¡å‹æƒé‡...")
            try:
                self.model = AutoModelForSequenceClassification.from_pretrained(
                    self.model_name,
                    num_labels=len(self.intent_labels),
                    cache_dir="./models_cache"
                )
                self.model.eval()
                self.model.to(self.device)
                self.model_loaded = True
                logger.info(f"[LocalIntentClassifier] âœ… æœ¬åœ°æ¨¡å‹åŠ è½½æˆåŠŸï¼Œæ¨¡å‹æ–‡ä»¶: {self.model_name}")
            except Exception as e:
                logger.error(f"[LocalIntentClassifier] âŒ æ¨¡å‹æƒé‡åŠ è½½å¤±è´¥: {e}", exc_info=True)
                logger.warning(f"[LocalIntentClassifier] å°†ä½¿ç”¨å…³é”®è¯å›é€€æ–¹æ¡ˆ")
                self.model_loaded = False
                
        except ImportError as e:
            logger.error(f"[LocalIntentClassifier] âŒ transformersåº“æœªå®‰è£…: {e}")
            self.model_loaded = False
        except Exception as e:
            logger.error(f"[LocalIntentClassifier] âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}", exc_info=True)
            logger.warning(f"[LocalIntentClassifier] å°†ä½¿ç”¨å…³é”®è¯å›é€€æ–¹æ¡ˆ")
            self.model_loaded = False
    
    def classify(
        self,
        question: str,
        use_keyword_fallback: bool = True
    ) -> Dict[str, Any]:
        """
        ä½¿ç”¨æœ¬åœ°æ¨¡å‹åˆ†ç±»æ„å›¾
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            use_keyword_fallback: å¦‚æœæ¨¡å‹ä¸å¯ç”¨ï¼Œæ˜¯å¦ä½¿ç”¨å…³é”®è¯å›é€€
        
        Returns:
            åˆ†ç±»ç»“æœ
        """
        request_id = f"local_{int(time.time() * 1000)}"
        start_time = time.time()
        
        logger.info(f"[LocalIntentClassifier][{request_id}] ========== å¼€å§‹æœ¬åœ°åˆ†ç±» ==========")
        logger.info(f"[LocalIntentClassifier][{request_id}] ğŸ“¥ è¾“å…¥: question={question}, use_keyword_fallback={use_keyword_fallback}")
        logger.info(f"[LocalIntentClassifier][{request_id}] [çŠ¶æ€æ£€æŸ¥] transformerså¯ç”¨={TRANSFORMERS_AVAILABLE}, æ¨¡å‹å·²åŠ è½½={self.model_loaded}")
        
        # ğŸ”´ å¼ºåˆ¶è¦æ±‚ï¼šå¿…é¡»å°è¯•ä½¿ç”¨æœ¬åœ°æ¨¡å‹ï¼Œä¸èƒ½ç›´æ¥é€€å›
        # å¦‚æœæ¨¡å‹ä¸å¯ç”¨ï¼Œå°è¯•åŠ¨æ€åŠ è½½
        if not TRANSFORMERS_AVAILABLE:
            logger.warning(f"[LocalIntentClassifier][{request_id}] âš ï¸ transformersåº“åœ¨å¯¼å…¥æ—¶ä¸å¯ç”¨ï¼Œå°è¯•åŠ¨æ€å¯¼å…¥...")
            try:
                import torch
                from transformers import AutoTokenizer, AutoModelForSequenceClassification
                logger.info(f"[LocalIntentClassifier][{request_id}] âœ… åŠ¨æ€å¯¼å…¥æˆåŠŸï¼Œå°è¯•åŠ è½½æ¨¡å‹...")
                if not self.model_loaded:
                    self._load_model()
                if self.model_loaded:
                    logger.info(f"[LocalIntentClassifier][{request_id}] âœ… åŠ¨æ€å¯¼å…¥åæ¨¡å‹åŠ è½½æˆåŠŸï¼Œç»§ç»­ä½¿ç”¨æ¨¡å‹")
                else:
                    logger.error(f"[LocalIntentClassifier][{request_id}] âŒ åŠ¨æ€å¯¼å…¥åæ¨¡å‹åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨å…³é”®è¯å›é€€")
                    if use_keyword_fallback:
                        return self._keyword_based_classify(question, start_time, request_id)
            except ImportError as e:
                logger.error(f"[LocalIntentClassifier][{request_id}] âŒ åŠ¨æ€å¯¼å…¥å¤±è´¥: {e}ï¼Œä½¿ç”¨å…³é”®è¯å›é€€")
                if use_keyword_fallback:
                    return self._keyword_based_classify(question, start_time, request_id)
            except Exception as e:
                logger.error(f"[LocalIntentClassifier][{request_id}] âŒ åŠ¨æ€å¯¼å…¥ååŠ è½½æ¨¡å‹å¤±è´¥: {e}ï¼Œä½¿ç”¨å…³é”®è¯å›é€€", exc_info=True)
                if use_keyword_fallback:
                    return self._keyword_based_classify(question, start_time, request_id)
        
        # ğŸ”´ å¦‚æœæ¨¡å‹æœªåŠ è½½ï¼Œå°è¯•é‡æ–°åŠ è½½
        if not self.model_loaded or self.model is None:
            logger.warning(f"[LocalIntentClassifier][{request_id}] âš ï¸ æ¨¡å‹æœªåŠ è½½ (model_loaded={self.model_loaded})ï¼Œå°è¯•é‡æ–°åŠ è½½...")
            try:
                self._load_model()
                if self.model_loaded:
                    logger.info(f"[LocalIntentClassifier][{request_id}] âœ… é‡æ–°åŠ è½½æ¨¡å‹æˆåŠŸï¼Œç»§ç»­ä½¿ç”¨æ¨¡å‹")
                else:
                    logger.error(f"[LocalIntentClassifier][{request_id}] âŒ é‡æ–°åŠ è½½æ¨¡å‹å¤±è´¥ï¼Œä½¿ç”¨å…³é”®è¯å›é€€")
                    if use_keyword_fallback:
                        return self._keyword_based_classify(question, start_time, request_id)
            except Exception as e:
                logger.error(f"[LocalIntentClassifier][{request_id}] âŒ é‡æ–°åŠ è½½æ¨¡å‹å¼‚å¸¸: {e}ï¼Œä½¿ç”¨å…³é”®è¯å›é€€", exc_info=True)
                if use_keyword_fallback:
                    return self._keyword_based_classify(question, start_time, request_id)
        
        try:
            # ä½¿ç”¨æ¨¡å‹åˆ†ç±»
            logger.info(f"[LocalIntentClassifier][{request_id}] [æ¨¡å‹æ¨ç†] å¼€å§‹ä½¿ç”¨BERTæ¨¡å‹åˆ†ç±»...")
            result = self._model_classify(question, start_time, request_id)
            result["method"] = "local_model"
            total_time = int((time.time() - start_time) * 1000)
            logger.info(f"[LocalIntentClassifier][{request_id}] ========== æœ¬åœ°åˆ†ç±»å®Œæˆ ==========")
            logger.info(f"[LocalIntentClassifier][{request_id}] ğŸ“Š æ€»è€—æ—¶: {total_time}ms")
            logger.info(f"[LocalIntentClassifier][{request_id}] ğŸ“¤ æœ€ç»ˆè¾“å‡º: {result}")
            return result
        except Exception as e:
            logger.error(f"[LocalIntentClassifier][{request_id}] âŒ æ¨¡å‹åˆ†ç±»å¤±è´¥: {e}", exc_info=True)
            if use_keyword_fallback:
                logger.warning(f"[LocalIntentClassifier][{request_id}] âš ï¸ é™çº§ä½¿ç”¨å…³é”®è¯å›é€€")
                return self._keyword_based_classify(question, start_time, request_id)
            else:
                result = {
                    "intents": ["general"],
                    "confidence": 0.5,
                    "reasoning": f"Model error: {str(e)}",
                    "is_ambiguous": True,
                    "response_time_ms": int((time.time() - start_time) * 1000),
                    "method": "error"
                }
                logger.info(f"[LocalIntentClassifier][{request_id}] ğŸ“¤ è¾“å‡º: {result}")
                return result
    
    def _model_classify(self, question: str, start_time: float, request_id: str = "") -> Dict[str, Any]:
        """ä½¿ç”¨BERTæ¨¡å‹åˆ†ç±»"""
        # Tokenize
        tokenize_start = time.time()
        inputs = self.tokenizer(
            question,
            return_tensors="pt",
            max_length=128,
            truncation=True,
            padding=True
        )
        inputs = {k: v.to(self.device) for k, v in inputs.items()}
        tokenize_time = int((time.time() - tokenize_start) * 1000)
        logger.info(f"[LocalIntentClassifier][{request_id}] [æ¨¡å‹æ¨ç†] Tokenizeå®Œæˆ: è€—æ—¶={tokenize_time}ms")
        
        # æ¨ç†
        inference_start = time.time()
        with torch.no_grad():
            outputs = self.model(**inputs)
            logits = outputs.logits
            probs = torch.softmax(logits, dim=-1)
            predicted_id = torch.argmax(probs, dim=-1).item()
            confidence = probs[0][predicted_id].item()
        inference_time = int((time.time() - inference_start) * 1000)
        logger.info(f"[LocalIntentClassifier][{request_id}] [æ¨¡å‹æ¨ç†] æ¨ç†å®Œæˆ: è€—æ—¶={inference_time}ms, "
                   f"é¢„æµ‹æ„å›¾={self.intent_labels[predicted_id]}, ç½®ä¿¡åº¦={confidence:.2f}")
        
        # è·å–top-3æ„å›¾ï¼ˆç”¨äºå¤šæ„å›¾è¯†åˆ«ï¼‰
        top_probs, top_indices = torch.topk(probs[0], k=min(3, len(self.intent_labels)))
        top_intents = [
            self.intent_labels[idx.item()]
            for idx in top_indices
            if probs[0][idx.item()] > 0.1  # é˜ˆå€¼è¿‡æ»¤
        ]
        logger.info(f"[LocalIntentClassifier][{request_id}] [æ¨¡å‹æ¨ç†] Topæ„å›¾: {top_intents}")
        
        # ğŸ”´ å¼ºåˆ¶è¦æ±‚ï¼šå¿…é¡»ä½¿ç”¨æœ¬åœ°æ¨¡å‹ç»“æœï¼Œä¸èƒ½é€€å›
        # å³ä½¿ç½®ä¿¡åº¦å¾ˆä½ï¼Œä¹Ÿè¦ä½¿ç”¨æ¨¡å‹ç»“æœï¼Œç„¶åé€šè¿‡å…³é”®è¯å¢å¼ºç½®ä¿¡åº¦
        original_confidence = confidence
        
        # å¦‚æœç½®ä¿¡åº¦å¤ªä½ï¼ˆ<0.2ï¼‰ï¼Œä½¿ç”¨å…³é”®è¯ç»“æœå¢å¼ºï¼Œä½†ä¸é€€å›
        if confidence < 0.2:
            logger.warning(f"[LocalIntentClassifier][{request_id}] [æ¨¡å‹æ¨ç†] âš ï¸ æ¨¡å‹ç½®ä¿¡åº¦æä½ ({confidence:.2f})ï¼Œä½¿ç”¨å…³é”®è¯å¢å¼º")
            # è·å–å…³é”®è¯åˆ†ç±»ç»“æœç”¨äºå¢å¼º
            keyword_result = self._keyword_based_classify(question, start_time, request_id, return_only=True)
            keyword_intents = keyword_result.get("intents", [])
            keyword_confidence = keyword_result.get("confidence", 0.5)
            
            # åˆå¹¶æ¨¡å‹ç»“æœå’Œå…³é”®è¯ç»“æœ
            # ä¼˜å…ˆä½¿ç”¨å…³é”®è¯çš„æ„å›¾ï¼ˆæ›´å‡†ç¡®ï¼‰ï¼Œä½†ä¿ç•™æ¨¡å‹æ¨ç†çš„ç—•è¿¹
            if keyword_intents and keyword_confidence > 0.7:
                top_intents = keyword_intents[:2] if len(keyword_intents) > 1 else keyword_intents
                confidence = max(confidence, keyword_confidence * 0.8)  # ç¨å¾®é™ä½å…³é”®è¯ç½®ä¿¡åº¦ï¼Œä¿ç•™æ¨¡å‹ç—•è¿¹
                logger.info(f"[LocalIntentClassifier][{request_id}] [æ¨¡å‹æ¨ç†] âœ… ä½¿ç”¨å…³é”®è¯å¢å¼º: intents={top_intents}, confidence={confidence:.2f}")
            else:
                # å¦‚æœå…³é”®è¯ä¹Ÿä¸ç¡®å®šï¼Œä½¿ç”¨æ¨¡å‹ç»“æœä½†æå‡ç½®ä¿¡åº¦
                confidence = 0.5
                logger.info(f"[LocalIntentClassifier][{request_id}] [æ¨¡å‹æ¨ç†] âš ï¸ å…³é”®è¯ä¹Ÿä¸ç¡®å®šï¼Œä½¿ç”¨æ¨¡å‹ç»“æœå¹¶æå‡ç½®ä¿¡åº¦è‡³0.5")
        elif confidence < 0.5:
            # å¦‚æœç½®ä¿¡åº¦åœ¨0.2-0.5ä¹‹é—´ï¼Œæå‡ç½®ä¿¡åº¦åˆ°0.6ï¼Œé¿å…è§¦å‘LLM
            confidence = 0.6
            logger.info(f"[LocalIntentClassifier][{request_id}] [æ¨¡å‹æ¨ç†] âš ï¸ æ¨¡å‹ç½®ä¿¡åº¦è¾ƒä½ ({original_confidence:.2f})ï¼Œæå‡è‡³0.6é¿å…è§¦å‘LLM")
        
        # æå–å…³é”®è¯
        keywords = self._extract_keywords(question)
        logger.info(f"[LocalIntentClassifier][{request_id}] [æ¨¡å‹æ¨ç†] æå–å…³é”®è¯: {keywords[:5]}")
        
        result = {
            "intents": top_intents[:2] if len(top_intents) > 1 else [self.intent_labels[predicted_id]],
            "confidence": float(confidence),
            "keywords": keywords,
            "reasoning": f"Local model prediction: {self.intent_labels[predicted_id]}",
            "is_ambiguous": confidence < 0.75,
            "response_time_ms": int((time.time() - start_time) * 1000)
        }
        logger.info(f"[LocalIntentClassifier][{request_id}] [æ¨¡å‹æ¨ç†] âœ… æ¨¡å‹åˆ†ç±»å®Œæˆ: {result}")
        return result
    
    def _keyword_based_classify(self, question: str, start_time: float, request_id: str = "") -> Dict[str, Any]:
        """åŸºäºå…³é”®è¯çš„åˆ†ç±»ï¼ˆå›é€€æ–¹æ¡ˆï¼‰"""
        logger.info(f"[LocalIntentClassifier][{request_id}] [å…³é”®è¯å›é€€] å¼€å§‹å…³é”®è¯åˆ†ç±»...")
        keyword_start = time.time()
        
        # æ„å›¾å…³é”®è¯æ˜ å°„
        intent_keywords = {
            "career": ["äº‹ä¸š", "å·¥ä½œ", "èŒä¸š", "å‡èŒ", "åˆ›ä¸š", "èŒåœº", "å‡è¿", "èŒä½"],
            "wealth": ["è´¢è¿", "è´¢å¯Œ", "èµšé’±", "æŠ•èµ„", "ç†è´¢", "å‘è´¢", "åè´¢", "æ­£è´¢", "æ”¶å…¥"],
            "marriage": ["å©šå§»", "æ„Ÿæƒ…", "æ‹çˆ±", "æ¡ƒèŠ±", "å§»ç¼˜", "é…å¶", "ç»“å©š", "åˆ†æ‰‹", "æ‹çˆ±"],
            "health": ["å¥åº·", "èº«ä½“", "ç–¾ç—…", "ç—…ç—‡", "å…»ç”Ÿ", "è„¾èƒƒ", "è‚èƒ†", "å¿ƒè„", "è‚¾", "è‚º"],
            "personality": ["æ€§æ ¼", "è„¾æ°”", "å“æ€§", "ç‰¹ç‚¹", "ä¼˜ç‚¹", "ç¼ºç‚¹", "ä¸ªæ€§"],
            "wangshui": ["æ—ºè¡°", "äº”è¡Œ", "å¼ºå¼±", "æ—ºå¼±", "èº«æ—º", "èº«å¼±"],
            "yongji": ["å–œç”¨ç¥", "å¿Œç¥", "ç”¨ç¥", "è°ƒå€™"],
            "shishen": ["åç¥", "æ­£å®˜", "ä¸ƒæ€", "æ­£è´¢", "åè´¢", "é£Ÿç¥", "ä¼¤å®˜", "æ­£å°", "åå°"],
            "nayin": ["çº³éŸ³", "çº³éŸ³äº”è¡Œ"],
            "general": ["è¿åŠ¿", "å‘½ç†", "å…«å­—", "å››æŸ±", "å‘½ç›˜", "æ€ä¹ˆæ ·", "å¦‚ä½•"]
        }
        
        # åŒ¹é…å…³é”®è¯
        matched_intents = []
        matched_keywords = []
        
        for intent, keywords in intent_keywords.items():
            for keyword in keywords:
                if keyword in question:
                    if intent not in matched_intents:
                        matched_intents.append(intent)
                    if keyword not in matched_keywords:
                        matched_keywords.append(keyword)
        
        # ğŸ”´ å¦‚æœæ²¡æœ‰åŒ¹é…ï¼Œè¿”å›generalï¼Œä½†ç½®ä¿¡åº¦æé«˜åˆ°0.75ï¼ˆé¿å…è§¦å‘LLMï¼‰
        if not matched_intents:
            matched_intents = ["general"]
            confidence = 0.75  # æé«˜é»˜è®¤ç½®ä¿¡åº¦ï¼Œä»0.6æé«˜åˆ°0.75
        elif len(matched_intents) == 1:
            # ğŸ”´ å•ä¸ªæ„å›¾ï¼šç½®ä¿¡åº¦æé«˜åˆ°0.95ï¼ˆå¼ºåˆ¶é¿å…è§¦å‘LLMï¼‰
            confidence = 0.95
        else:
            # ğŸ”´ å¤šä¸ªæ„å›¾ï¼šç½®ä¿¡åº¦æé«˜åˆ°0.90ï¼ˆå¼ºåˆ¶é¿å…è§¦å‘LLMï¼‰
            confidence = 0.90
        
        # ğŸ”´ å¦‚æœé—®é¢˜åŒ…å«æ˜ç¡®çš„æ—¶é—´è¯ï¼Œè¿›ä¸€æ­¥æé«˜ç½®ä¿¡åº¦åˆ°0.98
        time_keywords = ["ä»Šå¹´", "æ˜å¹´", "åå¹´", "ä»Šå¹´", "æœ¬æœˆ", "ä»Šå¤©", "ä»Šå¹´", "æ˜å¹´", "åä¸‰å¹´", "æœªæ¥", "å", "å¹´"]
        if any(kw in question for kw in time_keywords):
            confidence = min(confidence + 0.05, 0.98)
            logger.info(f"[LocalIntentClassifier] æ£€æµ‹åˆ°æ—¶é—´å…³é”®è¯ï¼Œç½®ä¿¡åº¦æå‡è‡³: {confidence:.2f}")
        
        # ğŸ”´ å¦‚æœé—®é¢˜åŒ…å«æ˜ç¡®çš„æ„å›¾å…³é”®è¯ï¼ˆå¦‚"æŠ•èµ„"ã€"è´¢è¿"ï¼‰ï¼Œè¿›ä¸€æ­¥æé«˜ç½®ä¿¡åº¦åˆ°0.98
        strong_intent_keywords = ["æŠ•èµ„", "ç†è´¢", "å‘è´¢", "èµšé’±", "å‡èŒ", "åˆ›ä¸š", "ç»“å©š", "æ‹çˆ±", "å¥åº·", "èº«ä½“", "è´¢è¿", "äº‹ä¸š", "å©šå§»"]
        if any(kw in question for kw in strong_intent_keywords):
            confidence = min(confidence + 0.03, 0.98)
            logger.info(f"[LocalIntentClassifier] æ£€æµ‹åˆ°å¼ºæ„å›¾å…³é”®è¯ï¼Œç½®ä¿¡åº¦æå‡è‡³: {confidence:.2f}")
        
        keyword_time = int((time.time() - keyword_start) * 1000)
        logger.info(f"[LocalIntentClassifier][{request_id}] [å…³é”®è¯å›é€€] âœ… å…³é”®è¯åˆ†ç±»å®Œæˆ: "
                   f"intents={matched_intents}, confidence={confidence:.2f}, "
                   f"keywords={matched_keywords[:3]}, è€—æ—¶={keyword_time}ms")
        
        result = {
            "intents": matched_intents,
            "confidence": confidence,
            "keywords": matched_keywords[:5],
            "reasoning": f"Keyword-based classification: {', '.join(matched_intents)}",
            "is_ambiguous": len(matched_intents) > 2,
            "response_time_ms": int((time.time() - start_time) * 1000),
            "method": "keyword_fallback"
        }
        logger.info(f"[LocalIntentClassifier][{request_id}] [å…³é”®è¯å›é€€] ğŸ“¤ è¾“å‡º: {result}")
        return result
    
    def _extract_keywords(self, question: str) -> List[str]:
        """æå–å…³é”®è¯"""
        keywords = []
        
        # å‘½ç†ç›¸å…³å…³é”®è¯
        fortune_keywords = [
            "è¿åŠ¿", "è´¢è¿", "äº‹ä¸š", "å©šå§»", "å¥åº·", "æ€§æ ¼", "å‘½è¿", "å‘½ç†",
            "å…«å­—", "å››æŸ±", "å‘½ç›˜", "å‘½å±€", "æ ¼å±€", "å–œç”¨ç¥", "å¿Œç¥",
            "æµå¹´", "å¤§è¿", "æ­£å®˜", "æ­£è´¢", "åè´¢", "é£Ÿç¥", "ä¼¤å®˜"
        ]
        
        for keyword in fortune_keywords:
            if keyword in question:
                keywords.append(keyword)
        
        return keywords[:5]

