# 项目并发能力分析

## 📊 当前配置概览

### 1. 服务器配置（Uvicorn）

**位置**: `server/start.py`

```python
workers=4                    # 4个工作进程
limit_concurrency=1000       # 最大并发连接数
limit_max_requests=10000     # 每个worker最大请求数（重启前）
backlog=2048                 # 等待队列大小
```

**理论最大并发**: 
- 4 workers × 1000 并发 = **4000 并发连接**
- 但受限于其他资源（CPU、内存、数据库等）

### 2. 线程池配置

**每个API路由的线程池**:
```python
max_workers = min(cpu_count * 2, 100)
# 当前CPU: 8核心 → max_workers = 16
```

**规则引擎内部线程池**:
```python
max_workers = min(cpu_count * 2, 20) = 16
```

**总线程数估算**:
- 4 workers × 16 线程/worker = **64 个并发计算线程**
- 每个线程可以处理一个CPU密集型任务

### 3. Redis 连接池

**配置**: `server/config/redis_config.py`
```python
max_connections = 50  # Redis连接池大小
```

**限制**: 最多50个并发Redis操作

### 4. MySQL 连接

**当前状态**: ⚠️ **无连接池**（瓶颈）

**问题**: 每次请求都创建新连接，高并发下会成为瓶颈

**建议**: 使用连接池（如 SQLAlchemy 或 PyMySQL 连接池）

### 5. 限流配置

**精选接口限流**: 30次/分钟/IP
- 单个IP最多30次/分钟
- 多个IP可以同时访问

## 🎯 实际并发能力估算

### 场景1: 轻量级请求（如精选接口）

**单次请求耗时**: ~0.1秒

**理论QPS**:
- 4 workers × (1/0.1) = **40 QPS/worker**
- 总计: **160 QPS** (每秒160个请求)

**实际并发用户数**:
- 假设每个用户平均每10秒请求1次
- 160 QPS × 10秒 = **1600 并发用户**

### 场景2: 重量级请求（如完整八字计算）

**单次请求耗时**: ~0.5-2秒

**理论QPS**:
- 4 workers × (1/1.0) = **4 QPS/worker**
- 总计: **16 QPS**

**实际并发用户数**:
- 16 QPS × 10秒 = **160 并发用户**

### 场景3: 混合负载（实际情况）

**平均请求耗时**: ~0.3秒

**理论QPS**:
- 4 workers × (1/0.3) = **13 QPS/worker**
- 总计: **52 QPS**

**实际并发用户数**:
- 52 QPS × 10秒 = **520 并发用户**

## ⚠️ 瓶颈分析

### 1. MySQL 连接（最大瓶颈）

**问题**:
- 无连接池，每次请求创建新连接
- 连接创建/关闭开销大
- 高并发下可能耗尽MySQL最大连接数

**影响**: 
- 可能导致连接超时
- 响应时间增加

**建议**:
```python
# 使用连接池，建议配置：
max_connections = 100  # 连接池大小
pool_recycle = 3600   # 连接回收时间
```

### 2. Redis 连接池

**当前**: 50个连接

**评估**: 
- 对于缓存操作，50个连接通常足够
- 如果Redis操作频繁，可能需要增加到100

### 3. CPU 资源

**当前**: 8核心

**评估**:
- 4 workers × 16 线程 = 64 并发线程
- 8核心可以支持，但会有上下文切换开销
- 建议监控CPU使用率

### 4. 内存

**评估**:
- 每个worker进程约占用50-200MB
- 4 workers ≈ 200-800MB
- 加上缓存和数据库连接，建议至少2GB内存

## 📈 优化建议

### 1. 立即优化（高优先级）

#### 添加 MySQL 连接池

```python
# 使用 PyMySQL 连接池
from pymysql import pool

mysql_pool = pool.ConnectionPool(
    host='localhost',
    port=3306,
    user='root',
    password='123456',
    database='hifate_bazi',
    mincached=10,      # 最小连接数
    maxcached=50,      # 最大连接数
    maxconnections=100 # 最大连接数
)
```

**预期提升**: 并发能力提升 **2-3倍**

### 2. 中期优化

#### 增加 Workers 数量

```python
# server/start.py
workers = os.cpu_count()  # 8 workers (匹配CPU核心数)
```

**预期提升**: 并发能力提升 **2倍**

#### 优化 Redis 连接池

```python
max_connections = 100  # 增加到100
```

### 3. 长期优化

#### 使用异步数据库驱动

- 使用 `aiomysql` 或 `asyncpg` (PostgreSQL)
- 完全异步，无线程开销

**预期提升**: 并发能力提升 **5-10倍**

#### 添加负载均衡

- 使用 Nginx 做反向代理
- 部署多个实例

**预期提升**: 线性扩展

#### 数据库读写分离

- 主库写，从库读
- 减少数据库压力

## 🎯 最终评估

### 当前配置下的实际并发能力

| 场景 | QPS | 并发用户数 | 说明 |
|------|-----|-----------|------|
| 轻量级请求 | 160 | 1600 | 精选接口等 |
| 重量级请求 | 16 | 160 | 完整八字计算 |
| 混合负载 | 52 | 520 | 实际情况 |

### 优化后的预期并发能力

| 优化项 | QPS提升 | 并发用户数提升 |
|--------|---------|---------------|
| 添加MySQL连接池 | 2-3倍 | 1000-1500 |
| 增加Workers到8 | 2倍 | 1000-3000 |
| 使用异步数据库 | 5-10倍 | 2500-5000 |
| 负载均衡+多实例 | 线性扩展 | 无上限 |

## 📝 监控建议

### 关键指标

1. **响应时间**: 应 < 1秒（P95）
2. **错误率**: 应 < 1%
3. **CPU使用率**: 应 < 80%
4. **内存使用**: 应 < 80%
5. **数据库连接数**: 监控MySQL连接数
6. **Redis连接数**: 监控连接池使用率

### 监控工具

- **APM**: New Relic, Datadog, 或 Prometheus
- **日志**: ELK Stack 或 Loki
- **数据库**: MySQL慢查询日志

## 🚀 快速提升方案

### 方案1: 最小改动，最大收益

1. ✅ 添加MySQL连接池（预计1小时）
2. ✅ 增加workers到8（预计5分钟）
3. ✅ 监控关键指标

**预期**: 并发能力提升 **3-4倍** (1500-2000并发用户)

### 方案2: 全面优化

1. ✅ 方案1的所有内容
2. ✅ 使用异步数据库驱动
3. ✅ 添加Redis缓存层
4. ✅ 数据库读写分离

**预期**: 并发能力提升 **10倍以上** (5000+并发用户)

## 📌 总结

**当前并发能力**: 
- **轻量级**: ~1600并发用户
- **混合负载**: ~520并发用户
- **重量级**: ~160并发用户

**主要瓶颈**: MySQL无连接池

**最快优化**: 添加MySQL连接池 + 增加workers

**预期提升**: 3-4倍（1500-2000并发用户）

