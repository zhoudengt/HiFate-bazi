# HiFate系统 - 双节点高可用部署方案

## 📋 目录

- [一、架构设计](#一架构设计)
- [二、服务器配置](#二服务器配置)
- [三、软件清单](#三软件清单)
- [四、目录结构](#四目录结构)
- [五、配置文件](#五配置文件)
- [六、部署步骤](#六部署步骤)
- [七、高可用配置](#七高可用配置)
- [八、监控和维护](#八监控和维护)
- [九、故障处理](#九故障处理)
- [十、检查清单](#十检查清单)

---

## 一、架构设计

### 1.1 整体架构

```
┌─────────────────────────────────────────────────────────┐
│              阿里云负载均衡 SLB (可选)                    │
│             或 Nginx 负载均衡 (推荐)                      │
└──────────────────────┬──────────────────────────────────┘
                       │
        ┌──────────────┴──────────────┐
        │                              │
┌───────▼────────┐          ┌─────────▼────────┐
│  节点1 (主)     │          │  节点2 (备)       │
│  ECS-1          │◄────────►│  ECS-2            │
│                 │  心跳    │                  │
│  - Web App           │          │  - Web App            │
│  - bazi_core         │          │  - bazi_core          │
│  - bazi_fortune      │          │  - bazi_fortune       │
│  - bazi_analyzer     │          │  - bazi_analyzer      │
│  - bazi_rule         │          │  - bazi_rule          │
│  - fortune_analysis  │          │  - fortune_analysis   │
│  - payment_service   │          │  - payment_service    │
│  - fortune_rule      │          │  - fortune_rule       │
│  - MySQL (主)   │          │  - MySQL (从)    │
│  - Redis (主)   │          │  - Redis (从)    │
│  - Nginx        │          │  - Nginx         │
└─────────────────┘          └──────────────────┘
```

### 1.2 服务端口分配

| 服务 | 端口 | 协议 | 功能说明 |
|------|------|------|---------|
| Web App | 8001 | HTTP | FastAPI 主应用 |
| bazi_core | 9001 | gRPC | 八字核心计算服务：计算八字排盘（四柱、神煞、十神等基础信息） |
| bazi_fortune | 9002 | gRPC | 大运流年服务：计算大运、流年、流月等运势周期 |
| bazi_analyzer | 9003 | gRPC | 八字分析服务：执行各种分析器（如日柱性别分析等） |
| bazi_rule | 9004 | gRPC | 规则匹配服务：匹配八字规则（婚姻、桃花等462+条规则） |
| fortune_analysis | 9005 | gRPC | 面相手相分析服务：手相和面相图像分析，生成命理报告 |
| payment_service | 9006 | gRPC | 支付服务：Stripe支付集成，创建支付会话和验证支付状态 |
| fortune_rule | 9007 | gRPC | 面相手相规则服务：面相手相规则匹配和八字融合分析 |
| MySQL | 3306 | MySQL | 数据库服务 |
| Redis | 6379 | Redis | 缓存服务 |
| Nginx | 80 | HTTP | 负载均衡和反向代理 |

### 1.3 数据流向

```
用户请求
  ↓
Nginx 负载均衡
  ↓
Web App (节点1 或 节点2)
  ↓
├─→ bazi_core (gRPC)
├─→ bazi_fortune (gRPC)
├─→ bazi_analyzer (gRPC)
├─→ bazi_rule (gRPC)
├─→ fortune_analysis (gRPC)
├─→ payment_service (gRPC)
└─→ fortune_rule (gRPC)
    ├─→ MySQL (主/从)
    └─→ Redis (主/从)
```

---

## 二、服务器配置

### 2.1 推荐配置

| 资源 | 配置 | 说明 |
|------|------|------|
| CPU | 4核 | 每台服务器 |
| 内存 | 16GB | 足够运行所有服务 |
| 系统盘 | 40GB SSD | 系统 + 应用 |
| 数据盘 | 100GB SSD | MySQL + Redis 数据 |
| 带宽 | 5Mbps | 对外服务 |
| 操作系统 | CentOS 7.9 / Ubuntu 20.04 | 推荐 CentOS 7.9 |

### 2.2 网络要求

- **内网互通**：两台服务器必须在同一 VPC 内，确保内网互通
- **安全组规则**：开放必要端口（见下表）
- **公网 IP**：至少一台服务器需要公网 IP（用于部署和访问）

### 2.3 安全组配置

| 端口 | 协议 | 源 | 说明 |
|------|------|-----|------|
| 80 | TCP | 0.0.0.0/0 | Nginx HTTP |
| 443 | TCP | 0.0.0.0/0 | Nginx HTTPS (可选) |
| 8001 | TCP | 内网 | Web App (仅内网) |
| 9001-9004 | TCP | 内网 | 微服务 (仅内网) |
| 3306 | TCP | 内网 | MySQL (仅内网) |
| 6379 | TCP | 内网 | Redis (仅内网) |
| 22 | TCP | 你的IP | SSH (管理) |

### 2.4 成本估算

- **单台 ECS**：约 ¥300-500/月
- **两台 ECS**：约 ¥600-1000/月
- **负载均衡 SLB**（可选）：约 ¥50-100/月
- **总计**：约 ¥650-1100/月

---

## 三、软件清单

### 3.1 每台服务器需要安装的软件

```bash
# 基础软件
- Python 3.11
- Docker 20.10+
- Docker Compose 2.0+
- Nginx 1.20+
- MySQL 8.0 (或使用 Docker)
- Redis 7.0 (或使用 Docker)
- Keepalived 2.0+ (VIP 高可用，可选)
- Supervisor 4.0+ (进程管理，可选)
- Git
- curl, wget
```

### 3.2 Python 依赖

项目依赖已包含在 `requirements.txt` 中，主要包括：
- FastAPI, Uvicorn
- gRPC, Protobuf
- PyMySQL, Redis
- Coze API 相关库
- 其他业务依赖

---

## 四、目录结构

### 4.1 项目目录结构

```
/opt/HiFate-bazi/
├── app/                          # 应用代码（从 Git 克隆）
│   ├── server/
│   ├── services/
│   ├── src/
│   └── ...
├── docker-compose.master.yml     # 主节点 Docker Compose 配置
├── docker-compose.slave.yml      # 从节点 Docker Compose 配置
├── Dockerfile                    # Docker 镜像构建文件
├── nginx/                        # Nginx 配置
│   ├── nginx.conf
│   └── conf.d/
│       └── HiFate-bazi.conf
├── mysql/                        # MySQL 配置和数据
│   ├── master/
│   │   ├── data/                 # 数据目录
│   │   ├── conf/                 # 配置文件
│   │   └── init/                 # 初始化脚本
│   └── slave/
│       ├── data/
│       └── conf/
├── redis/                        # Redis 配置和数据
│   ├── master/
│   │   ├── data/
│   │   └── conf/
│   └── slave/
│       ├── data/
│       └── conf/
├── logs/                         # 日志目录
│   ├── web-app/
│   ├── bazi-core/
│   ├── bazi-fortune/
│   ├── bazi-analyzer/
│   ├── bazi-rule/
│   └── nginx/
├── scripts/                      # 部署脚本
│   ├── init_server.sh            # 服务器初始化
│   ├── deploy.sh                 # 部署脚本
│   ├── setup_mysql_replication.sh # MySQL 主从配置
│   └── health_check.sh           # 健康检查
├── .env                          # 环境变量（不提交到 Git）
└── .env.example                  # 环境变量模板
```

---

## 五、配置文件

### 5.1 环境变量配置

创建 `.env` 文件（每台服务器都需要）：

```bash
# ============================================
# MySQL 配置
# ============================================
MYSQL_ROOT_PASSWORD=your_secure_root_password
MYSQL_PASSWORD=your_secure_bazi_password

# ============================================
# Redis 配置
# ============================================
REDIS_PASSWORD=your_secure_redis_password

# ============================================
# Coze API 配置（大模型）
# ============================================
COZE_ACCESS_TOKEN=pat_xxxxxxxxxxxxx
COZE_BOT_ID=1234567890

# ============================================
# 节点配置
# ============================================
NODE_ROLE=master  # 节点1: master, 节点2: slave
NODE_ID=1         # 节点1: 1, 节点2: 2

# ============================================
# 网络配置（替换为实际内网 IP）
# ============================================
MASTER_NODE_IP=172.16.0.10
SLAVE_NODE_IP=172.16.0.11
VIRTUAL_IP=172.16.0.100  # Keepalived 虚拟 IP（可选）

# ============================================
# 服务配置
# ============================================
BAZI_CORE_SERVICE_URL=bazi-core:9001
BAZI_FORTUNE_SERVICE_URL=bazi-fortune:9002
BAZI_ANALYZER_SERVICE_URL=bazi-analyzer:9003
BAZI_RULE_SERVICE_URL=bazi-rule:9004
```

### 5.2 Docker Compose 配置 - 主节点

创建 `docker-compose.master.yml`：

```yaml
version: '3.8'

services:
  # Web 应用服务
  web-app:
    build:
      context: ./app
      dockerfile: ../Dockerfile
    image: HiFate-bazi:latest
    container_name: web-app
    ports:
      - "8001:8001"
    environment:
      - BAZI_CORE_SERVICE_URL=bazi-core:9001
      - BAZI_FORTUNE_SERVICE_URL=bazi-fortune:9002
      - BAZI_ANALYZER_SERVICE_URL=bazi-analyzer:9003
      - BAZI_RULE_SERVICE_URL=bazi-rule:9004
      - MYSQL_HOST=mysql-master
      - MYSQL_PORT=3306
      - MYSQL_DB=hifate_bazi
      - MYSQL_USER=bazi_user
      - MYSQL_PASSWORD=${MYSQL_PASSWORD}
      - REDIS_HOST=redis-master
      - REDIS_PORT=6379
      - REDIS_PASSWORD=${REDIS_PASSWORD}
      - COZE_ACCESS_TOKEN=${COZE_ACCESS_TOKEN}
      - COZE_BOT_ID=${COZE_BOT_ID}
    depends_on:
      - bazi-core
      - bazi-fortune
      - bazi-analyzer
      - bazi-rule
      - mysql-master
      - redis-master
    restart: unless-stopped
    networks:
      - bazi-network
    volumes:
      - ./logs/web-app:/app/logs
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # 八字核心服务
  bazi-core:
    build:
      context: ./app
      dockerfile: ../Dockerfile
    image: HiFate-bazi:latest
    command: python services/bazi_core/grpc_server.py --port 9001
    ports:
      - "9001:9001"
    restart: unless-stopped
    networks:
      - bazi-network
    volumes:
      - ./logs/bazi-core:/app/logs
    healthcheck:
      test: ["CMD-SHELL", "timeout 3 grpc_health_probe -addr=:9001 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  # 大运流年服务
  bazi-fortune:
    build:
      context: ./app
      dockerfile: ../Dockerfile
    image: HiFate-bazi:latest
    command: python services/bazi_fortune/grpc_server.py --port 9002
    ports:
      - "9002:9002"
    restart: unless-stopped
    networks:
      - bazi-network
    volumes:
      - ./logs/bazi-fortune:/app/logs
    healthcheck:
      test: ["CMD-SHELL", "timeout 3 grpc_health_probe -addr=:9002 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  # 分析服务
  bazi-analyzer:
    build:
      context: ./app
      dockerfile: ../Dockerfile
    image: HiFate-bazi:latest
    command: python services/bazi_analyzer/grpc_server.py --port 9003
    ports:
      - "9003:9003"
    restart: unless-stopped
    networks:
      - bazi-network
    volumes:
      - ./logs/bazi-analyzer:/app/logs
    healthcheck:
      test: ["CMD-SHELL", "timeout 3 grpc_health_probe -addr=:9003 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  # 规则服务
  bazi-rule:
    build:
      context: ./app
      dockerfile: ../Dockerfile
    image: HiFate-bazi:latest
    command: python services/bazi_rule/grpc_server.py --port 9004
    ports:
      - "9004:9004"
    environment:
      - MYSQL_HOST=mysql-master
      - MYSQL_PORT=3306
      - MYSQL_DB=hifate_bazi
      - MYSQL_USER=bazi_user
      - MYSQL_PASSWORD=${MYSQL_PASSWORD}
      - REDIS_HOST=redis-master
      - REDIS_PORT=6379
      - REDIS_PASSWORD=${REDIS_PASSWORD}
    depends_on:
      - mysql-master
      - redis-master
    restart: unless-stopped
    networks:
      - bazi-network
    volumes:
      - ./logs/bazi-rule:/app/logs
    healthcheck:
      test: ["CMD-SHELL", "timeout 3 grpc_health_probe -addr=:9004 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  # MySQL 主节点
  mysql-master:
    image: mysql:8.0
    container_name: mysql-master
    ports:
      - "3306:3306"
    environment:
      - MYSQL_ROOT_PASSWORD=${MYSQL_ROOT_PASSWORD}
      - MYSQL_DATABASE=hifate_bazi
      - MYSQL_USER=bazi_user
      - MYSQL_PASSWORD=${MYSQL_PASSWORD}
    volumes:
      - ./mysql/master/data:/var/lib/mysql
      - ./mysql/master/conf:/etc/mysql/conf.d
      - ./mysql/master/init:/docker-entrypoint-initdb.d
    command: >
      --server-id=1
      --log-bin=mysql-bin
      --binlog-format=ROW
      --gtid-mode=ON
      --enforce-gtid-consistency=ON
      --character-set-server=utf8mb4
      --collation-server=utf8mb4_unicode_ci
    restart: unless-stopped
    networks:
      - bazi-network
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost", "-u", "root", "-p${MYSQL_ROOT_PASSWORD}"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Redis 主节点
  redis-master:
    image: redis:7-alpine
    container_name: redis-master
    ports:
      - "6379:6379"
    command: >
      redis-server
      --requirepass ${REDIS_PASSWORD}
      --appendonly yes
      --appendfsync everysec
    volumes:
      - ./redis/master/data:/data
      - ./redis/master/conf:/usr/local/etc/redis
    restart: unless-stopped
    networks:
      - bazi-network
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5

networks:
  bazi-network:
    driver: bridge
```

### 5.3 Docker Compose 配置 - 从节点

创建 `docker-compose.slave.yml`：

```yaml
version: '3.8'

services:
  # Web 应用服务（备用）
  web-app:
    build:
      context: ./app
      dockerfile: ../Dockerfile
    image: HiFate-bazi:latest
    container_name: web-app
    ports:
      - "8001:8001"
    environment:
      - BAZI_CORE_SERVICE_URL=bazi-core:9001
      - BAZI_FORTUNE_SERVICE_URL=bazi-fortune:9002
      - BAZI_ANALYZER_SERVICE_URL=bazi-analyzer:9003
      - BAZI_RULE_SERVICE_URL=bazi-rule:9004
      - MYSQL_HOST=mysql-slave
      - MYSQL_PORT=3306
      - MYSQL_DB=hifate_bazi
      - MYSQL_USER=bazi_user
      - MYSQL_PASSWORD=${MYSQL_PASSWORD}
      - REDIS_HOST=redis-slave
      - REDIS_PORT=6379
      - REDIS_PASSWORD=${REDIS_PASSWORD}
      - COZE_ACCESS_TOKEN=${COZE_ACCESS_TOKEN}
      - COZE_BOT_ID=${COZE_BOT_ID}
    depends_on:
      - bazi-core
      - bazi-fortune
      - bazi-analyzer
      - bazi-rule
      - mysql-slave
      - redis-slave
    restart: unless-stopped
    networks:
      - bazi-network
    volumes:
      - ./logs/web-app:/app/logs
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # 微服务（与主节点相同）
  bazi-core:
    build:
      context: ./app
      dockerfile: ../Dockerfile
    image: HiFate-bazi:latest
    command: python services/bazi_core/grpc_server.py --port 9001
    ports:
      - "9001:9001"
    restart: unless-stopped
    networks:
      - bazi-network
    volumes:
      - ./logs/bazi-core:/app/logs

  bazi-fortune:
    build:
      context: ./app
      dockerfile: ../Dockerfile
    image: HiFate-bazi:latest
    command: python services/bazi_fortune/grpc_server.py --port 9002
    ports:
      - "9002:9002"
    restart: unless-stopped
    networks:
      - bazi-network
    volumes:
      - ./logs/bazi-fortune:/app/logs

  bazi-analyzer:
    build:
      context: ./app
      dockerfile: ../Dockerfile
    image: HiFate-bazi:latest
    command: python services/bazi_analyzer/grpc_server.py --port 9003
    ports:
      - "9003:9003"
    restart: unless-stopped
    networks:
      - bazi-network
    volumes:
      - ./logs/bazi-analyzer:/app/logs

  bazi-rule:
    build:
      context: ./app
      dockerfile: ../Dockerfile
    image: HiFate-bazi:latest
    command: python services/bazi_rule/grpc_server.py --port 9004
    ports:
      - "9004:9004"
    environment:
      - MYSQL_HOST=mysql-slave
      - MYSQL_PORT=3306
      - MYSQL_DB=hifate_bazi
      - MYSQL_USER=bazi_user
      - MYSQL_PASSWORD=${MYSQL_PASSWORD}
      - REDIS_HOST=redis-slave
      - REDIS_PORT=6379
      - REDIS_PASSWORD=${REDIS_PASSWORD}
    depends_on:
      - mysql-slave
      - redis-slave
    restart: unless-stopped
    networks:
      - bazi-network
    volumes:
      - ./logs/bazi-rule:/app/logs

  # MySQL 从节点
  mysql-slave:
    image: mysql:8.0
    container_name: mysql-slave
    ports:
      - "3306:3306"
    environment:
      - MYSQL_ROOT_PASSWORD=${MYSQL_ROOT_PASSWORD}
      - MYSQL_DATABASE=hifate_bazi
      - MYSQL_USER=bazi_user
      - MYSQL_PASSWORD=${MYSQL_PASSWORD}
    volumes:
      - ./mysql/slave/data:/var/lib/mysql
      - ./mysql/slave/conf:/etc/mysql/conf.d
    command: >
      --server-id=2
      --log-bin=mysql-bin
      --binlog-format=ROW
      --gtid-mode=ON
      --enforce-gtid-consistency=ON
      --read-only=1
      --relay-log=mysql-relay-bin
      --character-set-server=utf8mb4
      --collation-server=utf8mb4_unicode_ci
    restart: unless-stopped
    networks:
      - bazi-network
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost", "-u", "root", "-p${MYSQL_ROOT_PASSWORD}"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Redis 从节点
  redis-slave:
    image: redis:7-alpine
    container_name: redis-slave
    ports:
      - "6379:6379"
    command: >
      redis-server
      --requirepass ${REDIS_PASSWORD}
      --replicaof ${MASTER_NODE_IP} 6379
      --masterauth ${REDIS_PASSWORD}
      --appendonly yes
      --appendfsync everysec
    volumes:
      - ./redis/slave/data:/data
    restart: unless-stopped
    networks:
      - bazi-network
    depends_on:
      - redis-master
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5

networks:
  bazi-network:
    driver: bridge
```

### 5.4 MySQL 主节点配置

创建 `mysql/master/conf/my.cnf`:

```ini
[mysqld]
# 服务器 ID（主节点为 1）
server-id = 1

# 二进制日志配置
log-bin = mysql-bin
binlog-format = ROW
expire_logs_days = 7
max_binlog_size = 100M

# GTID 配置
gtid-mode = ON
enforce-gtid-consistency = ON

# 字符集配置
character-set-server = utf8mb4
collation-server = utf8mb4_unicode_ci

# 性能优化
innodb_buffer_pool_size = 1G
innodb_log_file_size = 256M
max_connections = 500
```

### 5.5 MySQL 从节点配置

创建 `mysql/slave/conf/my.cnf`:

```ini
[mysqld]
# 服务器 ID（从节点为 2）
server-id = 2

# 二进制日志配置
log-bin = mysql-bin
binlog-format = ROW

# GTID 配置
gtid-mode = ON
enforce-gtid-consistency = ON

# 只读模式
read-only = 1

# 中继日志
relay-log = mysql-relay-bin
relay-log-index = mysql-relay-bin.index

# 字符集配置
character-set-server = utf8mb4
collation-server = utf8mb4_unicode_ci

# 性能优化
innodb_buffer_pool_size = 1G
innodb_log_file_size = 256M
max_connections = 500
```

### 5.6 Nginx 负载均衡配置

创建 `nginx/conf.d/HiFate-bazi.conf`:

```nginx
upstream web_app_backend {
    # 主节点（优先）
    server ${MASTER_NODE_IP}:8001 max_fails=3 fail_timeout=30s weight=2;
    
    # 备用节点
    server ${SLAVE_NODE_IP}:8001 max_fails=3 fail_timeout=30s weight=1 backup;
    
    # 健康检查（需要 nginx_upstream_check_module）
    # check interval=3000 rise=2 fall=3 timeout=1000;
}

server {
    listen 80;
    server_name your-domain.com;  # 替换为你的域名或使用 _ 表示所有域名
    
    # 日志
    access_log /var/log/nginx/HiFate-bazi-access.log;
    error_log /var/log/nginx/HiFate-bazi-error.log;

    # 客户端最大请求体大小
    client_max_body_size 10M;

    # 负载均衡
    location / {
        proxy_pass http://web_app_backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # 超时设置
        proxy_connect_timeout 60s;
        proxy_send_timeout 60s;
        proxy_read_timeout 60s;
        
        # 缓冲设置
        proxy_buffering on;
        proxy_buffer_size 4k;
        proxy_buffers 8 4k;
    }
    
    # 健康检查端点
    location /health {
        access_log off;
        proxy_pass http://web_app_backend/health;
    }
    
    # API 文档
    location /docs {
        proxy_pass http://web_app_backend/docs;
    }
    
    location /redoc {
        proxy_pass http://web_app_backend/redoc;
    }
}
```

### 5.7 Keepalived 配置（可选）

**节点1** (`/etc/keepalived/keepalived.conf`):

```conf
vrrp_script chk_nginx {
    script "/usr/bin/curl -f http://localhost/health || exit 1"
    interval 2
    weight -2
    fall 3
    rise 2
}

vrrp_instance VI_1 {
    state MASTER
    interface eth0  # 根据实际网卡名称调整
    virtual_router_id 51
    priority 100
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass your_keepalived_password
    }
    virtual_ipaddress {
        ${VIRTUAL_IP}/24  # 虚拟 IP
    }
    track_script {
        chk_nginx
    }
    notify_master "/etc/keepalived/notify_master.sh"
    notify_backup "/etc/keepalived/notify_backup.sh"
    notify_fault "/etc/keepalived/notify_fault.sh"
}
```

**节点2** (相同配置，但 `state BACKUP`, `priority 90`)

---

## 六、部署步骤

### 6.1 服务器初始化

在**两台服务器**上分别执行：

```bash
# 1. 创建部署目录
mkdir -p /opt/HiFate-bazi
cd /opt/HiFate-bazi

# 2. 运行初始化脚本
bash scripts/init_server.sh
```

### 6.2 初始化脚本内容

创建 `scripts/init_server.sh`:

```bash
#!/bin/bash
# 服务器初始化脚本

set -e

echo ">>> 开始初始化服务器..."

# 1. 更新系统
if [ -f /etc/redhat-release ]; then
    # CentOS
    yum update -y
    yum install -y epel-release
    yum install -y docker docker-compose nginx keepalived supervisor git curl wget
elif [ -f /etc/lsb-release ]; then
    # Ubuntu
    apt update && apt upgrade -y
    apt install -y docker.io docker-compose nginx keepalived supervisor git curl wget
fi

# 2. 启动 Docker
systemctl start docker
systemctl enable docker

# 3. 配置防火墙（CentOS）
if command -v firewall-cmd &> /dev/null; then
    firewall-cmd --permanent --add-port=80/tcp
    firewall-cmd --permanent --add-port=8001/tcp
    firewall-cmd --permanent --add-port=9001-9004/tcp
    firewall-cmd --permanent --add-port=3306/tcp
    firewall-cmd --permanent --add-port=6379/tcp
    firewall-cmd --reload
fi

# 4. 创建目录结构
mkdir -p mysql/{master,slave}/{data,conf,init}
mkdir -p redis/{master,slave}/{data,conf}
mkdir -p logs/{web-app,bazi-core,bazi-fortune,bazi-analyzer,bazi-rule,nginx}
mkdir -p scripts

# 5. 设置权限
chmod -R 755 mysql redis logs scripts

echo "✅ 服务器初始化完成"
```

### 6.3 部署应用代码

在**两台服务器**上分别执行：

```bash
cd /opt/HiFate-bazi

# 方式1: 从 Git 克隆
git clone <your-repo-url> app

# 方式2: 使用 scp 上传
# scp -r /path/to/HiFate-bazi root@服务器IP:/opt/HiFate-bazi/app
```

### 6.4 配置环境变量

在**节点1**创建 `.env`:

```bash
cd /opt/HiFate-bazi
cp .env.example .env
vim .env  # 编辑环境变量
```

在**节点2**创建 `.env`（相同内容，但 `NODE_ROLE=slave`）:

```bash
cd /opt/HiFate-bazi
cp .env.example .env
vim .env  # 编辑环境变量，设置 NODE_ROLE=slave
```

### 6.5 部署主节点

在**节点1**执行：

```bash
cd /opt/HiFate-bazi

# 1. 构建镜像
docker build -t HiFate-bazi:latest -f Dockerfile ./app

# 2. 启动服务
docker-compose -f docker-compose.master.yml --env-file .env up -d

# 3. 等待服务启动
sleep 10

# 4. 检查服务状态
docker-compose -f docker-compose.master.yml ps

# 5. 查看日志
docker-compose -f docker-compose.master.yml logs -f
```

### 6.6 部署从节点

在**节点2**执行：

```bash
cd /opt/HiFate-bazi

# 1. 构建镜像
docker build -t HiFate-bazi:latest -f Dockerfile ./app

# 2. 启动服务
docker-compose -f docker-compose.slave.yml --env-file .env up -d

# 3. 等待服务启动
sleep 10

# 4. 检查服务状态
docker-compose -f docker-compose.slave.yml ps
```

### 6.7 配置 MySQL 主从复制

在**节点1**执行：

```bash
cd /opt/HiFate-bazi

# 1. 进入 MySQL 主节点容器
docker exec -it mysql-master mysql -uroot -p${MYSQL_ROOT_PASSWORD}

# 2. 在 MySQL 中执行
CREATE USER 'repl_user'@'%' IDENTIFIED BY 'your_repl_password';
GRANT REPLICATION SLAVE ON *.* TO 'repl_user'@'%';
FLUSH PRIVILEGES;
SHOW MASTER STATUS;  # 记录 File 和 Position
EXIT;
```

在**节点2**执行：

```bash
# 1. 进入 MySQL 从节点容器
docker exec -it mysql-slave mysql -uroot -p${MYSQL_ROOT_PASSWORD}

# 2. 在 MySQL 中执行（替换为实际值）
CHANGE MASTER TO
  MASTER_HOST='${MASTER_NODE_IP}',
  MASTER_PORT=3306,
  MASTER_USER='repl_user',
  MASTER_PASSWORD='your_repl_password',
  MASTER_AUTO_POSITION=1;

START SLAVE;
SHOW SLAVE STATUS\G  # 检查复制状态
EXIT;
```

### 6.8 配置 Nginx 负载均衡

在**两台服务器**上分别执行：

```bash
# 1. 复制 Nginx 配置
cp nginx/conf.d/HiFate-bazi.conf /etc/nginx/conf.d/

# 2. 测试配置
nginx -t

# 3. 启动 Nginx
systemctl start nginx
systemctl enable nginx

# 4. 检查状态
systemctl status nginx
```

### 6.9 初始化数据库

在**节点1**执行：

```bash
# 1. 导入数据库结构
docker exec -i mysql-master mysql -uroot -p${MYSQL_ROOT_PASSWORD} hifate_bazi < app/server/db/schema.sql

# 2. 导入初始数据（如果有）
# docker exec -i mysql-master mysql -uroot -p${MYSQL_ROOT_PASSWORD} hifate_bazi < app/server/db/init_data.sql
```

---

## 七、高可用配置

### 7.1 健康检查脚本

创建 `scripts/health_check.sh`:

```bash
#!/bin/bash
# 健康检查脚本

NODE_ROLE=${NODE_ROLE:-master}
LOG_FILE="/opt/HiFate-bazi/logs/health_check.log"

check_service() {
    local service=$1
    local port=$2
    
    if curl -f -s http://localhost:${port}/health > /dev/null 2>&1; then
        echo "$(date '+%Y-%m-%d %H:%M:%S') - ${service} is healthy" >> ${LOG_FILE}
        return 0
    else
        echo "$(date '+%Y-%m-%d %H:%M:%S') - ${service} is unhealthy" >> ${LOG_FILE}
        return 1
    fi
}

# 检查 Web App
check_service "web-app" "8001"

# 检查 MySQL
docker exec mysql-${NODE_ROLE} mysqladmin ping -h localhost -uroot -p${MYSQL_ROOT_PASSWORD} > /dev/null 2>&1
if [ $? -eq 0 ]; then
    echo "$(date '+%Y-%m-%d %H:%M:%S') - MySQL is healthy" >> ${LOG_FILE}
else
    echo "$(date '+%Y-%m-%d %H:%M:%S') - MySQL is unhealthy" >> ${LOG_FILE}
fi

# 检查 Redis
docker exec redis-${NODE_ROLE} redis-cli -a ${REDIS_PASSWORD} ping > /dev/null 2>&1
if [ $? -eq 0 ]; then
    echo "$(date '+%Y-%m-%d %H:%M:%S') - Redis is healthy" >> ${LOG_FILE}
else
    echo "$(date '+%Y-%m-%d %H:%M:%S') - Redis is unhealthy" >> ${LOG_FILE}
fi
```

### 7.2 自动故障转移

创建 `scripts/failover.sh`:

```bash
#!/bin/bash
# 故障转移脚本

MASTER_IP=${MASTER_NODE_IP}
SLAVE_IP=${SLAVE_NODE_IP}

# 检查主节点健康状态
if ! curl -f -s http://${MASTER_IP}:8001/health > /dev/null 2>&1; then
    echo "$(date '+%Y-%m-%d %H:%M:%S') - Master node is down, switching to slave" >> /opt/HiFate-bazi/logs/failover.log
    
    # 更新 Nginx 配置，将备用节点提升为主节点
    # 这里需要根据实际情况调整
    # 可以发送通知、更新配置等
fi
```

### 7.3 定时任务

添加到 crontab (`crontab -e`):

```bash
# 每5分钟执行健康检查
*/5 * * * * /opt/HiFate-bazi/scripts/health_check.sh

# 每天凌晨2点备份数据库
0 2 * * * /opt/HiFate-bazi/scripts/backup_mysql.sh

# 每天凌晨3点清理旧日志（保留30天）
0 3 * * * find /opt/HiFate-bazi/logs -type f -mtime +30 -delete
```

---

## 八、监控和维护

### 8.1 日志查看

```bash
# 查看所有服务日志
docker-compose -f docker-compose.master.yml logs -f

# 查看特定服务日志
docker-compose -f docker-compose.master.yml logs -f web-app
docker-compose -f docker-compose.master.yml logs -f bazi-rule

# 查看 Nginx 日志
tail -f /var/log/nginx/HiFate-bazi-access.log
tail -f /var/log/nginx/HiFate-bazi-error.log
```

### 8.2 服务管理

```bash
# 启动服务
docker-compose -f docker-compose.master.yml up -d

# 停止服务
docker-compose -f docker-compose.master.yml down

# 重启服务
docker-compose -f docker-compose.master.yml restart

# 查看服务状态
docker-compose -f docker-compose.master.yml ps

# 查看资源使用
docker stats
```

### 8.3 数据库备份

创建 `scripts/backup_mysql.sh`:

```bash
#!/bin/bash
# MySQL 备份脚本

BACKUP_DIR="/opt/HiFate-bazi/backups"
DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_FILE="${BACKUP_DIR}/mysql_backup_${DATE}.sql"

mkdir -p ${BACKUP_DIR}

# 备份数据库
docker exec mysql-master mysqldump -uroot -p${MYSQL_ROOT_PASSWORD} \
    --single-transaction \
    --routines \
    --triggers \
    hifate_bazi > ${BACKUP_FILE}

# 压缩备份文件
gzip ${BACKUP_FILE}

# 删除7天前的备份
find ${BACKUP_DIR} -name "*.sql.gz" -mtime +7 -delete

echo "Backup completed: ${BACKUP_FILE}.gz"
```

### 8.4 性能监控

```bash
# 查看容器资源使用
docker stats

# 查看系统资源
top
htop
free -h
df -h

# 查看网络连接
netstat -tulpn
ss -tulpn
```

---

## 九、故障处理

### 9.1 常见问题

#### 问题1: 服务无法启动

```bash
# 检查日志
docker-compose -f docker-compose.master.yml logs

# 检查端口占用
netstat -tulpn | grep 8001

# 检查容器状态
docker ps -a
```

#### 问题2: MySQL 主从复制失败

```bash
# 在从节点检查复制状态
docker exec -it mysql-slave mysql -uroot -p${MYSQL_ROOT_PASSWORD} -e "SHOW SLAVE STATUS\G"

# 重新配置主从复制
# 参考步骤 6.7
```

#### 问题3: Redis 连接失败

```bash
# 检查 Redis 状态
docker exec redis-master redis-cli -a ${REDIS_PASSWORD} ping

# 检查 Redis 日志
docker logs redis-master
```

#### 问题4: 大模型 API 调用失败

```bash
# 检查环境变量
docker exec web-app env | grep COZE

# 检查网络连接
docker exec web-app curl -v https://api.coze.cn
```

### 9.2 故障恢复流程

1. **识别故障**：通过健康检查或监控告警
2. **切换流量**：更新 Nginx 配置，切换到备用节点
3. **排查问题**：查看日志，定位故障原因
4. **修复问题**：修复后重启服务
5. **验证恢复**：确认服务正常后，切回主节点

---

## 十、检查清单

### 10.1 部署前检查

- [ ] 两台 ECS 服务器已购买并配置
- [ ] 安全组规则已配置（开放必要端口）
- [ ] 内网互通（同一 VPC）
- [ ] 域名已解析（如使用域名）
- [ ] SSL 证书已准备（如使用 HTTPS）

### 10.2 部署检查

- [ ] 代码已上传到两台服务器
- [ ] Docker 和 Docker Compose 已安装
- [ ] 环境变量已配置（包括 Coze API）
- [ ] MySQL 主从复制已配置
- [ ] Redis 主从复制已配置
- [ ] Nginx 负载均衡已配置
- [ ] 健康检查已配置
- [ ] 日志目录已创建

### 10.3 功能检查

- [ ] Web App 健康检查通过
- [ ] 所有微服务健康检查通过
- [ ] MySQL 主从复制正常
- [ ] Redis 主从复制正常
- [ ] 负载均衡正常工作
- [ ] API 接口正常响应
- [ ] 大模型 API 调用正常
- [ ] 数据库读写正常

### 10.4 高可用检查

- [ ] 主节点故障时，流量自动切换到备用节点
- [ ] 主节点恢复后，可以手动切回
- [ ] MySQL 主从复制延迟在可接受范围内
- [ ] Redis 主从复制正常
- [ ] 监控告警已配置

---

## 十一、快速部署命令总结

### 节点1（主节点）

```bash
# 1. 初始化
cd /opt/HiFate-bazi
bash scripts/init_server.sh

# 2. 部署代码
git clone <repo> app  # 或使用 scp

# 3. 配置环境变量
cp .env.example .env
vim .env  # 设置 NODE_ROLE=master

# 4. 部署服务
docker-compose -f docker-compose.master.yml --env-file .env up -d

# 5. 初始化数据库
docker exec -i mysql-master mysql -uroot -p${MYSQL_ROOT_PASSWORD} hifate_bazi < app/server/db/schema.sql
```

### 节点2（从节点）

```bash
# 1. 初始化
cd /opt/HiFate-bazi
bash scripts/init_server.sh

# 2. 部署代码
git clone <repo> app  # 或使用 scp

# 3. 配置环境变量
cp .env.example .env
vim .env  # 设置 NODE_ROLE=slave

# 4. 部署服务
docker-compose -f docker-compose.slave.yml --env-file .env up -d

# 5. 配置 MySQL 主从复制（参考步骤 6.7）
```

### 配置负载均衡

```bash
# 在两台服务器上分别执行
cp nginx/conf.d/HiFate-bazi.conf /etc/nginx/conf.d/
nginx -t
systemctl start nginx
systemctl enable nginx
```

---

## 十二、附录

### 12.1 环境变量模板

创建 `.env.example`:

```bash
# MySQL 配置
MYSQL_ROOT_PASSWORD=change_me
MYSQL_PASSWORD=change_me

# Redis 配置
REDIS_PASSWORD=change_me

# Coze API 配置
COZE_ACCESS_TOKEN=pat_xxxxxxxxxxxxx
COZE_BOT_ID=1234567890

# 节点配置
NODE_ROLE=master
NODE_ID=1
MASTER_NODE_IP=172.16.0.10
SLAVE_NODE_IP=172.16.0.11
VIRTUAL_IP=172.16.0.100
```

### 12.2 常用命令

```bash
# 查看服务状态
docker-compose -f docker-compose.master.yml ps

# 查看日志
docker-compose -f docker-compose.master.yml logs -f

# 重启服务
docker-compose -f docker-compose.master.yml restart web-app

# 进入容器
docker exec -it web-app /bin/bash

# 查看资源使用
docker stats

# 清理未使用的镜像和容器
docker system prune -a
```

### 12.3 联系信息

- **文档版本**: 1.0
- **最后更新**: 2025-01-15
- **维护人员**: 系统管理员

---

**部署完成后，请按照检查清单逐项验证，确保所有服务正常运行。**

---

## 十三、十几万用户规模配置分析与优化方案

### 13.1 当前配置评估

#### 13.1.1 当前配置概览

| 资源项 | 当前配置 | 单台服务器能力 |
|--------|---------|--------------|
| CPU | 4核 | 支持约520并发用户（混合负载） |
| 内存 | 16GB | 足够运行所有服务 |
| 带宽 | 5Mbps | 约625KB/s，约50-100并发请求/秒 |
| 服务器数量 | 2台 | 理论最大约1000-1500并发用户 |
| MySQL连接 | 500 | 单台服务器 |
| Redis连接池 | 50 | 单台服务器 |

#### 13.1.2 并发能力分析

根据 `并发能力分析.md` 的评估：

- **轻量级请求**（如精选接口）：单台约160 QPS，支持约1600并发用户
- **重量级请求**（完整八字计算）：单台约16 QPS，支持约160并发用户
- **混合负载**（实际情况）：单台约52 QPS，支持约520并发用户

**双节点总并发能力**：
- 理论最大：约1000-1500并发用户（混合负载）
- 实际建议：约800-1000并发用户（留20%余量）

### 13.2 十几万用户负载分析（实际场景）

#### 13.2.1 用户规模假设

假设总用户数：**10-15万**

**实际并发用户估算**（八字算命类应用特点）：
- **用户行为特点**：查询后离开，不是持续在线
- **日活用户**：总用户的5-10%（5000-15000人）
- **同时在线用户**：日活的1-5%
  - 10万用户 × 5%日活 × 2%同时在线 = **100并发用户**
  - 15万用户 × 8%日活 × 3%同时在线 = **360并发用户**
- **高峰时段**（晚上8-10点）：同时在线可能达到日活的5-10%
  - 10万用户 × 5%日活 × 8%高峰 = **400并发用户**
  - 15万用户 × 8%日活 × 10%高峰 = **1200并发用户**
- **平峰时段**：**200-500并发用户**
- **低峰时段**：**50-200并发用户**

#### 13.2.2 请求量估算

假设每个用户平均行为：
- 平均每30-60秒1次请求（查询后浏览结果）
- 平均每次请求大小：10-30KB（响应）
- 平均请求耗时：0.3秒（混合负载）

**高峰时段QPS需求**：
- 400并发用户 ÷ 30秒 = **13 QPS**
- 1200并发用户 ÷ 30秒 = **40 QPS**
- **最坏情况**（假设更活跃）：1200并发 ÷ 10秒 = **120 QPS**

**带宽需求**：
- 40 QPS × 20KB/请求 = **0.8MB/s = 6.4Mbps**
- 120 QPS × 20KB/请求 = **2.4MB/s = 19.2Mbps**
- **考虑峰值和静态资源**：建议 **30-50Mbps** 总带宽

### 13.3 当前配置评估（实际需求）

#### 13.3.1 并发能力评估

| 项目 | 当前能力 | 实际高峰需求 | 评估 |
|------|---------|------------|------|
| 并发用户 | 1000 | 400-1200 | **基本满足，但需优化** |
| QPS | 104 (双节点) | 40-120 | **基本满足** |
| 服务器数量 | 2台 | 2台（基础）+ 动态扩展 | **需要支持动态扩展** |

#### 13.3.2 带宽评估

| 项目 | 当前配置 | 实际高峰需求 | 评估 |
|------|---------|------------|------|
| 单台带宽 | 5Mbps | 需要15-25Mbps | **需要升级到20-30Mbps** |
| 总带宽 | 10Mbps | 需要30-50Mbps | **需要升级到40-60Mbps** |

#### 13.3.3 数据库连接不足

- 当前：每台MySQL max_connections=500
- 需求：5000并发用户 ÷ 10 = 500个活跃连接（单台）
- 问题：双节点主从架构，从节点只读，主节点压力大

#### 13.3.4 无自动扩展能力

- 当前架构：固定2台服务器，无法根据负载自动扩展
- 问题：高峰时段无法自动扩容，低峰时段资源浪费

### 13.4 性价比最高方案（基于2台服务器 + 动态扩展）

#### 方案：2台基础服务器 + 自动扩展（推荐）

**基础服务器配置（2台固定）**：

| 资源项 | 配置 | 说明 |
|--------|------|------|
| CPU | 8核 | 每台服务器（提升2倍） |
| 内存 | 32GB | 足够运行所有服务 |
| 系统盘 | 40GB SSD | 系统 + 应用 |
| 数据盘 | 200GB SSD | MySQL + Redis 数据 |
| 带宽 | 20Mbps | 每台服务器（提升4倍） |
| 服务器数量 | **2台（基础）** | 主备模式，同时提供服务 |

**自动扩展配置**：
- **最小实例数**：2台（基础服务器）
- **最大实例数**：5-8台（高峰自动扩展）
- **扩展触发**：CPU > 70% 或 QPS > 80 时自动扩容
- **缩容触发**：CPU < 30% 且 QPS < 30 时自动缩容

**架构设计**：
```
┌─────────────────────────────────────────┐
│         负载均衡 SLB / Nginx             │
│            (40-60Mbps)                   │
└──────────────┬───────────────────────────┘
               │
    ┌──────────┼──────────┐
    │          │          │
┌───▼───┐  ┌───▼───┐  ┌───▼───┐ (自动扩展)
│基础1  │  │基础2  │  │扩展1  │
│8核32G │  │8核32G │  │8核32G │ (按需)
│20Mbps │  │20Mbps │  │20Mbps │
└───┬───┘  └───┬───┘  └───┬───┘
    │          │          │
    └──────────┼──────────┘
               │
    ┌──────────┼──────────┐
    │          │          │
┌───▼───┐  ┌───▼───┐
│MySQL主│  │MySQL从│
│8核32G │  │8核32G │
│200GB  │  │200GB  │
└───────┘  └───────┘
```

**预期能力**：
- **基础能力**（2台）：并发用户 **800-1000**，QPS **80-100**
- **扩展后**（5台）：并发用户 **2000-2500**，QPS **200-250**
- **带宽**：基础40Mbps，扩展后100Mbps

**成本估算**：
- 基础服务器（2台固定）：¥1000-1500/月
- 扩展服务器（平均1-2台）：¥500-1000/月（按需计费）
- 负载均衡SLB：¥100-200/月
- **总计**：约 **¥1600-2700/月**（平均¥2000/月）

#### 优化措施（提升性价比）

**1. 使用CDN加速静态资源**
- 静态资源（CSS、JS、图片）走CDN
- 减少服务器带宽压力 **50-70%**
- CDN成本：¥100-200/月（比服务器带宽便宜）

**2. 启用Gzip压缩**
- 减少响应大小 **30-50%**
- 几乎零成本，只需Nginx配置

**3. Redis缓存优化**
- 增加缓存命中率到 **80%+**
- 减少数据库压力 **50-70%**

**4. 数据库读写分离**
- 主库写，从库读
- 提升读性能 **2-3倍**

**5. 连接池优化**
- MySQL连接池：增加到200
- Redis连接池：增加到100

**优化后预期**：
- 基础2台可支持：**1200-1500并发用户**
- 扩展后5台可支持：**3000-4000并发用户**
- 带宽需求降低：**30-40Mbps**（使用CDN后）

**总成本**：
- 基础服务器（2台）：¥1000-1500/月
- 扩展服务器（平均1台）：¥500-750/月
- 负载均衡：¥100-200/月
- CDN：¥100-200/月
- **总计**：约 **¥1700-2650/月**（平均¥2200/月）

#### 自动扩展配置示例（阿里云）

**弹性伸缩组配置**：
- 启动模板：8核32GB，20Mbps，自动部署脚本
- 最小实例数：2（基础服务器）
- 最大实例数：5-8（高峰扩展）
- 期望实例数：2（平时）

**扩展规则**：
- CPU使用率 > 70% 持续3分钟 → 扩容2台
- CPU使用率 < 30% 持续10分钟 → 缩容1台
- QPS > 80 持续2分钟 → 扩容1台
- QPS < 30 持续10分钟 → 缩容1台

**成本优化**：
- 使用按量付费（非高峰时段自动释放）
- 低峰时段自动缩容到2台，节省成本
- 高峰时段自动扩容，保证服务稳定

### 13.5 带宽详细分析

#### 13.5.1 带宽需求计算

**单次请求带宽消耗**：
- 请求大小：平均2KB
- 响应大小：平均30KB（包含HTML、JSON、静态资源）
- 总带宽：32KB/请求

**不同并发场景的带宽需求**：

| 并发用户数 | QPS | 带宽需求 | 建议配置 |
|-----------|-----|---------|---------|
| 1000 | 100 | 3.2MB/s = 25.6Mbps | 30Mbps |
| 2000 | 200 | 6.4MB/s = 51.2Mbps | 60Mbps |
| 5000 | 500 | 16MB/s = 128Mbps | 150Mbps |
| 7500 | 750 | 24MB/s = 192Mbps | 200Mbps |
| 10000 | 1000 | 32MB/s = 256Mbps | 300Mbps |

#### 13.5.2 当前带宽问题

- **当前配置**：5Mbps/台 × 2台 = 10Mbps总带宽
- **实际高峰需求**：30-50Mbps（使用CDN后）
- **建议配置**：20Mbps/台 × 2台 = 40Mbps基础，扩展后可达100Mbps

#### 13.5.3 带宽优化建议

1. **应用服务器带宽**：每台20Mbps（基础），扩展时按需增加
2. **负载均衡带宽**：40-60Mbps（基础），扩展后可达100Mbps
3. **使用CDN**：静态资源（CSS、JS、图片）走CDN，减少服务器带宽压力50-70%
4. **启用Gzip压缩**：减少响应大小30-50%
5. **按需扩展**：高峰时段自动扩展服务器，带宽自动增加

### 13.6 数据库优化

#### 13.6.1 MySQL配置优化

**主节点配置**（`mysql/master/conf/my.cnf`）：
```ini
[mysqld]
# 连接数（实际需求500-1000，留有余量）
max_connections = 1000  # 足够支持2000-3000并发用户

# InnoDB缓冲池（使用70%内存）
innodb_buffer_pool_size = 20G  # 32GB内存的70%约22GB

# 日志文件
innodb_log_file_size = 512M
innodb_log_buffer_size = 64M

# 查询缓存（MySQL 8.0已移除，使用应用层缓存）
# 使用Redis缓存热点数据

# 慢查询日志
slow_query_log = 1
long_query_time = 1
```

**从节点配置**：
- 配置相同，但 `read-only = 1`
- 建议配置2-3个从节点，分担读压力

#### 13.6.2 读写分离

**应用层读写分离**：
```python
# 主库写，从库读
MYSQL_MASTER_HOST = 'mysql-master'
MYSQL_SLAVE_HOSTS = ['mysql-slave-1', 'mysql-slave-2']
```

**预期提升**：
- 读性能提升：2-3倍
- 主库压力减少：50-70%

### 13.7 Redis优化

#### 13.7.1 Redis配置优化

**连接池配置**（`server/config/redis_config.py`）：
```python
REDIS_CONFIG = {
    'max_connections': 200,  # 增加到200
    'socket_connect_timeout': 5,
    'socket_timeout': 5,
    'retry_on_timeout': True
}
```

#### 13.7.2 Redis集群模式

对于高并发场景，建议使用Redis集群：
- **主节点**：3个，每个8GB
- **从节点**：3个，每个8GB
- **自动故障转移**

### 13.8 自动扩展实现方案

#### 13.8.1 基于云服务的自动扩展（阿里云示例）

**创建弹性伸缩组**：

1. **创建启动模板**：
   - 镜像：包含应用代码的镜像
   - 实例规格：ecs.c6.2xlarge（8核32GB）
   - 安全组：开放80、443端口
   - 用户数据脚本：自动部署应用

2. **创建伸缩组**：
   - 最小实例数：3
   - 最大实例数：10
   - 期望实例数：5

3. **创建伸缩规则**：
   - **扩容规则**：CPU使用率 > 70%，增加2台
   - **缩容规则**：CPU使用率 < 30%，减少1台

4. **创建报警任务**：
   - 监控指标：CPU使用率、内存使用率、QPS
   - 触发条件：连续3分钟超过阈值

**自动扩展脚本示例**（用户数据）：
```bash
#!/bin/bash
# 自动部署脚本（在实例启动时执行）

# 1. 安装Docker
yum install -y docker
systemctl start docker
systemctl enable docker

# 2. 从对象存储拉取应用代码
# ossutil cp oss://your-bucket/app.tar.gz /opt/
# tar -xzf /opt/app.tar.gz -C /opt/HiFate-bazi

# 3. 启动服务
cd /opt/HiFate-bazi
docker-compose up -d

# 4. 注册到负载均衡
# 通过API或CLI将实例添加到SLB后端服务器组
```

#### 13.8.2 基于Kubernetes的自动扩展

**HPA配置**（见方案三）

**VPA（垂直扩展）**：
```yaml
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: web-app-vpa
spec:
  targetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: web-app
  updatePolicy:
    updateMode: "Auto"
```

### 13.9 监控和告警

#### 13.9.1 关键监控指标

| 指标 | 阈值 | 告警级别 |
|------|------|---------|
| CPU使用率 | > 70% | 警告 |
| CPU使用率 | > 85% | 严重 |
| 内存使用率 | > 80% | 警告 |
| 内存使用率 | > 90% | 严重 |
| QPS | > 400 | 警告 |
| QPS | > 600 | 严重 |
| 响应时间（P95） | > 1秒 | 警告 |
| 响应时间（P95） | > 2秒 | 严重 |
| 错误率 | > 1% | 警告 |
| 错误率 | > 5% | 严重 |
| MySQL连接数 | > 1500 | 警告 |
| Redis连接数 | > 150 | 警告 |

#### 13.9.2 监控工具推荐

- **云监控**：阿里云云监控、腾讯云监控
- **APM**：New Relic、Datadog、SkyWalking
- **日志**：ELK Stack、Loki + Grafana
- **指标**：Prometheus + Grafana

### 13.10 成本优化建议

#### 13.10.1 按需付费

- 使用自动扩展，低峰时段自动缩容
- 数据库使用按量付费（非高峰时段）

#### 13.10.2 预留实例

- 对于稳定负载，使用预留实例（节省30-50%成本）
- 对于波动负载，使用按需实例 + 自动扩展

#### 13.10.3 CDN加速

- 静态资源使用CDN，减少服务器带宽成本
- CDN成本通常比服务器带宽便宜50-70%

#### 13.10.4 数据库优化

- 使用读写分离，减少主库压力
- 使用Redis缓存，减少数据库查询
- 定期清理历史数据，减少存储成本

### 13.11 性价比最高方案总结

#### 13.11.1 推荐配置（2台基础 + 自动扩展）

| 项目 | 配置 | 成本/月 |
|------|------|---------|
| 基础服务器 | 2台 × 8核32GB，20Mbps | ¥1200 |
| 扩展服务器 | 自动扩展1-3台（平均1台） | ¥600 |
| 数据库 | 2台 × 8核32GB，200GB | ¥1000 |
| 负载均衡 | SLB 40Mbps | ¥150 |
| Redis | 主从模式，16GB | ¥300 |
| CDN | 静态资源加速 | ¥150 |
| **总计** | | **¥3400**（平均） |

**能力**：
- **基础能力**（2台）：1200-1500并发用户，120-150 QPS
- **扩展能力**（5台）：3000-4000并发用户，300-400 QPS
- **带宽**：40-100Mbps（使用CDN后）

**成本分析**：
- **低峰时段**（2台）：¥2350/月
- **平峰时段**（3台）：¥2950/月
- **高峰时段**（5台）：¥4150/月
- **平均成本**：¥3400/月

#### 13.11.2 成本优化效果

| 优化项 | 节省成本 | 说明 |
|--------|---------|------|
| 使用CDN | 节省带宽成本50% | 静态资源走CDN |
| 自动扩展 | 节省30-40% | 低峰自动缩容 |
| 按量付费 | 节省20-30% | 非高峰释放资源 |
| **总节省** | **约40-50%** | 相比固定扩容方案 |

#### 13.11.3 实施优先级

1. **立即实施**（1周内）：
   - ✅ 升级2台服务器配置到8核32GB，20Mbps
   - ✅ 优化MySQL和Redis配置（连接池、缓存）
   - ✅ 启用Gzip压缩
   - ✅ 配置Nginx负载均衡

2. **短期实施**（1个月内）：
   - ✅ 配置自动扩展（最小2台，最大5-8台）
   - ✅ 配置CDN（静态资源加速）
   - ✅ 实施读写分离（MySQL主从）
   - ✅ 完善监控告警

3. **长期优化**（3个月内）：
   - ✅ 根据实际负载调整扩展策略
   - ✅ 优化缓存策略，提升命中率
   - ✅ 数据库索引优化

---

**结论**：对于十几万用户，实际并发在400-1200之间。**2台8核32GB服务器 + 自动扩展**的方案性价比最高，平均成本约¥3400/月，可支持3000-4000并发用户，完全满足需求。通过CDN、缓存、自动扩展等优化，成本可进一步降低。

